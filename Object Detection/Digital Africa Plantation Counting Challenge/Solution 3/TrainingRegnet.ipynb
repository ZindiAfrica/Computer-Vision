{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a239eea-e414-412d-9242-d7316e9cc18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a7fcd7-eb6b-4ee8-8f57-ff5a443c78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch==1.13.1 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5833a3bb-192d-46b4-80ac-f7e3b03e17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "radiant-mlhub==0.4.1\n",
    "rasterio\n",
    "shapely\n",
    "accelerate==0.15.0\n",
    "albumentations==1.3.0\n",
    "timm==0.6.12\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6eb2fe-f515-471e-8ae3-1aae649d697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c866a9c-6192-4cf1-b8e7-1b96c98953f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1961ba0b-d202-4477-8004-63b1c5e5ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 10 15:40:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 30%   33C    P8    17W / 300W |      0MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a20d7-05ea-4951-a079-08c8b8a71940",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16825bfc-8853-445c-9e6c-53395bea41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b9b22b-0a41-44b0-beec-e050afbeaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as TDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.geometric.transforms as AG\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a120b4-51ef-49dc-9748-873fbd66e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy         : 1.23.4\n",
      "albumentations: 1.3.0\n",
      "PIL           : 9.2.0\n",
      "timm          : 0.6.12\n",
      "cv2           : 4.7.0\n",
      "torch         : 1.13.1+cu116\n",
      "matplotlib    : 3.6.1\n",
      "pandas        : 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563effdb-c378-45ba-8f7e-8d7cc8bf8b08",
   "metadata": {},
   "source": [
    "# Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db742f8-2be3-47d5-bd7b-82629ce77866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_warnings(strict=False):\n",
    "\twarnings.simplefilter('ignore')\n",
    "\tif strict:\n",
    "\t\tlogging.disable(logging.WARNING)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01b0cb9-83b7-46c0-8383-c9384772e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "disable_warnings()\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7fe6b-98d6-4d75-9912-bf1bf44b6643",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe357fad-adaf-4b32-8c8a-3bfba4d57170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_jdqw9hlv6j.png</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_6xtrolmuvc.png</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_2m49sj3xd9.png</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_9jwg5pcnn4.png</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_vnm6e8n0p3.png</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_jdqw9hlv6j.png    14.0\n",
       "1  Id_6xtrolmuvc.png    18.0\n",
       "2  Id_2m49sj3xd9.png     0.0\n",
       "3  Id_9jwg5pcnn4.png    28.0\n",
       "4  Id_vnm6e8n0p3.png    21.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files\n",
    "data_path = './data/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "sample_submission = pd.read_csv(data_path + 'SampleSubmission.csv')\n",
    "\n",
    "# Preview train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d2ead2-2302-480b-82b6-37346e9e07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId\n",
       "0  Id_ohk78h9ld8.png\n",
       "1  Id_eeyj2u4j7y.png\n",
       "2  Id_wsd7vx2ifa.png\n",
       "3  Id_6vfneamaoh.png\n",
       "4  Id_9wil3575fv.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd40436e-a4f4-4823-99b3-8ff6c05636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_ohk78h9ld8.png       0\n",
       "1  Id_eeyj2u4j7y.png       0\n",
       "2  Id_wsd7vx2ifa.png       0\n",
       "3  Id_6vfneamaoh.png       0\n",
       "4  Id_9wil3575fv.png       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview sample submission\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c4eea-ebba-4afe-8bde-2f37646bfb13",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46cb191-2de4-4698-ace9-95cabd8475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paralellize(fct, data, verbose=0, with_tqdm=True):\n",
    "    fn = map(delayed(fct), data)\n",
    "    if with_tqdm:\n",
    "        fn = tqdm(fn, total=len(data))\n",
    "    return Parallel(n_jobs=-1, verbose=verbose, backend=\"multiprocessing\")(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b524d68-7b88-4242-84d1-9015f40cf798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_transforms(size):\n",
    "    return A.Compose([\n",
    "      A.Resize(height=size, width=size, p=1),\n",
    "    ])\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(),\n",
    "            A.MedianBlur(blur_limit=3),\n",
    "            A.Blur(blur_limit=3),\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "def get_mosaic_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.0625, scale_limit=(-0.3, -0.2), rotate_limit=45, interpolation=1, border_mode=0, value=0, p=0.2\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452cbcd5-7bd3-43ed-98a4-ab216baaacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "def get_combos(ids, n=4) :\n",
    "    combos = []\n",
    "    size = len(ids)\n",
    "    \n",
    "    for i in range(0, size - n, 1):\n",
    "        combos.append(ids[i:i+n])\n",
    "    return combos\n",
    "\n",
    "def _combo_image_saver(ids_list):\n",
    "    save_path = './data/TreeImagesCombo/'\n",
    "    \n",
    "    images = [\n",
    "        Image.open(f'./data/TreeImages/{p}') for p in ids_list\n",
    "    ]\n",
    "\n",
    "    img = get_concat_h(*images[:2])\n",
    "\n",
    "    if len(ids_list) == 4:\n",
    "        img = get_concat_v(\n",
    "            img,\n",
    "            get_concat_h(*images[2:])\n",
    "        )\n",
    "\n",
    "    ids_list = [p.split('.')[0] for p in ids_list]\n",
    "    path = save_path + '|'.join(ids_list) + '.png'\n",
    "\n",
    "    img.save(path)\n",
    "\n",
    "def concat_mix_up(zeros_ids, palm_ids, n=4):\n",
    "    np.random.shuffle(zeros_ids)\n",
    "    np.random.shuffle(palm_ids)\n",
    "    \n",
    "    palm_combos = []\n",
    "    if n != -1:\n",
    "        palm_combos = get_combos(palm_ids, n=n)\n",
    "    \n",
    "    new_palm_combos = list(zip(zeros_ids, palm_ids))\n",
    "    new_palm_combos = [list(x) for x in new_palm_combos]\n",
    "    \n",
    "    _ = paralellize(_combo_image_saver, palm_combos + new_palm_combos)\n",
    "    \n",
    "    print(f'New {len(palm_combos + new_palm_combos)} images generated')\n",
    "    \n",
    "    return palm_combos + new_palm_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b207baa-60de-4d48-a281-1e71d56f3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(imgs):\n",
    "    size = len(imgs)\n",
    "    h, w, c = imgs[0].shape\n",
    "    \n",
    "    assert 1 <= size <= 4, f'size is {size}'\n",
    "    \n",
    "    if size == 1:\n",
    "        img = imgs[0]\n",
    "    elif size == 2:\n",
    "        img = np.empty(shape=(h, w*size, c), dtype=imgs[0].dtype)\n",
    "        img[:, :w, :] = imgs[0]\n",
    "        img[:, w:, :] = imgs[1]\n",
    "    else:\n",
    "        if size == 3:\n",
    "            imgs.append(np.zeros_like(imgs[0], dtype=imgs[0].dtype))\n",
    "        \n",
    "        img = np.empty(shape=(h*2, w*2, c), dtype=imgs[0].dtype)\n",
    "        img[:h, :w, :] = imgs[0]\n",
    "        img[h:, :w, :] = imgs[1]\n",
    "        img[:h, w:, :] = imgs[2]\n",
    "        img[h:, w:, :] = imgs[3]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e96cec8-1822-4129-b5bf-73974ca259a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(preds, biomass):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    return torch.sqrt(loss_fn(preds, biomass))\n",
    "\n",
    "def metric(preds, biomass):\n",
    "    preds = preds.cpu().numpy()\n",
    "    preds = np.where(preds > 0, preds, 0)\n",
    "    \n",
    "    return mean_squared_error(biomass.cpu().numpy(), preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a1076b-e3c9-4471-8157-cb53260fd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            args.arch, num_classes=1, pretrained=True, **args.extra_params\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beee4655-7297-443f-8bb6-37aa6e95c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, imagesPath, df, tfms=None, phase='test'):\n",
    "        self.imagespath = imagesPath\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "        self.default_tfms = get_common_transforms(args.img_size)\n",
    "        self.mosaic = args.mosaic\n",
    "        self.mosaic_aug = args.mosaic_aug\n",
    "        self.mosaic_tfms = get_mosaic_transforms()\n",
    "        self.length = len(self.df)\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def _read_image(self, idx):\n",
    "        imagename, label, *z = self.df.iloc[idx].values\n",
    "        path = os.path.join(self.imagespath, imagename)\n",
    "        if not os.path.exists(path):\n",
    "            path = os.path.join('./data/TreeImagesCombo/', imagename)\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self._read_image(idx)\n",
    "        \n",
    "        if self.mosaic and self.phase == 'train':\n",
    "            n_image = np.random.choice([0, 1])\n",
    "            if n_image != 0:\n",
    "                idxs = np.random.randint(self.length, size=n_image)\n",
    "                images = [image]\n",
    "                for i in idxs:\n",
    "                    img, i_label = self._read_image(i)\n",
    "                    if self.mosaic_aug:\n",
    "                        img = self.mosaic_tfms(image=img)['image']\n",
    "                        \n",
    "                    images.append(img)\n",
    "                    label += i_label\n",
    "                \n",
    "                image = mosaic(images)\n",
    "        \n",
    "        if self.tfms is not None:\n",
    "            image = self.tfms(image=image)['image']\n",
    "        \n",
    "        image = self.default_tfms(image=image)['image']\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        image = torch.permute(image, (2, 0, 1))\n",
    "        \n",
    "        return image, torch.tensor([label], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ef3c9e-8251-4957-a9d8-0bb7b9a0fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    model = TreeCountingModel(args)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b07ec777-b1fa-4a48-9c64-152e298b287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(args, df, path='folds/'):\n",
    "    os.makedirs(\"folds/\", exist_ok=True)\n",
    "    os.makedirs(f\"folds/{args.n_split}_splits/\", exist_ok=True)\n",
    "    \n",
    "    all_splits = {}\n",
    "    fold_path = f\"folds/{args.n_split}_splits/\"\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    to_drop = ['Id_u45dpub99b.png', 'Id_kzuy1er5jm.png', 'Id_lp4yl8q9n2.png', 'Id_2r2259ynzp.png', 'Id_w4fnd54go8.png', 'Id_lh8b1k1lx8.png', 'Id_hmcnf15rll.png']\n",
    "    hard_ids = ['Id_scf1bqac43.png', 'Id_uhcehdmyc1.png', 'Id_y87obok3v0.png', 'Id_kx60b4dgn2.png', 'Id_85992p4se2.png', 'Id_g7fbxrng46.png',\n",
    "           'Id_tz74cy4nh9.png', 'Id_u2dzh57wmf.png', 'Id_n0ipc9o8el.png', 'Id_lvua92vvg5.png', 'Id_ibrflyue8t.png', 'Id_xi61ipimpj.png',\n",
    "           'Id_tn748l5k57.png', 'Id_63zqtghlbi.png', 'Id_9xwykwajjb.png', 'Id_owxhn1zmlh.png', 'Id_6ls94ewz47.png', 'Id_upua3g7q2q.png',\n",
    "           'Id_eza4ic1a4k.png', 'Id_jxu8riswpw.png', 'Id_4nuo9gc80n.png', 'Id_rkm6vwm0md.png', 'Id_2goic5xoft.png', 'Id_234nhwag1a.png',\n",
    "           'Id_842atkbl2g.png', 'Id_v9gmdly1tl.png', 'Id_7evqslin0q.png', 'Id_5jgknuixmg.png', 'Id_8bhp0orrri.png', 'Id_yyvlvcursz.png',\n",
    "           'Id_kbgnlekbjm.png', 'Id_kd9m5eoeuf.png', 'Id_h0f091di0y.png', 'Id_scf4jxhlfg.png', 'Id_8xuqs2ut71.png', 'Id_4x0zh3y93q.png',\n",
    "           'Id_oamy4tybj9.png', 'Id_8q73x3g38y.png', 'Id_k0c89tgg4c.png', 'Id_niwpztq309.png', 'Id_r405nptkvd.png'\n",
    "    ]\n",
    "    df_hard = df_clean[df_clean.ImageId.isin(hard_ids)].reset_index(drop=True)\n",
    "    df_clean = df_clean[~df_clean.ImageId.isin(to_drop+hard_ids)].reset_index(drop=True)\n",
    "    \n",
    "    kf = StratifiedKFold(args.n_split, shuffle=True, random_state=42)\n",
    "    \n",
    "    num_bins = int(np.floor(1 + np.log2(len(df_clean))))\n",
    "    bins = pd.cut(df_clean['Target'], bins=num_bins, labels=False)\n",
    "        \n",
    "    print('Num bins:', num_bins)\n",
    "    \n",
    "    for f, (tr_idx, vr_idx) in enumerate(kf.split(df_clean, bins)):\n",
    "        all_splits[f] = {\n",
    "          'train': pd.concat([ df_clean.iloc[tr_idx], df_hard]).sample(frac=1),\n",
    "          'val': df_clean.iloc[vr_idx],\n",
    "        }\n",
    "        \n",
    "        df_clean.iloc[vr_idx].to_csv(f\"folds/{args.n_split}_splits/fold_{f}.csv\", index=False)\n",
    "\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccd222f9-e3e1-4398-994b-33637be80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._time = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._time = time()\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return (time() - self._time) / 60\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5267b313-81a8-4d56-9042-2db614934797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fn(args, dataloader, model, opt, epoch, accelerator, scheduler=None):    \n",
    "    avg_loss = 0\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    timer.start()\n",
    "    for i, (x, biomass) in enumerate(dataloader):\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, biomass)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        score = metric(preds.detach().float(), biomass.detach())\n",
    "        meter.update(score)\n",
    "\n",
    "        if scheduler is not None and args.schedule not in ['plateau']:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(('\\r[Training][{}/{}][{:.2f} min] Epoch {} : Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "        i+1, size, timer.time, epoch, avg_loss/(i+1), meter.avg\n",
    "        ), end='')\n",
    "    print()\n",
    "\n",
    "################## evaluation Function ####################   \n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    avg_loss = 0\n",
    "\n",
    "    all_logits = []\n",
    "    all_masks = []\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    timer.start()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, biomass) in enumerate(dataloader):\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, biomass)\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            score = metric(preds.detach().float(), biomass.detach().float())\n",
    "            meter.update(score)\n",
    "\n",
    "            print(('\\r[Evaluation][{}/{}][{:.2f} min] Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "            i+1, size, timer.time, avg_loss/(i+1), meter.avg\n",
    "            ), end='')\n",
    "    print()\n",
    "\n",
    "    return avg_loss/size, meter.avg\n",
    "\n",
    "################## Run training over folds Function ####################   \n",
    "def release_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def run_fold(fold, args, path='./models'):\n",
    "    model_path = f'{path}/{args.arch}-{args.n_split}-{args.img_size}-{args.lr}-{args.bs}'\n",
    "    if fold == 0:\n",
    "        mid = len(glob(model_path+'*'))\n",
    "        model_path += f'-{mid}'\n",
    "        os.makedirs(model_path, exist_ok=False)\n",
    "        \n",
    "        print('Model path:', model_path)\n",
    "    else:\n",
    "        model_id = sorted([int(x.replace(model_path+'-', '')) for x in glob(f'{model_path}*')])[-1]\n",
    "        model_path = f'{model_path}-{model_id}'\n",
    "    \n",
    "    best_metric = np.inf\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    train_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['train'],\n",
    "        tfms=get_train_transforms(),\n",
    "        phase='train'\n",
    "    )\n",
    "    val_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['val'],\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(train_ds, batch_size=args.bs, num_workers=args.workers, pin_memory=True, shuffle=True)\n",
    "    validloader = DataLoader(val_ds, batch_size=args.ebs, num_workers=args.workers, pin_memory=True, shuffle=False)\n",
    "\n",
    "    accelerator = Accelerator(fp16=args.fp16)\n",
    "\n",
    "    model = get_model(args)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "    num_train_steps = int(len(trainloader) * args.epochs)\n",
    "    steps_per_epoch = len(trainloader)\n",
    "\n",
    "    scheduler = None\n",
    "    if args.schedule:\n",
    "        scheduler = CosineAnnealingLR(opt, T_max=num_train_steps, eta_min=args.min_lr)\n",
    "        model, scheduler, opt, trainloader, validloader = accelerator.prepare(model, scheduler, opt, trainloader, validloader)\n",
    "    else:\n",
    "        model, opt, trainloader, validloader = accelerator.prepare(model, opt, trainloader, validloader)\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    loader = tqdm(range(args.epochs), desc=f'Fold {fold}')\n",
    "\n",
    "    for epoch in loader:\n",
    "        training_fn(args, trainloader, model, opt, epoch, accelerator, scheduler)\n",
    "        avg_loss, avg_metric = evaluate(validloader, model)\n",
    "\n",
    "        if scheduler is not None and args.schedule in ['plateau']:\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "        if avg_metric < best_metric:\n",
    "            best_loss = avg_loss\n",
    "            best_metric = avg_metric\n",
    "\n",
    "            torch.save(model.state_dict(), f'{model_path}/best_{fold}.pt')\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(f\"Best Fold --- Loss score: {best_loss} - F1 Score {best_metric}\")\n",
    "\n",
    "    # Clean up\n",
    "    del trainloader, validloader\n",
    "    del model, opt\n",
    "    release_memory()\n",
    "\n",
    "    return best_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de588c-aabf-4134-b3a3-c208e25b642b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412e0d03-2e54-4789-95e1-fe31af84a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu count: 8\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    arch = 'regnetz_040h'\n",
    "    lr = 1e-3\n",
    "    min_lr = 0\n",
    "    wd = 1e-6\n",
    "    epochs = 20\n",
    "    warmup = 0.\n",
    "    bs = 24\n",
    "    ebs = 2 * bs\n",
    "    \n",
    "    n_split = 5\n",
    "    use_folds = list(range(n_split))\n",
    "    actual_split = len(use_folds)\n",
    "\n",
    "    img_size = 768\n",
    "    \n",
    "    tta_tfms = []\n",
    "\n",
    "    schedule = True\n",
    "    augment = True\n",
    "    mosaic = False\n",
    "    mosaic_aug = False\n",
    "\n",
    "    fp16 = True\n",
    "    workers = os.cpu_count()\n",
    "    \n",
    "    print('Cpu count:', workers)\n",
    "\n",
    "    extra_params = {\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86583c8-6cf2-4e28-aa6e-ec499c63fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f3852cc-0945-4b1a-952c-7eb289ca9955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num bins: 11\n"
     ]
    }
   ],
   "source": [
    "all_splits = make_splits(args, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f75fcba-e376-45bf-adf6-a33db857737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./models/regnetz_040h-5-768-0.001-24-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a807608b89241da8be1b4ec5ffb8bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.16 min] Epoch 0 : Loss: 7.65986 - RMSE: 7.5145082\n",
      "[Evaluation][9/9][0.15 min] Loss: 3.90206 - RMSE: 3.90206\n",
      "\n",
      "[Training][67/67][1.08 min] Epoch 1 : Loss: 3.52342 - RMSE: 3.51606\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.86460 - RMSE: 2.86216\n",
      "\n",
      "[Training][67/67][1.08 min] Epoch 2 : Loss: 2.85862 - RMSE: 2.84740\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.30920 - RMSE: 2.30920\n",
      "\n",
      "[Training][67/67][1.08 min] Epoch 3 : Loss: 2.52722 - RMSE: 2.52199\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.73005 - RMSE: 1.72985\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 4 : Loss: 2.34285 - RMSE: 2.34014\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.77575 - RMSE: 1.77420\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 5 : Loss: 2.11717 - RMSE: 2.11241\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.05190 - RMSE: 2.02993\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 6 : Loss: 2.07209 - RMSE: 2.06465\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.13612 - RMSE: 2.13254\n",
      "\n",
      "[Training][67/67][1.25 min] Epoch 7 : Loss: 2.06915 - RMSE: 2.06686\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.39995 - RMSE: 2.39995\n",
      "\n",
      "[Training][67/67][1.08 min] Epoch 8 : Loss: 1.82085 - RMSE: 1.81841\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.89870 - RMSE: 1.89820\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 9 : Loss: 1.69354 - RMSE: 1.69100\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.79728 - RMSE: 1.79724\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 10 : Loss: 1.71288 - RMSE: 1.71243\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.93212 - RMSE: 1.93212\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 11 : Loss: 1.51128 - RMSE: 1.51039\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.60550 - RMSE: 1.60524\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 12 : Loss: 1.47940 - RMSE: 1.47780\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.60222 - RMSE: 1.60216\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 13 : Loss: 1.44207 - RMSE: 1.44131\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.57163 - RMSE: 1.57043\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 14 : Loss: 1.32406 - RMSE: 1.32301\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.52753 - RMSE: 1.52752\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 15 : Loss: 1.33816 - RMSE: 1.33765\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.64353 - RMSE: 1.64345\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 16 : Loss: 1.22197 - RMSE: 1.22134\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.56143 - RMSE: 1.56067\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 17 : Loss: 1.23461 - RMSE: 1.23388\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.50967 - RMSE: 1.50960\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 18 : Loss: 1.16992 - RMSE: 1.16930\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.54297 - RMSE: 1.54273\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 19 : Loss: 1.13020 - RMSE: 1.12926\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.61862 - RMSE: 1.61832\n",
      "\n",
      "Best Fold --- Loss score: 1.50967366165585 - F1 Score 1.5095959769354925\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e290994780cb40a1a6c8ae3b588f77c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.11 min] Epoch 0 : Loss: 7.20877 - RMSE: 6.9411596\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.79425 - RMSE: 2.64487\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 1 : Loss: 3.71683 - RMSE: 3.68683\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.44280 - RMSE: 2.20979\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 2 : Loss: 3.08446 - RMSE: 3.05758\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.09400 - RMSE: 2.09131\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 3 : Loss: 2.64795 - RMSE: 2.63158\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.62961 - RMSE: 1.62961\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 4 : Loss: 2.19926 - RMSE: 2.19133\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.41424 - RMSE: 2.40509\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 5 : Loss: 2.18115 - RMSE: 2.17351\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.81949 - RMSE: 2.81940\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 6 : Loss: 2.04066 - RMSE: 2.03454\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.59382 - RMSE: 1.59378\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 7 : Loss: 1.91784 - RMSE: 1.91220\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.40773 - RMSE: 1.40388\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 8 : Loss: 1.78386 - RMSE: 1.77926\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.46730 - RMSE: 1.46730\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 9 : Loss: 1.80533 - RMSE: 1.79999\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.97990 - RMSE: 1.97896\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 10 : Loss: 1.64210 - RMSE: 1.63903\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.68166 - RMSE: 1.68166\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 11 : Loss: 1.71761 - RMSE: 1.71499\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.38374 - RMSE: 1.38313\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 12 : Loss: 1.58075 - RMSE: 1.57843\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.37969 - RMSE: 1.37943\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 13 : Loss: 1.46310 - RMSE: 1.46020\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.48761 - RMSE: 1.48760\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 14 : Loss: 1.37192 - RMSE: 1.36826\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.30161 - RMSE: 1.30114\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 15 : Loss: 1.32860 - RMSE: 1.32703\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.41413 - RMSE: 1.41370\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 16 : Loss: 1.25872 - RMSE: 1.25709\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.34044 - RMSE: 1.34038\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 17 : Loss: 1.18534 - RMSE: 1.18422\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.35677 - RMSE: 1.35676\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 18 : Loss: 1.14568 - RMSE: 1.14337\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.29301 - RMSE: 1.29300\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 19 : Loss: 1.17731 - RMSE: 1.17520\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.29925 - RMSE: 1.29891\n",
      "\n",
      "Best Fold --- Loss score: 1.2930079234970941 - F1 Score 1.2930027378929987\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985e360236224cdb8b8199115b46fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.10 min] Epoch 0 : Loss: 6.61264 - RMSE: 6.3719454\n",
      "[Evaluation][9/9][0.14 min] Loss: 4.14328 - RMSE: 4.13115\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 1 : Loss: 3.81213 - RMSE: 3.78047\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.20224 - RMSE: 1.88982\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 2 : Loss: 2.81636 - RMSE: 2.79122\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.39083 - RMSE: 2.00147\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 3 : Loss: 2.58420 - RMSE: 2.56331\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.39463 - RMSE: 2.39463\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 4 : Loss: 2.67087 - RMSE: 2.66626\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.06901 - RMSE: 2.05911\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 5 : Loss: 2.29479 - RMSE: 2.28847\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.58851 - RMSE: 1.57656\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 6 : Loss: 2.06059 - RMSE: 2.05686\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.49634 - RMSE: 1.49057\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 7 : Loss: 1.94928 - RMSE: 1.93959\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.54289 - RMSE: 1.54119\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 8 : Loss: 1.97162 - RMSE: 1.96512\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.39715 - RMSE: 1.39079\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 9 : Loss: 1.79007 - RMSE: 1.78707\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.79033 - RMSE: 1.78228\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 10 : Loss: 1.73418 - RMSE: 1.73226\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.53110 - RMSE: 1.53093\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 11 : Loss: 1.66012 - RMSE: 1.65840\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.44495 - RMSE: 1.44453\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 12 : Loss: 1.66515 - RMSE: 1.66160\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.46198 - RMSE: 1.45383\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 13 : Loss: 1.55242 - RMSE: 1.54943\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.70921 - RMSE: 1.69848\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 14 : Loss: 1.52658 - RMSE: 1.52513\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.33527 - RMSE: 1.33273\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 15 : Loss: 1.39576 - RMSE: 1.39440\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.34076 - RMSE: 1.33989\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 16 : Loss: 1.43592 - RMSE: 1.43480\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.36222 - RMSE: 1.36069\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 17 : Loss: 1.30293 - RMSE: 1.30194\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.28452 - RMSE: 1.28169\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 18 : Loss: 1.27681 - RMSE: 1.27621\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.30703 - RMSE: 1.30633\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 19 : Loss: 1.25091 - RMSE: 1.25027\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.31176 - RMSE: 1.31011\n",
      "\n",
      "Best Fold --- Loss score: 1.2845206194453769 - F1 Score 1.2816869616508484\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6451b4f4d94b1cb3221e5657039dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.10 min] Epoch 0 : Loss: 7.09356 - RMSE: 6.9380751\n",
      "[Evaluation][9/9][0.13 min] Loss: 3.12462 - RMSE: 3.12462\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 1 : Loss: 3.77888 - RMSE: 3.76026\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.76159 - RMSE: 2.62485\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 2 : Loss: 3.00383 - RMSE: 2.99204\n",
      "[Evaluation][9/9][0.14 min] Loss: 3.33204 - RMSE: 3.33204\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 3 : Loss: 2.86496 - RMSE: 2.85215\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.26701 - RMSE: 2.26318\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 4 : Loss: 2.17505 - RMSE: 2.17084\n",
      "[Evaluation][9/9][0.14 min] Loss: 3.14733 - RMSE: 3.14611\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 5 : Loss: 2.23136 - RMSE: 2.22485\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.63903 - RMSE: 1.63885\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 6 : Loss: 2.03913 - RMSE: 2.03662\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.48649 - RMSE: 1.47720\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 7 : Loss: 2.10346 - RMSE: 2.10069\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.68858 - RMSE: 1.68839\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 8 : Loss: 1.84087 - RMSE: 1.83627\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.72435 - RMSE: 1.72116\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 9 : Loss: 1.74771 - RMSE: 1.74454\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.34995 - RMSE: 1.34930\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 10 : Loss: 1.74808 - RMSE: 1.74486\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.35008 - RMSE: 1.34987\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 11 : Loss: 1.77852 - RMSE: 1.77561\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.30066 - RMSE: 1.29677\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 12 : Loss: 1.57879 - RMSE: 1.57622\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.34874 - RMSE: 1.34871\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 13 : Loss: 1.51744 - RMSE: 1.51576\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.28795 - RMSE: 1.28712\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 14 : Loss: 1.50609 - RMSE: 1.50510\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.20219 - RMSE: 1.20163\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 15 : Loss: 1.37567 - RMSE: 1.37406\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.31033 - RMSE: 1.30937\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 16 : Loss: 1.39402 - RMSE: 1.39215\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.23126 - RMSE: 1.23036\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 17 : Loss: 1.27082 - RMSE: 1.26895\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.18675 - RMSE: 1.18447\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 18 : Loss: 1.29254 - RMSE: 1.29100\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.20858 - RMSE: 1.20773\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 19 : Loss: 1.28857 - RMSE: 1.28707\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.20940 - RMSE: 1.20860\n",
      "\n",
      "Best Fold --- Loss score: 1.1867535445425246 - F1 Score 1.1844655341572232\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6914f740223e4cdb82237fa53f2002ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.10 min] Epoch 0 : Loss: 7.20096 - RMSE: 7.0659833\n",
      "[Evaluation][9/9][0.14 min] Loss: 7.80215 - RMSE: 7.80215\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 1 : Loss: 4.17563 - RMSE: 4.16866\n",
      "[Evaluation][9/9][0.14 min] Loss: 4.52683 - RMSE: 4.52658\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 2 : Loss: 3.08482 - RMSE: 3.07329\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.94100 - RMSE: 1.91039\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 3 : Loss: 2.54758 - RMSE: 2.53983\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.99843 - RMSE: 1.98467\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 4 : Loss: 2.14441 - RMSE: 2.13914\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.52140 - RMSE: 2.51018\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 5 : Loss: 2.00254 - RMSE: 1.99521\n",
      "[Evaluation][9/9][0.14 min] Loss: 2.00944 - RMSE: 2.00620\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 6 : Loss: 1.91860 - RMSE: 1.91654\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.63261 - RMSE: 1.63243\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 7 : Loss: 1.86590 - RMSE: 1.86299\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.40354 - RMSE: 1.40327\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 8 : Loss: 1.89055 - RMSE: 1.88879\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.19378 - RMSE: 2.18896\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 9 : Loss: 1.74604 - RMSE: 1.74366\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.62432 - RMSE: 1.62409\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 10 : Loss: 1.70278 - RMSE: 1.70179\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.87712 - RMSE: 1.87321\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 11 : Loss: 1.62550 - RMSE: 1.62375\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.60446 - RMSE: 1.60418\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 12 : Loss: 1.48171 - RMSE: 1.48042\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.44283 - RMSE: 1.43534\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 13 : Loss: 1.42815 - RMSE: 1.42630\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.36023 - RMSE: 1.35991\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 14 : Loss: 1.42422 - RMSE: 1.42297\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.32974 - RMSE: 1.32826\n",
      "\n",
      "[Training][67/67][1.11 min] Epoch 15 : Loss: 1.25416 - RMSE: 1.25338\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.33649 - RMSE: 1.33601\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 16 : Loss: 1.26019 - RMSE: 1.25905\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.28671 - RMSE: 1.28529\n",
      "\n",
      "[Training][67/67][1.09 min] Epoch 17 : Loss: 1.20312 - RMSE: 1.20208\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.28500 - RMSE: 1.28421\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 18 : Loss: 1.15464 - RMSE: 1.15383\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.27922 - RMSE: 1.27884\n",
      "\n",
      "[Training][67/67][1.10 min] Epoch 19 : Loss: 1.17360 - RMSE: 1.17254\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.46258 - RMSE: 1.46103\n",
      "\n",
      "Best Fold --- Loss score: 1.2792197002304926 - F1 Score 1.2788418531417847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "\n",
    "for f in args.use_folds:\n",
    "    fold_score = run_fold(f, args)\n",
    "    avg_score += (fold_score / args.actual_split)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c58122eb-2391-4274-83e1-ee953aaa1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3095186127556695"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cb824-9570-422d-a864-d34cbbe973a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
