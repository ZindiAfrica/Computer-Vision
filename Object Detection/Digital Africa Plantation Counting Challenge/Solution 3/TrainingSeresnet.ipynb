{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a239eea-e414-412d-9242-d7316e9cc18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5833a3bb-192d-46b4-80ac-f7e3b03e17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "radiant-mlhub==0.4.1\n",
    "rasterio\n",
    "shapely\n",
    "accelerate==0.15.0\n",
    "albumentations==1.3.0\n",
    "timm==0.6.12\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a7fcd7-eb6b-4ee8-8f57-ff5a443c78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch==1.13.1 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6eb2fe-f515-471e-8ae3-1aae649d697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c866a9c-6192-4cf1-b8e7-1b96c98953f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1961ba0b-d202-4477-8004-63b1c5e5ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 10 23:45:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   31C    P0    51W / 400W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a20d7-05ea-4951-a079-08c8b8a71940",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16825bfc-8853-445c-9e6c-53395bea41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b9b22b-0a41-44b0-beec-e050afbeaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as TDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.geometric.transforms as AG\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a120b4-51ef-49dc-9748-873fbd66e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2           : 4.7.0\n",
      "torch         : 1.13.1+cu116\n",
      "PIL           : 9.2.0\n",
      "albumentations: 1.3.0\n",
      "timm          : 0.6.12\n",
      "matplotlib    : 3.6.1\n",
      "pandas        : 1.5.0\n",
      "numpy         : 1.23.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563effdb-c378-45ba-8f7e-8d7cc8bf8b08",
   "metadata": {},
   "source": [
    "# Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db742f8-2be3-47d5-bd7b-82629ce77866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_warnings(strict=False):\n",
    "\twarnings.simplefilter('ignore')\n",
    "\tif strict:\n",
    "\t\tlogging.disable(logging.WARNING)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01b0cb9-83b7-46c0-8383-c9384772e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "disable_warnings()\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7fe6b-98d6-4d75-9912-bf1bf44b6643",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe357fad-adaf-4b32-8c8a-3bfba4d57170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_jdqw9hlv6j.png</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_6xtrolmuvc.png</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_2m49sj3xd9.png</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_9jwg5pcnn4.png</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_vnm6e8n0p3.png</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_jdqw9hlv6j.png    14.0\n",
       "1  Id_6xtrolmuvc.png    18.0\n",
       "2  Id_2m49sj3xd9.png     0.0\n",
       "3  Id_9jwg5pcnn4.png    28.0\n",
       "4  Id_vnm6e8n0p3.png    21.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files\n",
    "data_path = './data/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "sample_submission = pd.read_csv(data_path + 'SampleSubmission.csv')\n",
    "\n",
    "# Preview train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d2ead2-2302-480b-82b6-37346e9e07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId\n",
       "0  Id_ohk78h9ld8.png\n",
       "1  Id_eeyj2u4j7y.png\n",
       "2  Id_wsd7vx2ifa.png\n",
       "3  Id_6vfneamaoh.png\n",
       "4  Id_9wil3575fv.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd40436e-a4f4-4823-99b3-8ff6c05636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_ohk78h9ld8.png       0\n",
       "1  Id_eeyj2u4j7y.png       0\n",
       "2  Id_wsd7vx2ifa.png       0\n",
       "3  Id_6vfneamaoh.png       0\n",
       "4  Id_9wil3575fv.png       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview sample submission\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c4eea-ebba-4afe-8bde-2f37646bfb13",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b46cb191-2de4-4698-ace9-95cabd8475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paralellize(fct, data, verbose=0, with_tqdm=True):\n",
    "    fn = map(delayed(fct), data)\n",
    "    if with_tqdm:\n",
    "        fn = tqdm(fn, total=len(data))\n",
    "    return Parallel(n_jobs=-1, verbose=verbose, backend=\"multiprocessing\")(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b524d68-7b88-4242-84d1-9015f40cf798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_transforms(size):\n",
    "    return A.Compose([\n",
    "      A.Resize(height=size, width=size, p=1),\n",
    "    ])\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(),\n",
    "            A.MedianBlur(blur_limit=3),\n",
    "            A.Blur(blur_limit=3),\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "def get_mosaic_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.0625, scale_limit=(-0.3, -0.2), rotate_limit=45, interpolation=1, border_mode=0, value=0, p=0.2\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "452cbcd5-7bd3-43ed-98a4-ab216baaacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "def get_combos(ids, n=4) :\n",
    "    combos = []\n",
    "    size = len(ids)\n",
    "    \n",
    "    for i in range(0, size - n, 1):\n",
    "        combos.append(ids[i:i+n])\n",
    "    return combos\n",
    "\n",
    "def _combo_image_saver(ids_list):\n",
    "    save_path = './data/TreeImagesCombo/'\n",
    "    \n",
    "    images = [\n",
    "        Image.open(f'./data/TreeImages/{p}') for p in ids_list\n",
    "    ]\n",
    "\n",
    "    img = get_concat_h(*images[:2])\n",
    "\n",
    "    if len(ids_list) == 4:\n",
    "        img = get_concat_v(\n",
    "            img,\n",
    "            get_concat_h(*images[2:])\n",
    "        )\n",
    "\n",
    "    ids_list = [p.split('.')[0] for p in ids_list]\n",
    "    path = save_path + '|'.join(ids_list) + '.png'\n",
    "\n",
    "    img.save(path)\n",
    "\n",
    "def concat_mix_up(zeros_ids, palm_ids, n=4):\n",
    "    np.random.shuffle(zeros_ids)\n",
    "    np.random.shuffle(palm_ids)\n",
    "    \n",
    "    palm_combos = []\n",
    "    if n != -1:\n",
    "        palm_combos = get_combos(palm_ids, n=n)\n",
    "    \n",
    "    new_palm_combos = list(zip(zeros_ids, palm_ids))\n",
    "    new_palm_combos = [list(x) for x in new_palm_combos]\n",
    "    \n",
    "    _ = paralellize(_combo_image_saver, palm_combos + new_palm_combos)\n",
    "    \n",
    "    print(f'New {len(palm_combos + new_palm_combos)} images generated')\n",
    "    \n",
    "    return palm_combos + new_palm_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b207baa-60de-4d48-a281-1e71d56f3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(imgs):\n",
    "    size = len(imgs)\n",
    "    h, w, c = imgs[0].shape\n",
    "    \n",
    "    assert 1 <= size <= 4, f'size is {size}'\n",
    "    \n",
    "    if size == 1:\n",
    "        img = imgs[0]\n",
    "    elif size == 2:\n",
    "        img = np.empty(shape=(h, w*size, c), dtype=imgs[0].dtype)\n",
    "        img[:, :w, :] = imgs[0]\n",
    "        img[:, w:, :] = imgs[1]\n",
    "    else:\n",
    "        if size == 3:\n",
    "            imgs.append(np.zeros_like(imgs[0], dtype=imgs[0].dtype))\n",
    "        \n",
    "        img = np.empty(shape=(h*2, w*2, c), dtype=imgs[0].dtype)\n",
    "        img[:h, :w, :] = imgs[0]\n",
    "        img[h:, :w, :] = imgs[1]\n",
    "        img[:h, w:, :] = imgs[2]\n",
    "        img[h:, w:, :] = imgs[3]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e96cec8-1822-4129-b5bf-73974ca259a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(preds, counting):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    return torch.sqrt(loss_fn(preds, counting))\n",
    "\n",
    "def metric(preds, biomass):\n",
    "    preds = preds.cpu().numpy()\n",
    "    preds = np.where(preds > 0, preds, 0)\n",
    "    \n",
    "    return mean_squared_error(biomass.cpu().numpy(), preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a1076b-e3c9-4471-8157-cb53260fd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            args.arch, num_classes=1, pretrained=True, **args.extra_params\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beee4655-7297-443f-8bb6-37aa6e95c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, imagesPath, df, tfms=None, phase='test'):\n",
    "        self.imagespath = imagesPath\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "        self.default_tfms = get_common_transforms(args.img_size)\n",
    "        self.mosaic = args.mosaic\n",
    "        self.mosaic_aug = args.mosaic_aug\n",
    "        self.mosaic_tfms = get_mosaic_transforms()\n",
    "        self.length = len(self.df)\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def _read_image(self, idx):\n",
    "        imagename, label, *z = self.df.iloc[idx].values\n",
    "        path = os.path.join(self.imagespath, imagename)\n",
    "        if not os.path.exists(path):\n",
    "            path = os.path.join('./data/TreeImagesCombo/', imagename)\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self._read_image(idx)\n",
    "        \n",
    "        if self.mosaic and self.phase == 'train':\n",
    "            n_image = np.random.choice([0, 1])\n",
    "            if n_image != 0:\n",
    "                idxs = np.random.randint(self.length, size=n_image)\n",
    "                images = [image]\n",
    "                for i in idxs:\n",
    "                    img, i_label = self._read_image(i)\n",
    "                    if self.mosaic_aug:\n",
    "                        img = self.mosaic_tfms(image=img)['image']\n",
    "                        \n",
    "                    images.append(img)\n",
    "                    label += i_label\n",
    "                \n",
    "                image = mosaic(images)\n",
    "        \n",
    "        if self.tfms is not None:\n",
    "            image = self.tfms(image=image)['image']\n",
    "        \n",
    "        image = self.default_tfms(image=image)['image']\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        image = torch.permute(image, (2, 0, 1))\n",
    "        \n",
    "        return image, torch.tensor([label], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20ef3c9e-8251-4957-a9d8-0bb7b9a0fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    model = TreeCountingModel(args)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b07ec777-b1fa-4a48-9c64-152e298b287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(args, df, path='folds/'):\n",
    "    os.makedirs(\"folds/\", exist_ok=True)\n",
    "    os.makedirs(f\"folds/{args.n_split}_splits/\", exist_ok=True)\n",
    "    \n",
    "    all_splits = {}\n",
    "    fold_path = f\"folds/{args.n_split}_splits/\"\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    to_drop = ['Id_u45dpub99b.png', 'Id_kzuy1er5jm.png', 'Id_lp4yl8q9n2.png', 'Id_2r2259ynzp.png', 'Id_w4fnd54go8.png', 'Id_lh8b1k1lx8.png', 'Id_hmcnf15rll.png']\n",
    "    hard_ids = ['Id_scf1bqac43.png', 'Id_uhcehdmyc1.png', 'Id_y87obok3v0.png', 'Id_kx60b4dgn2.png', 'Id_85992p4se2.png', 'Id_g7fbxrng46.png',\n",
    "           'Id_tz74cy4nh9.png', 'Id_u2dzh57wmf.png', 'Id_n0ipc9o8el.png', 'Id_lvua92vvg5.png', 'Id_ibrflyue8t.png', 'Id_xi61ipimpj.png',\n",
    "           'Id_tn748l5k57.png', 'Id_63zqtghlbi.png', 'Id_9xwykwajjb.png', 'Id_owxhn1zmlh.png', 'Id_6ls94ewz47.png', 'Id_upua3g7q2q.png',\n",
    "           'Id_eza4ic1a4k.png', 'Id_jxu8riswpw.png', 'Id_4nuo9gc80n.png', 'Id_rkm6vwm0md.png', 'Id_2goic5xoft.png', 'Id_234nhwag1a.png',\n",
    "           'Id_842atkbl2g.png', 'Id_v9gmdly1tl.png', 'Id_7evqslin0q.png', 'Id_5jgknuixmg.png', 'Id_8bhp0orrri.png', 'Id_yyvlvcursz.png',\n",
    "           'Id_kbgnlekbjm.png', 'Id_kd9m5eoeuf.png', 'Id_h0f091di0y.png', 'Id_scf4jxhlfg.png', 'Id_8xuqs2ut71.png', 'Id_4x0zh3y93q.png',\n",
    "           'Id_oamy4tybj9.png', 'Id_8q73x3g38y.png', 'Id_k0c89tgg4c.png', 'Id_niwpztq309.png', 'Id_r405nptkvd.png'\n",
    "    ]\n",
    "    df_hard = df_clean[df_clean.ImageId.isin(hard_ids)].reset_index(drop=True)\n",
    "    df_clean = df_clean[~df_clean.ImageId.isin(to_drop+hard_ids)].reset_index(drop=True)\n",
    "    \n",
    "    kf = StratifiedKFold(args.n_split, shuffle=True, random_state=42)\n",
    "    \n",
    "    num_bins = int(np.floor(1 + np.log2(len(df_clean))))\n",
    "    bins = pd.cut(df_clean['Target'], bins=num_bins, labels=False)\n",
    "        \n",
    "    print('Num bins:', num_bins)\n",
    "    \n",
    "    for f, (tr_idx, vr_idx) in enumerate(kf.split(df_clean, bins)):\n",
    "        all_splits[f] = {\n",
    "          'train': pd.concat([ df_clean.iloc[tr_idx], df_hard]).sample(frac=1),\n",
    "          'val': df_clean.iloc[vr_idx],\n",
    "        }\n",
    "        \n",
    "        df_clean.iloc[vr_idx].to_csv(f\"{fold_path}fold_{f}.csv\", index=False)\n",
    "\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccd222f9-e3e1-4398-994b-33637be80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._time = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._time = time()\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return (time() - self._time) / 60\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5267b313-81a8-4d56-9042-2db614934797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fn(args, dataloader, model, opt, epoch, accelerator, scheduler=None):    \n",
    "    avg_loss = 0\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    timer.start()\n",
    "    for i, (x, counting) in enumerate(dataloader):\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, counting)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        score = metric(preds.detach().float(), counting.detach())\n",
    "        meter.update(score)\n",
    "\n",
    "        if scheduler is not None and args.schedule not in ['plateau']:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(('\\r[Training][{}/{}][{:.2f} min] Epoch {} : Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "        i+1, size, timer.time, epoch, avg_loss/(i+1), meter.avg\n",
    "        ), end='')\n",
    "    print()\n",
    "\n",
    "################## evaluation Function ####################   \n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    avg_loss = 0\n",
    "\n",
    "    all_logits = []\n",
    "    all_masks = []\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    timer.start()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, counting) in enumerate(dataloader):\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, counting)\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            score = metric(preds.detach().float(), counting.detach().float())\n",
    "            meter.update(score)\n",
    "\n",
    "            print(('\\r[Evaluation][{}/{}][{:.2f} min] Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "            i+1, size, timer.time, avg_loss/(i+1), meter.avg\n",
    "            ), end='')\n",
    "    print()\n",
    "\n",
    "    return avg_loss/size, meter.avg\n",
    "\n",
    "################## Run training over folds Function ####################   \n",
    "def release_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def run_fold(fold, args, path='./models'):\n",
    "    model_path = f'{path}/{args.arch}-{args.n_split}-{args.img_size}-{args.lr}-{args.bs}'\n",
    "    if fold == 0:\n",
    "        mid = len(glob(model_path+'*'))\n",
    "        model_path += f'-{mid}'\n",
    "        os.makedirs(model_path, exist_ok=False)\n",
    "        \n",
    "        print('Model path:', model_path)\n",
    "    else:\n",
    "        model_id = sorted([int(x.replace(model_path+'-', '')) for x in glob(f'{model_path}*')])[-1]\n",
    "        model_path = f'{model_path}-{model_id}'\n",
    "    \n",
    "    best_metric = np.inf\n",
    "    best_loss = np.inf\n",
    "   \n",
    "\n",
    "    train_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['train'],\n",
    "        tfms=get_train_transforms(),\n",
    "        phase='train'\n",
    "    )\n",
    "    val_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['val'],\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(train_ds, batch_size=args.bs, num_workers=args.workers, pin_memory=True, shuffle=True)\n",
    "    validloader = DataLoader(val_ds, batch_size=args.ebs, num_workers=args.workers, pin_memory=True, shuffle=False)\n",
    "\n",
    "    accelerator = Accelerator(fp16=args.fp16)\n",
    "\n",
    "    model = get_model(args)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "    num_train_steps = int(len(trainloader) * args.epochs)\n",
    "    steps_per_epoch = len(trainloader)\n",
    "\n",
    "    scheduler = None\n",
    "    if args.schedule:\n",
    "        scheduler = CosineAnnealingLR(opt, T_max=num_train_steps, eta_min=args.min_lr)\n",
    "        model, scheduler, opt, trainloader, validloader = accelerator.prepare(model, scheduler, opt, trainloader, validloader)\n",
    "    else:\n",
    "        model, opt, trainloader, validloader = accelerator.prepare(model, opt, trainloader, validloader)\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    loader = tqdm(range(args.epochs), desc=f'Fold {fold}')\n",
    "\n",
    "    for epoch in loader:\n",
    "        training_fn(args, trainloader, model, opt, epoch, accelerator, scheduler)\n",
    "        avg_loss, avg_metric = evaluate(validloader, model)\n",
    "\n",
    "        if scheduler is not None and args.schedule in ['plateau']:\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "        if avg_metric < best_metric:\n",
    "            best_loss = avg_loss\n",
    "            best_metric = avg_metric\n",
    "\n",
    "            torch.save(model.state_dict(), f'{model_path}/best_{fold}.pt')\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(f\"Best Fold --- Loss score: {best_loss} - F1 Score {best_metric}\")\n",
    "\n",
    "    # Clean up\n",
    "    del trainloader, validloader\n",
    "    del model, opt\n",
    "    release_memory()\n",
    "\n",
    "    return best_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de588c-aabf-4134-b3a3-c208e25b642b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "412e0d03-2e54-4789-95e1-fe31af84a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu count: 12\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    arch = 'seresnet152d'\n",
    "    lr = 5e-4\n",
    "    min_lr = 0\n",
    "    wd = 1e-6\n",
    "    epochs = 20\n",
    "    warmup = 0.\n",
    "    bs = 24\n",
    "    ebs = 2 * bs\n",
    "    \n",
    "    n_split = 5\n",
    "    use_folds = list(range(n_split))\n",
    "    actual_split = len(use_folds)\n",
    "\n",
    "    img_size = 1024\n",
    "    \n",
    "    tta_tfms = []\n",
    "\n",
    "    schedule = True\n",
    "    augment = True\n",
    "    mosaic = False\n",
    "    mosaic_aug = False\n",
    "\n",
    "    fp16 = True\n",
    "    workers = os.cpu_count()\n",
    "    \n",
    "    print('Cpu count:', workers)\n",
    "\n",
    "    extra_params = {\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b86583c8-6cf2-4e28-aa6e-ec499c63fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f3852cc-0945-4b1a-952c-7eb289ca9955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num bins: 11\n"
     ]
    }
   ],
   "source": [
    "all_splits = make_splits(args, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f75fcba-e376-45bf-adf6-a33db857737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./models/seresnet152d-5-1024-0.0005-24-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnet152d_ra2-04464dd2.pth\" to /root/.cache/torch/hub/checkpoints/seresnet152d_ra2-04464dd2.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6299e523f64d87829de1b7f766aae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.12 min] Epoch 0 : Loss: 5.73057 - RMSE: 5.7300472\n",
      "[Evaluation][9/9][0.16 min] Loss: 2.30227 - RMSE: 2.30227\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 1 : Loss: 2.68975 - RMSE: 2.68975\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.95413 - RMSE: 1.95412\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 2 : Loss: 2.53179 - RMSE: 2.53178\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.07657 - RMSE: 2.07651\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 3 : Loss: 2.28136 - RMSE: 2.28134\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.00166 - RMSE: 2.00165\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 4 : Loss: 2.18072 - RMSE: 2.18060\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.87095 - RMSE: 1.87081\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 5 : Loss: 1.89850 - RMSE: 1.89815\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.74113 - RMSE: 1.74044\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 6 : Loss: 1.87604 - RMSE: 1.87584\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.66497 - RMSE: 1.66460\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 7 : Loss: 1.76711 - RMSE: 1.76686\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.05438 - RMSE: 2.05390\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 8 : Loss: 1.76772 - RMSE: 1.76723\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.78912 - RMSE: 1.78889\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 9 : Loss: 1.78237 - RMSE: 1.78199\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.61361 - RMSE: 1.61251\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 10 : Loss: 1.65692 - RMSE: 1.65648\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.60158 - RMSE: 1.60074\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 11 : Loss: 1.61293 - RMSE: 1.61235\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.64916 - RMSE: 1.64788\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 12 : Loss: 1.49886 - RMSE: 1.49836\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.92941 - RMSE: 1.92820\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 13 : Loss: 1.40623 - RMSE: 1.40537\n",
      "[Evaluation][9/9][0.11 min] Loss: 2.04990 - RMSE: 2.04821\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 14 : Loss: 1.27995 - RMSE: 1.27894\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.74209 - RMSE: 1.74038\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 15 : Loss: 1.26954 - RMSE: 1.26884\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.93396 - RMSE: 1.93221\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 16 : Loss: 1.19931 - RMSE: 1.19843\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.72680 - RMSE: 1.72506\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 17 : Loss: 1.15241 - RMSE: 1.15157\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.68288 - RMSE: 1.68110\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 18 : Loss: 1.11165 - RMSE: 1.11071\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.73697 - RMSE: 1.73528\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 19 : Loss: 1.10157 - RMSE: 1.10071\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.66296 - RMSE: 1.66129\n",
      "\n",
      "Best Fold --- Loss score: 1.601575705740187 - F1 Score 1.6007442474365234\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f7cfa9ddce4c5295f2f1a1ebeb872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.01 min] Epoch 0 : Loss: 6.17039 - RMSE: 6.1690638\n",
      "[Evaluation][9/9][0.12 min] Loss: 4.37175 - RMSE: 4.37175\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 1 : Loss: 2.68336 - RMSE: 2.68336\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.77648 - RMSE: 1.77648\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 2 : Loss: 2.38422 - RMSE: 2.38422\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.74366 - RMSE: 1.74364\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 3 : Loss: 2.02863 - RMSE: 2.02862\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.70819 - RMSE: 1.70818\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 4 : Loss: 2.18313 - RMSE: 2.18304\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.79528 - RMSE: 1.79512\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 5 : Loss: 1.95426 - RMSE: 1.95372\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.76113 - RMSE: 2.76082\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 6 : Loss: 1.93353 - RMSE: 1.93215\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.80662 - RMSE: 1.80477\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 7 : Loss: 1.83296 - RMSE: 1.83222\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.59969 - RMSE: 1.59921\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 8 : Loss: 1.70918 - RMSE: 1.70863\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.78353 - RMSE: 1.78264\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 9 : Loss: 1.59922 - RMSE: 1.59882\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.46264 - RMSE: 1.46236\n",
      "\n",
      "[Training][67/67][0.99 min] Epoch 10 : Loss: 1.56837 - RMSE: 1.56778\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.44707 - RMSE: 1.44657\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 11 : Loss: 1.55974 - RMSE: 1.55938\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.33647 - RMSE: 1.33577\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 12 : Loss: 1.34949 - RMSE: 1.34923\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.41900 - RMSE: 1.41835\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 13 : Loss: 1.30287 - RMSE: 1.30255\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.32272 - RMSE: 1.32217\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 14 : Loss: 1.22977 - RMSE: 1.22945\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.35393 - RMSE: 1.35353\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 15 : Loss: 1.15250 - RMSE: 1.15211\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.34154 - RMSE: 1.34097\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 16 : Loss: 1.07828 - RMSE: 1.07782\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.36640 - RMSE: 1.36564\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 17 : Loss: 1.06271 - RMSE: 1.06227\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.48629 - RMSE: 1.48565\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 18 : Loss: 1.01509 - RMSE: 1.01460\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.39677 - RMSE: 1.39611\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 19 : Loss: 1.02298 - RMSE: 1.02246\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.37332 - RMSE: 1.37264\n",
      "\n",
      "Best Fold --- Loss score: 1.322720660103692 - F1 Score 1.3221653037601047\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f525957d92c4584a244acb1d2cd5a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.01 min] Epoch 0 : Loss: 5.70239 - RMSE: 5.7023987\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.32562 - RMSE: 2.32562\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 1 : Loss: 2.90170 - RMSE: 2.90170\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.17924 - RMSE: 2.17924\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 2 : Loss: 2.63901 - RMSE: 2.63901\n",
      "[Evaluation][9/9][0.11 min] Loss: 3.46196 - RMSE: 3.46196\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 3 : Loss: 2.33036 - RMSE: 2.33036\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.49258 - RMSE: 1.49258\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 4 : Loss: 2.14495 - RMSE: 2.14493\n",
      "[Evaluation][9/9][0.11 min] Loss: 2.12554 - RMSE: 2.12551\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 5 : Loss: 1.91154 - RMSE: 1.91149\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.48348 - RMSE: 1.48345\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 6 : Loss: 1.88618 - RMSE: 1.88614\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.38670 - RMSE: 1.38660\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 7 : Loss: 1.67409 - RMSE: 1.67390\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.51514 - RMSE: 1.51462\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 8 : Loss: 1.77881 - RMSE: 1.77851\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.44197 - RMSE: 1.44172\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 9 : Loss: 1.58172 - RMSE: 1.58157\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.03662 - RMSE: 2.03639\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 10 : Loss: 1.60317 - RMSE: 1.60295\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.31649 - RMSE: 1.31584\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 11 : Loss: 1.48588 - RMSE: 1.48544\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.38122 - RMSE: 1.38089\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 12 : Loss: 1.45231 - RMSE: 1.45191\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.53305 - RMSE: 1.53236\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 13 : Loss: 1.33799 - RMSE: 1.33758\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.28069 - RMSE: 1.27980\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 14 : Loss: 1.23518 - RMSE: 1.23465\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.23362 - RMSE: 1.23317\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 15 : Loss: 1.18715 - RMSE: 1.18648\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.33814 - RMSE: 1.33712\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 16 : Loss: 1.14057 - RMSE: 1.14003\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.26621 - RMSE: 1.26555\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 17 : Loss: 1.04981 - RMSE: 1.04897\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.27205 - RMSE: 1.27134\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 18 : Loss: 1.02966 - RMSE: 1.02907\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.28081 - RMSE: 1.28012\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 19 : Loss: 1.01908 - RMSE: 1.01843\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.25951 - RMSE: 1.25880\n",
      "\n",
      "Best Fold --- Loss score: 1.2336154911253188 - F1 Score 1.2331702179378934\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf333644b364ed68b1f6ce52c781045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.02 min] Epoch 0 : Loss: 5.84280 - RMSE: 5.8426731\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.87386 - RMSE: 2.87386\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 1 : Loss: 3.10348 - RMSE: 3.10348\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.69054 - RMSE: 1.69054\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 2 : Loss: 2.40421 - RMSE: 2.40419\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.67365 - RMSE: 1.67365\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 3 : Loss: 2.39659 - RMSE: 2.39656\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.67212 - RMSE: 1.67191\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 4 : Loss: 1.98476 - RMSE: 1.98463\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.72004 - RMSE: 1.71977\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 5 : Loss: 2.06976 - RMSE: 2.06964\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.74030 - RMSE: 1.73988\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 6 : Loss: 1.92516 - RMSE: 1.92494\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.60464 - RMSE: 1.60418\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 7 : Loss: 1.89011 - RMSE: 1.88976\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.81764 - RMSE: 1.81712\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 8 : Loss: 1.73762 - RMSE: 1.73724\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.60125 - RMSE: 1.60042\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 9 : Loss: 1.66887 - RMSE: 1.66840\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.69117 - RMSE: 1.69025\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 10 : Loss: 1.64102 - RMSE: 1.64021\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.56222 - RMSE: 1.56109\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 11 : Loss: 1.64704 - RMSE: 1.64636\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.45079 - RMSE: 1.44987\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 12 : Loss: 1.39852 - RMSE: 1.39767\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.43103 - RMSE: 1.43025\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 13 : Loss: 1.40566 - RMSE: 1.40466\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.45852 - RMSE: 1.45738\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 14 : Loss: 1.27269 - RMSE: 1.27169\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.77383 - RMSE: 1.77312\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 15 : Loss: 1.16053 - RMSE: 1.16002\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.33966 - RMSE: 1.33879\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 16 : Loss: 1.13203 - RMSE: 1.13141\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.39773 - RMSE: 1.39711\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 17 : Loss: 1.04620 - RMSE: 1.04558\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.33306 - RMSE: 1.33264\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 18 : Loss: 1.04217 - RMSE: 1.04168\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.33707 - RMSE: 1.33651\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 19 : Loss: 1.05150 - RMSE: 1.05109\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.34659 - RMSE: 1.34611\n",
      "\n",
      "Best Fold --- Loss score: 1.333061350716485 - F1 Score 1.3326427274280124\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42c596167294fd2b56db20c71ea510f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][1.02 min] Epoch 0 : Loss: 5.38365 - RMSE: 5.3836501\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.48500 - RMSE: 2.48500\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 1 : Loss: 3.15165 - RMSE: 3.15165\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.79706 - RMSE: 1.79706\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 2 : Loss: 2.35033 - RMSE: 2.35029\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.76246 - RMSE: 1.76190\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 3 : Loss: 2.15078 - RMSE: 2.15069\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.91593 - RMSE: 1.91585\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 4 : Loss: 2.28176 - RMSE: 2.28123\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.02925 - RMSE: 2.02766\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 5 : Loss: 1.96411 - RMSE: 1.96344\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.43031 - RMSE: 1.42997\n",
      "\n",
      "[Training][67/67][1.03 min] Epoch 6 : Loss: 1.87776 - RMSE: 1.87688\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.68136 - RMSE: 1.68070\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 7 : Loss: 1.85537 - RMSE: 1.85472\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.65186 - RMSE: 1.65031\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 8 : Loss: 1.67857 - RMSE: 1.67743\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.85956 - RMSE: 1.85910\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 9 : Loss: 1.69000 - RMSE: 1.68956\n",
      "[Evaluation][9/9][0.13 min] Loss: 2.02974 - RMSE: 2.02939\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 10 : Loss: 1.58743 - RMSE: 1.58690\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.56664 - RMSE: 1.56520\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 11 : Loss: 1.40090 - RMSE: 1.40026\n",
      "[Evaluation][9/9][0.14 min] Loss: 1.35603 - RMSE: 1.35520\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 12 : Loss: 1.50264 - RMSE: 1.50155\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.38473 - RMSE: 1.38354\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 13 : Loss: 1.32176 - RMSE: 1.32028\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.31533 - RMSE: 1.31214\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 14 : Loss: 1.24188 - RMSE: 1.24078\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.69833 - RMSE: 1.69645\n",
      "\n",
      "[Training][67/67][1.00 min] Epoch 15 : Loss: 1.20381 - RMSE: 1.20296\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.22770 - RMSE: 1.22735\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 16 : Loss: 1.07491 - RMSE: 1.07452\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.26095 - RMSE: 1.26030\n",
      "\n",
      "[Training][67/67][1.01 min] Epoch 17 : Loss: 1.10621 - RMSE: 1.10569\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.28480 - RMSE: 1.28399\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 18 : Loss: 1.05361 - RMSE: 1.05301\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.31984 - RMSE: 1.31891\n",
      "\n",
      "[Training][67/67][1.02 min] Epoch 19 : Loss: 1.07083 - RMSE: 1.07016\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.47006 - RMSE: 1.46898\n",
      "\n",
      "Best Fold --- Loss score: 1.2277041011386447 - F1 Score 1.2273485859235127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "\n",
    "for f in args.use_folds:\n",
    "    fold_score = run_fold(f, args)\n",
    "    avg_score += (fold_score / args.actual_split)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c58122eb-2391-4274-83e1-ee953aaa1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3432142164972094"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951cb824-9570-422d-a864-d34cbbe973a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
