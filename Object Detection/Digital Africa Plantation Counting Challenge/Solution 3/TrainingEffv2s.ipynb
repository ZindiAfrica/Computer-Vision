{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a239eea-e414-412d-9242-d7316e9cc18d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5833a3bb-192d-46b4-80ac-f7e3b03e17cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "radiant-mlhub==0.4.1\n",
    "rasterio\n",
    "shapely\n",
    "accelerate==0.15.0\n",
    "albumentations==1.3.0\n",
    "timm==0.6.12\n",
    "watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a7fcd7-eb6b-4ee8-8f57-ff5a443c78d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q torch==1.13.1 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6eb2fe-f515-471e-8ae3-1aae649d697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c866a9c-6192-4cf1-b8e7-1b96c98953f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1961ba0b-d202-4477-8004-63b1c5e5ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 11 14:17:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 35%   54C    P8    24W / 300W |      0MiB / 49140MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a20d7-05ea-4951-a079-08c8b8a71940",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16825bfc-8853-445c-9e6c-53395bea41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time, sleep\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from glob import glob\n",
    "import warnings\n",
    "\n",
    "import shutil\n",
    "\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b9b22b-0a41-44b0-beec-e050afbeaa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset as TDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR, CosineAnnealingLR\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.geometric.transforms as AG\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a120b4-51ef-49dc-9748-873fbd66e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib    : 3.6.1\n",
      "timm          : 0.6.12\n",
      "cv2           : 4.7.0\n",
      "numpy         : 1.23.4\n",
      "albumentations: 1.3.0\n",
      "PIL           : 9.2.0\n",
      "torch         : 1.13.1+cu116\n",
      "pandas        : 1.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563effdb-c378-45ba-8f7e-8d7cc8bf8b08",
   "metadata": {},
   "source": [
    "# Envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db742f8-2be3-47d5-bd7b-82629ce77866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_warnings(strict=False):\n",
    "\twarnings.simplefilter('ignore')\n",
    "\tif strict:\n",
    "\t\tlogging.disable(logging.WARNING)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.backends.cudnn.deterministic = True\n",
    "\ttorch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01b0cb9-83b7-46c0-8383-c9384772e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "disable_warnings()\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7fe6b-98d6-4d75-9912-bf1bf44b6643",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe357fad-adaf-4b32-8c8a-3bfba4d57170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_jdqw9hlv6j.png</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_6xtrolmuvc.png</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_2m49sj3xd9.png</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_9jwg5pcnn4.png</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_vnm6e8n0p3.png</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_jdqw9hlv6j.png    14.0\n",
       "1  Id_6xtrolmuvc.png    18.0\n",
       "2  Id_2m49sj3xd9.png     0.0\n",
       "3  Id_9jwg5pcnn4.png    28.0\n",
       "4  Id_vnm6e8n0p3.png    21.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load files\n",
    "data_path = './data/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "sample_submission = pd.read_csv(data_path + 'SampleSubmission.csv')\n",
    "\n",
    "# Preview train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d2ead2-2302-480b-82b6-37346e9e07ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId\n",
       "0  Id_ohk78h9ld8.png\n",
       "1  Id_eeyj2u4j7y.png\n",
       "2  Id_wsd7vx2ifa.png\n",
       "3  Id_6vfneamaoh.png\n",
       "4  Id_9wil3575fv.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd40436e-a4f4-4823-99b3-8ff6c05636de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Id_ohk78h9ld8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Id_eeyj2u4j7y.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Id_wsd7vx2ifa.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Id_6vfneamaoh.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Id_9wil3575fv.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ImageId  Target\n",
       "0  Id_ohk78h9ld8.png       0\n",
       "1  Id_eeyj2u4j7y.png       0\n",
       "2  Id_wsd7vx2ifa.png       0\n",
       "3  Id_6vfneamaoh.png       0\n",
       "4  Id_9wil3575fv.png       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview sample submission\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c4eea-ebba-4afe-8bde-2f37646bfb13",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46cb191-2de4-4698-ace9-95cabd8475a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paralellize(fct, data, verbose=0, with_tqdm=True):\n",
    "    fn = map(delayed(fct), data)\n",
    "    if with_tqdm:\n",
    "        fn = tqdm(fn, total=len(data))\n",
    "    return Parallel(n_jobs=-1, verbose=verbose, backend=\"multiprocessing\")(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b524d68-7b88-4242-84d1-9015f40cf798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_transforms(size):\n",
    "    return A.Compose([\n",
    "      A.Resize(height=size, width=size, p=1),\n",
    "    ])\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(),\n",
    "            A.MedianBlur(blur_limit=3),\n",
    "            A.Blur(blur_limit=3),\n",
    "        ]),\n",
    "    ])\n",
    "\n",
    "def get_mosaic_transforms():\n",
    "    return A.Compose([\n",
    "        A.Flip(),\n",
    "        A.RandomRotate90(),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.0625, scale_limit=(-0.3, -0.2), rotate_limit=45, interpolation=1, border_mode=0, value=0, p=0.2\n",
    "        )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452cbcd5-7bd3-43ed-98a4-ab216baaacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "def get_combos(ids, n=4) :\n",
    "    combos = []\n",
    "    size = len(ids)\n",
    "    \n",
    "    for i in range(0, size - n, 1):\n",
    "        combos.append(ids[i:i+n])\n",
    "    return combos\n",
    "\n",
    "def _combo_image_saver(ids_list):\n",
    "    save_path = './data/TreeImagesCombo/'\n",
    "    \n",
    "    images = [\n",
    "        Image.open(f'./data/TreeImages/{p}') for p in ids_list\n",
    "    ]\n",
    "\n",
    "    img = get_concat_h(*images[:2])\n",
    "\n",
    "    if len(ids_list) == 4:\n",
    "        img = get_concat_v(\n",
    "            img,\n",
    "            get_concat_h(*images[2:])\n",
    "        )\n",
    "\n",
    "    ids_list = [p.split('.')[0] for p in ids_list]\n",
    "    path = save_path + '|'.join(ids_list) + '.png'\n",
    "\n",
    "    img.save(path)\n",
    "\n",
    "def concat_mix_up(zeros_ids, palm_ids, n=4):\n",
    "    np.random.shuffle(zeros_ids)\n",
    "    np.random.shuffle(palm_ids)\n",
    "    \n",
    "    palm_combos = []\n",
    "    if n != -1:\n",
    "        palm_combos = get_combos(palm_ids, n=n)\n",
    "    \n",
    "    new_palm_combos = list(zip(zeros_ids, palm_ids))\n",
    "    new_palm_combos = [list(x) for x in new_palm_combos]\n",
    "    \n",
    "    _ = paralellize(_combo_image_saver, palm_combos + new_palm_combos)\n",
    "    \n",
    "    print(f'New {len(palm_combos + new_palm_combos)} images generated')\n",
    "    \n",
    "    return palm_combos + new_palm_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b207baa-60de-4d48-a281-1e71d56f3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mosaic(imgs):\n",
    "    size = len(imgs)\n",
    "    h, w, c = imgs[0].shape\n",
    "    \n",
    "    assert 1 <= size <= 4, f'size is {size}'\n",
    "    \n",
    "    if size == 1:\n",
    "        img = imgs[0]\n",
    "    elif size == 2:\n",
    "        img = np.empty(shape=(h, w*size, c), dtype=imgs[0].dtype)\n",
    "        img[:, :w, :] = imgs[0]\n",
    "        img[:, w:, :] = imgs[1]\n",
    "    else:\n",
    "        if size == 3:\n",
    "            imgs.append(np.zeros_like(imgs[0], dtype=imgs[0].dtype))\n",
    "        \n",
    "        img = np.empty(shape=(h*2, w*2, c), dtype=imgs[0].dtype)\n",
    "        img[:h, :w, :] = imgs[0]\n",
    "        img[h:, :w, :] = imgs[1]\n",
    "        img[:h, w:, :] = imgs[2]\n",
    "        img[h:, w:, :] = imgs[3]\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e96cec8-1822-4129-b5bf-73974ca259a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(preds, biomass):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    return torch.sqrt(loss_fn(preds, biomass))\n",
    "\n",
    "def metric(preds, biomass):\n",
    "    preds = preds.cpu().numpy()\n",
    "    preds = np.where(preds > 0, preds, 0)\n",
    "    \n",
    "    return mean_squared_error(biomass.cpu().numpy(), preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a1076b-e3c9-4471-8157-cb53260fd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            args.arch, num_classes=1, pretrained=True, **args.extra_params\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beee4655-7297-443f-8bb6-37aa6e95c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeCountingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, args, imagesPath, df, tfms=None, phase='test'):\n",
    "        self.imagespath = imagesPath\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "        self.default_tfms = get_common_transforms(args.img_size)\n",
    "        self.mosaic = args.mosaic\n",
    "        self.mosaic_aug = args.mosaic_aug\n",
    "        self.mosaic_tfms = get_mosaic_transforms()\n",
    "        self.length = len(self.df)\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def _read_image(self, idx):\n",
    "        imagename, label, *z = self.df.iloc[idx].values\n",
    "        path = os.path.join(self.imagespath, imagename)\n",
    "        if not os.path.exists(path):\n",
    "            path = os.path.join('./data/TreeImagesCombo/', imagename)\n",
    "        image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self._read_image(idx)\n",
    "        \n",
    "        if self.mosaic and self.phase == 'train':\n",
    "            n_image = np.random.choice([0, 1])\n",
    "            if n_image != 0:\n",
    "                idxs = np.random.randint(self.length, size=n_image)\n",
    "                images = [image]\n",
    "                for i in idxs:\n",
    "                    img, i_label = self._read_image(i)\n",
    "                    if self.mosaic_aug:\n",
    "                        img = self.mosaic_tfms(image=img)['image']\n",
    "                        \n",
    "                    images.append(img)\n",
    "                    label += i_label\n",
    "                \n",
    "                image = mosaic(images)\n",
    "        \n",
    "        if self.tfms is not None:\n",
    "            image = self.tfms(image=image)['image']\n",
    "        \n",
    "        image = self.default_tfms(image=image)['image']\n",
    "        image = torch.tensor(image, dtype=torch.float)\n",
    "        image = torch.permute(image, (2, 0, 1))\n",
    "        \n",
    "        return image, torch.tensor([label], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ef3c9e-8251-4957-a9d8-0bb7b9a0fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(args):\n",
    "    model = TreeCountingModel(args)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b07ec777-b1fa-4a48-9c64-152e298b287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_splits(args, df, path='folds/'):\n",
    "    os.makedirs(\"folds/\", exist_ok=True)\n",
    "    os.makedirs(f\"folds/{args.n_split}_splits/\", exist_ok=True)\n",
    "    \n",
    "    all_splits = {}\n",
    "    fold_path = f\"folds/{args.n_split}_splits/\"\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    to_drop = ['Id_u45dpub99b.png', 'Id_kzuy1er5jm.png', 'Id_lp4yl8q9n2.png', 'Id_2r2259ynzp.png', 'Id_w4fnd54go8.png', 'Id_lh8b1k1lx8.png', 'Id_hmcnf15rll.png']\n",
    "    hard_ids = ['Id_scf1bqac43.png', 'Id_uhcehdmyc1.png', 'Id_y87obok3v0.png', 'Id_kx60b4dgn2.png', 'Id_85992p4se2.png', 'Id_g7fbxrng46.png',\n",
    "           'Id_tz74cy4nh9.png', 'Id_u2dzh57wmf.png', 'Id_n0ipc9o8el.png', 'Id_lvua92vvg5.png', 'Id_ibrflyue8t.png', 'Id_xi61ipimpj.png',\n",
    "           'Id_tn748l5k57.png', 'Id_63zqtghlbi.png', 'Id_9xwykwajjb.png', 'Id_owxhn1zmlh.png', 'Id_6ls94ewz47.png', 'Id_upua3g7q2q.png',\n",
    "           'Id_eza4ic1a4k.png', 'Id_jxu8riswpw.png', 'Id_4nuo9gc80n.png', 'Id_rkm6vwm0md.png', 'Id_2goic5xoft.png', 'Id_234nhwag1a.png',\n",
    "           'Id_842atkbl2g.png', 'Id_v9gmdly1tl.png', 'Id_7evqslin0q.png', 'Id_5jgknuixmg.png', 'Id_8bhp0orrri.png', 'Id_yyvlvcursz.png',\n",
    "           'Id_kbgnlekbjm.png', 'Id_kd9m5eoeuf.png', 'Id_h0f091di0y.png', 'Id_scf4jxhlfg.png', 'Id_8xuqs2ut71.png', 'Id_4x0zh3y93q.png',\n",
    "           'Id_oamy4tybj9.png', 'Id_8q73x3g38y.png', 'Id_k0c89tgg4c.png', 'Id_niwpztq309.png', 'Id_r405nptkvd.png'\n",
    "    ]\n",
    "    df_hard = df_clean[df_clean.ImageId.isin(hard_ids)].reset_index(drop=True)\n",
    "    df_clean = df_clean[~df_clean.ImageId.isin(to_drop+hard_ids)].reset_index(drop=True)\n",
    "    \n",
    "    kf = StratifiedKFold(args.n_split, shuffle=True, random_state=42)\n",
    "    \n",
    "    num_bins = int(np.floor(1 + np.log2(len(df_clean))))\n",
    "    bins = pd.cut(df_clean['Target'], bins=num_bins, labels=False)\n",
    "        \n",
    "    print('Num bins:', num_bins)\n",
    "    \n",
    "    for f, (tr_idx, vr_idx) in enumerate(kf.split(df_clean, bins)):\n",
    "        all_splits[f] = {\n",
    "          'train': pd.concat([ df_clean.iloc[tr_idx], df_hard]).sample(frac=1),\n",
    "          'val': df_clean.iloc[vr_idx],\n",
    "        }\n",
    "        \n",
    "        df_clean.iloc[vr_idx].to_csv(f\"folds/{args.n_split}_splits/fold_{f}.csv\", index=False)\n",
    "\n",
    "    return all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccd222f9-e3e1-4398-994b-33637be80614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._time = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._time = time()\n",
    "\n",
    "    @property\n",
    "    def time(self):\n",
    "        return (time() - self._time) / 60\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5267b313-81a8-4d56-9042-2db614934797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_fn(args, dataloader, model, opt, epoch, accelerator, scheduler=None):    \n",
    "    avg_loss = 0\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    timer.start()\n",
    "    for i, (x, biomass) in enumerate(dataloader):\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, biomass)\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        accelerator.backward(loss)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        score = metric(preds.detach().float(), biomass.detach())\n",
    "        meter.update(score)\n",
    "\n",
    "        if scheduler is not None and args.schedule not in ['plateau']:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(('\\r[Training][{}/{}][{:.2f} min] Epoch {} : Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "        i+1, size, timer.time, epoch, avg_loss/(i+1), meter.avg\n",
    "        ), end='')\n",
    "    print()\n",
    "\n",
    "################## evaluation Function ####################   \n",
    "\n",
    "def evaluate(dataloader, model):\n",
    "    avg_loss = 0\n",
    "\n",
    "    all_logits = []\n",
    "    all_masks = []\n",
    "\n",
    "    size = len(dataloader)\n",
    "    timer = Timer()\n",
    "    meter = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    timer.start()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, biomass) in enumerate(dataloader):\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, biomass)\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            score = metric(preds.detach().float(), biomass.detach().float())\n",
    "            meter.update(score)\n",
    "\n",
    "            print(('\\r[Evaluation][{}/{}][{:.2f} min] Loss: {:.5f} - RMSE: {:.5f}').format(\n",
    "            i+1, size, timer.time, avg_loss/(i+1), meter.avg\n",
    "            ), end='')\n",
    "    print()\n",
    "\n",
    "    return avg_loss/size, meter.avg\n",
    "\n",
    "################## Run training over folds Function ####################   \n",
    "def release_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "def run_fold(fold, args, path='./models'):\n",
    "    model_path = f'{path}/{args.arch}-{args.n_split}-{args.img_size}-{args.lr}-{args.bs}'\n",
    "    if fold == 0:\n",
    "        mid = len(glob(model_path+'*'))\n",
    "        model_path += f'-{mid}'\n",
    "        os.makedirs(model_path, exist_ok=False)\n",
    "        \n",
    "        print('Model path:', model_path)\n",
    "    else:\n",
    "        model_id = sorted([int(x.replace(model_path+'-', '')) for x in glob(f'{model_path}*')])[-1]\n",
    "        model_path = f'{model_path}-{model_id}'\n",
    "    \n",
    "    best_metric = np.inf\n",
    "    best_loss = np.inf\n",
    "\n",
    "    train_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['train'],\n",
    "        tfms=get_train_transforms(),\n",
    "        phase='train'\n",
    "    )\n",
    "    val_ds = TreeCountingDataset(\n",
    "        args,\n",
    "        imagesPath='./data/TreeImages/',\n",
    "        df=all_splits[fold]['val'],\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(train_ds, batch_size=args.bs, num_workers=args.workers, pin_memory=True, shuffle=True)\n",
    "    validloader = DataLoader(val_ds, batch_size=args.ebs, num_workers=args.workers, pin_memory=True, shuffle=False)\n",
    "\n",
    "    accelerator = Accelerator(fp16=args.fp16)\n",
    "\n",
    "    model = get_model(args)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "\n",
    "    num_train_steps = int(len(trainloader) * args.epochs)\n",
    "    steps_per_epoch = len(trainloader)\n",
    "\n",
    "    scheduler = None\n",
    "    if args.schedule:\n",
    "        scheduler = CosineAnnealingLR(opt, T_max=num_train_steps, eta_min=args.min_lr)\n",
    "        model, scheduler, opt, trainloader, validloader = accelerator.prepare(model, scheduler, opt, trainloader, validloader)\n",
    "    else:\n",
    "        model, opt, trainloader, validloader = accelerator.prepare(model, opt, trainloader, validloader)\n",
    "\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    loader = tqdm(range(args.epochs), desc=f'Fold {fold}')\n",
    "\n",
    "    for epoch in loader:\n",
    "        training_fn(args, trainloader, model, opt, epoch, accelerator, scheduler)\n",
    "        avg_loss, avg_metric = evaluate(validloader, model)\n",
    "\n",
    "        if scheduler is not None and args.schedule in ['plateau']:\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "        if avg_metric < best_metric:\n",
    "            best_loss = avg_loss\n",
    "            best_metric = avg_metric\n",
    "\n",
    "            torch.save(model.state_dict(), f'{model_path}/best_{fold}.pt')\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(f\"Best Fold --- Loss score: {best_loss} - F1 Score {best_metric}\")\n",
    "\n",
    "    # Clean up\n",
    "    del trainloader, validloader\n",
    "    del model, opt\n",
    "    release_memory()\n",
    "\n",
    "    return best_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de588c-aabf-4134-b3a3-c208e25b642b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412e0d03-2e54-4789-95e1-fe31af84a5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cpu count: 8\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    arch = 'tf_efficientnetv2_s_in21ft1k'\n",
    "    lr = 5e-4\n",
    "    min_lr = 0\n",
    "    wd = 1e-6\n",
    "    epochs = 20\n",
    "    warmup = 0.\n",
    "    bs = 24\n",
    "    ebs = 2 * bs\n",
    "    \n",
    "    n_split = 5\n",
    "    use_folds = list(range(n_split))\n",
    "    actual_split = len(use_folds)\n",
    "\n",
    "    img_size = 1024\n",
    "    \n",
    "    tta_tfms = []\n",
    "\n",
    "    schedule = True\n",
    "    augment = True\n",
    "    mosaic = False\n",
    "    mosaic_aug = False\n",
    "\n",
    "    fp16 = True\n",
    "    workers = os.cpu_count()\n",
    "    \n",
    "    print('Cpu count:', workers)\n",
    "\n",
    "    extra_params = {\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b86583c8-6cf2-4e28-aa6e-ec499c63fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = CFG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f3852cc-0945-4b1a-952c-7eb289ca9955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num bins: 11\n"
     ]
    }
   ],
   "source": [
    "all_splits = make_splits(args, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f75fcba-e376-45bf-adf6-a33db857737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: ./models/tf_efficientnetv2_s_in21ft1k-5-1024-0.0005-24-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba498be5b8d4396ba83640936985645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][0.94 min] Epoch 0 : Loss: 8.44200 - RMSE: 7.8175335\n",
      "[Evaluation][9/9][0.17 min] Loss: 4.22669 - RMSE: 4.21409\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 1 : Loss: 4.36931 - RMSE: 4.21855\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.66122 - RMSE: 2.59908\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 2 : Loss: 3.16822 - RMSE: 3.11379\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.07877 - RMSE: 2.04738\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 3 : Loss: 2.65216 - RMSE: 2.60209\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.98933 - RMSE: 1.93146\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 4 : Loss: 2.19283 - RMSE: 2.16117\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.68448 - RMSE: 1.67476\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 5 : Loss: 2.34059 - RMSE: 2.31581\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.77751 - RMSE: 1.76051\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 6 : Loss: 1.85028 - RMSE: 1.83803\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.57744 - RMSE: 1.57411\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 7 : Loss: 1.84404 - RMSE: 1.82983\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.52618 - RMSE: 1.51803\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 8 : Loss: 1.79046 - RMSE: 1.77557\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.66174 - RMSE: 1.65078\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 9 : Loss: 1.69707 - RMSE: 1.68861\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.59286 - RMSE: 1.58029\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 10 : Loss: 1.71654 - RMSE: 1.70605\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.68750 - RMSE: 1.65886\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 11 : Loss: 1.55777 - RMSE: 1.54308\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.67993 - RMSE: 1.67335\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 12 : Loss: 1.39838 - RMSE: 1.38904\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.54934 - RMSE: 1.54281\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 13 : Loss: 1.35460 - RMSE: 1.34601\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.61792 - RMSE: 1.60762\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 14 : Loss: 1.19075 - RMSE: 1.18369\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.59665 - RMSE: 1.59250\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 15 : Loss: 1.13803 - RMSE: 1.13142\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.51299 - RMSE: 1.50810\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 16 : Loss: 1.08860 - RMSE: 1.08057\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.48210 - RMSE: 1.48022\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 17 : Loss: 1.05524 - RMSE: 1.04812\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.47358 - RMSE: 1.47166\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 18 : Loss: 0.95364 - RMSE: 0.94613\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.49023 - RMSE: 1.48810\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 19 : Loss: 0.97784 - RMSE: 0.97470\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.49233 - RMSE: 1.49095\n",
      "\n",
      "Best Fold --- Loss score: 1.4735770622889202 - F1 Score 1.4716575476858351\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49feb4a3f71d48139627eaefbc6b9710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][0.85 min] Epoch 0 : Loss: 10.38623 - RMSE: 7.605157\n",
      "[Evaluation][9/9][0.12 min] Loss: 4.39254 - RMSE: 2.42686\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 1 : Loss: 4.62283 - RMSE: 4.48073\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.22823 - RMSE: 2.09161\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 2 : Loss: 3.19829 - RMSE: 3.12339\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.74377 - RMSE: 2.74056\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 3 : Loss: 2.48474 - RMSE: 2.42006\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.63388 - RMSE: 2.56928\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 4 : Loss: 2.25613 - RMSE: 2.22811\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.04875 - RMSE: 1.73322\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 5 : Loss: 2.30568 - RMSE: 2.25106\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.92838 - RMSE: 1.92838\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 6 : Loss: 1.90207 - RMSE: 1.87645\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.54525 - RMSE: 1.54442\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 7 : Loss: 1.90533 - RMSE: 1.88000\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.65262 - RMSE: 1.52416\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 8 : Loss: 1.75230 - RMSE: 1.72834\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.72330 - RMSE: 1.61609\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 9 : Loss: 1.65076 - RMSE: 1.62895\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.44981 - RMSE: 1.44976\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 10 : Loss: 1.47921 - RMSE: 1.46233\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.61220 - RMSE: 1.61152\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 11 : Loss: 1.46598 - RMSE: 1.45175\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.41852 - RMSE: 1.41787\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 12 : Loss: 1.32776 - RMSE: 1.30969\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.42010 - RMSE: 1.41823\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 13 : Loss: 1.31915 - RMSE: 1.30747\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.40737 - RMSE: 1.40495\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 14 : Loss: 1.19088 - RMSE: 1.18052\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.42829 - RMSE: 1.42717\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 15 : Loss: 1.10728 - RMSE: 1.09844\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.43916 - RMSE: 1.43831\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 16 : Loss: 1.01283 - RMSE: 1.00640\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.39202 - RMSE: 1.38114\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 17 : Loss: 0.97335 - RMSE: 0.96705\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.38645 - RMSE: 1.38365\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 18 : Loss: 0.91490 - RMSE: 0.90796\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.41936 - RMSE: 1.41613\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 19 : Loss: 0.87851 - RMSE: 0.87434\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.40296 - RMSE: 1.39926\n",
      "\n",
      "Best Fold --- Loss score: 1.392018887731764 - F1 Score 1.3811386161380343\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199a112a30914235a20dcf97a0f8ebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][0.85 min] Epoch 0 : Loss: 10.75022 - RMSE: 8.159505\n",
      "[Evaluation][9/9][0.11 min] Loss: 5.89403 - RMSE: 4.32353\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 1 : Loss: 3.62168 - RMSE: 3.51767\n",
      "[Evaluation][9/9][0.11 min] Loss: 2.36700 - RMSE: 2.35447\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 2 : Loss: 3.10839 - RMSE: 3.04832\n",
      "[Evaluation][9/9][0.11 min] Loss: 2.34248 - RMSE: 2.34021\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 3 : Loss: 2.51073 - RMSE: 2.45890\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.54452 - RMSE: 2.18442\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 4 : Loss: 2.14580 - RMSE: 2.11534\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.59189 - RMSE: 1.54904\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 5 : Loss: 2.07211 - RMSE: 2.04137\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.85289 - RMSE: 1.85139\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 6 : Loss: 1.99459 - RMSE: 1.96624\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.58160 - RMSE: 1.58098\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 7 : Loss: 1.95721 - RMSE: 1.92975\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.63470 - RMSE: 1.63301\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 8 : Loss: 1.73330 - RMSE: 1.71341\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.63647 - RMSE: 1.58257\n",
      "\n",
      "[Training][67/67][0.83 min] Epoch 9 : Loss: 1.54645 - RMSE: 1.52976\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.48502 - RMSE: 1.48491\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 10 : Loss: 1.50102 - RMSE: 1.48721\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.99459 - RMSE: 1.93733\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 11 : Loss: 1.53113 - RMSE: 1.52018\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.36327 - RMSE: 1.36029\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 12 : Loss: 1.33709 - RMSE: 1.31785\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.54410 - RMSE: 1.52744\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 13 : Loss: 1.35108 - RMSE: 1.34228\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.60257 - RMSE: 1.58037\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 14 : Loss: 1.23755 - RMSE: 1.22912\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.35294 - RMSE: 1.35034\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 15 : Loss: 1.07183 - RMSE: 1.06352\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.41046 - RMSE: 1.40920\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 16 : Loss: 1.07334 - RMSE: 1.06650\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.36807 - RMSE: 1.36704\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 17 : Loss: 0.96718 - RMSE: 0.96297\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.37448 - RMSE: 1.37086\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 18 : Loss: 1.00981 - RMSE: 1.00153\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.38927 - RMSE: 1.38619\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 19 : Loss: 0.95289 - RMSE: 0.94856\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.36771 - RMSE: 1.36425\n",
      "\n",
      "Best Fold --- Loss score: 1.3529419170485601 - F1 Score 1.350335803296831\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406910d9fde7481886a250ee1c5f9956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][0.85 min] Epoch 0 : Loss: 9.39829 - RMSE: 7.7590460\n",
      "[Evaluation][9/9][0.12 min] Loss: 3.71833 - RMSE: 3.00896\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 1 : Loss: 4.84986 - RMSE: 4.69850\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.29265 - RMSE: 2.16421\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 2 : Loss: 3.18066 - RMSE: 3.14577\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.83487 - RMSE: 1.82495\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 3 : Loss: 2.85548 - RMSE: 2.83078\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.53474 - RMSE: 1.51749\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 4 : Loss: 2.14523 - RMSE: 2.12649\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.96820 - RMSE: 1.96817\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 5 : Loss: 2.04031 - RMSE: 2.01148\n",
      "[Evaluation][9/9][0.11 min] Loss: 2.17003 - RMSE: 2.16875\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 6 : Loss: 2.28188 - RMSE: 2.27085\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.61969 - RMSE: 1.60276\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 7 : Loss: 2.03363 - RMSE: 2.02029\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.59730 - RMSE: 1.59680\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 8 : Loss: 1.78743 - RMSE: 1.76434\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.94234 - RMSE: 1.93045\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 9 : Loss: 1.82563 - RMSE: 1.80848\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.52476 - RMSE: 1.51011\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 10 : Loss: 1.61824 - RMSE: 1.60232\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.68383 - RMSE: 1.59050\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 11 : Loss: 1.44753 - RMSE: 1.44095\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.46628 - RMSE: 1.46536\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 12 : Loss: 1.36581 - RMSE: 1.35426\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.45409 - RMSE: 1.45408\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 13 : Loss: 1.45743 - RMSE: 1.44926\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.37178 - RMSE: 1.36901\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 14 : Loss: 1.23225 - RMSE: 1.22464\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.34875 - RMSE: 1.33134\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 15 : Loss: 1.16486 - RMSE: 1.15771\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.29916 - RMSE: 1.29366\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 16 : Loss: 1.07982 - RMSE: 1.07327\n",
      "[Evaluation][9/9][0.11 min] Loss: 1.28356 - RMSE: 1.27183\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 17 : Loss: 1.04056 - RMSE: 1.03484\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.25040 - RMSE: 1.24215\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 18 : Loss: 1.00098 - RMSE: 0.99309\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.24536 - RMSE: 1.23720\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 19 : Loss: 0.97638 - RMSE: 0.97321\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.23314 - RMSE: 1.22668\n",
      "\n",
      "Best Fold --- Loss score: 1.2331358393033345 - F1 Score 1.2266845438215468\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0f87b7bd064577b2b12f0906d9ac34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training][67/67][0.85 min] Epoch 0 : Loss: 10.41046 - RMSE: 9.216896\n",
      "[Evaluation][9/9][0.12 min] Loss: 5.41384 - RMSE: 4.46592\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 1 : Loss: 4.20925 - RMSE: 4.10932\n",
      "[Evaluation][9/9][0.12 min] Loss: 5.04945 - RMSE: 4.90224\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 2 : Loss: 4.01601 - RMSE: 3.90153\n",
      "[Evaluation][9/9][0.12 min] Loss: 3.68247 - RMSE: 3.67246\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 3 : Loss: 3.05300 - RMSE: 2.98332\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.92840 - RMSE: 2.92835\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 4 : Loss: 2.41692 - RMSE: 2.38622\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.90875 - RMSE: 1.90457\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 5 : Loss: 2.16169 - RMSE: 2.14327\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.64345 - RMSE: 1.63827\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 6 : Loss: 2.48368 - RMSE: 2.46644\n",
      "[Evaluation][9/9][0.12 min] Loss: 2.84120 - RMSE: 2.78584\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 7 : Loss: 2.01339 - RMSE: 1.99460\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.82557 - RMSE: 1.70824\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 8 : Loss: 1.85572 - RMSE: 1.83658\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.87705 - RMSE: 1.87643\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 9 : Loss: 1.62757 - RMSE: 1.60648\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.43316 - RMSE: 1.34261\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 10 : Loss: 1.57257 - RMSE: 1.55382\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.50209 - RMSE: 1.41564\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 11 : Loss: 1.44340 - RMSE: 1.42864\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.61985 - RMSE: 1.57261\n",
      "\n",
      "[Training][67/67][0.84 min] Epoch 12 : Loss: 1.43138 - RMSE: 1.41827\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.53295 - RMSE: 1.52606\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 13 : Loss: 1.38155 - RMSE: 1.37382\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.44610 - RMSE: 1.43230\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 14 : Loss: 1.17709 - RMSE: 1.16480\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.44539 - RMSE: 1.43817\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 15 : Loss: 1.10932 - RMSE: 1.09969\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.58651 - RMSE: 1.57979\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 16 : Loss: 1.06696 - RMSE: 1.05925\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.38534 - RMSE: 1.36934\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 17 : Loss: 0.98996 - RMSE: 0.98034\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.35092 - RMSE: 1.34916\n",
      "\n",
      "[Training][67/67][0.85 min] Epoch 18 : Loss: 0.95455 - RMSE: 0.94856\n",
      "[Evaluation][9/9][0.13 min] Loss: 1.33125 - RMSE: 1.32664\n",
      "\n",
      "[Training][67/67][0.86 min] Epoch 19 : Loss: 0.97904 - RMSE: 0.97299\n",
      "[Evaluation][9/9][0.12 min] Loss: 1.32902 - RMSE: 1.32108\n",
      "\n",
      "Best Fold --- Loss score: 1.329024765226576 - F1 Score 1.321076340145535\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_score = 0\n",
    "\n",
    "for f in args.use_folds:\n",
    "    fold_score = run_fold(f, args)\n",
    "    avg_score += (fold_score / args.actual_split)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c58122eb-2391-4274-83e1-ee953aaa1dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3501785702175564"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
