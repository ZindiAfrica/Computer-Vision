{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pandas import read_csv,DataFrame,get_dummies\n",
    "Test = read_csv(\"./test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Some Columns to 0 : A lot of work was tested here but none of my ideas improves the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011_RE_0001 x Expenditure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011_RE_0002 x Expenditure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011_RE_0003 x Expenditure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011_RE_0004 x Expenditure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011_RE_0005 x Expenditure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ID  error\n",
       "0  2011_RE_0001 x Expenditure      0\n",
       "1  2011_RE_0002 x Expenditure      0\n",
       "2  2011_RE_0003 x Expenditure      0\n",
       "3  2011_RE_0004 x Expenditure      0\n",
       "4  2011_RE_0005 x Expenditure      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scored_Data = DataFrame()\n",
    "No_errors = ['Expenditure','Status','Tag_3','PCVNumber',\n",
    "             'T_Number','Tag_2','Sex',\n",
    "             'Release_Admiss_Notes', 'Date_Caught',\n",
    "             'TurtleCharacteristics','Date','Date_Release','Researcher','Species',\n",
    "             'SpecialRemarks','Lost_Tags','CCW_cm','CCL_cm','Weight_Kg']\n",
    "for Column in No_errors:\n",
    "    Temp = DataFrame()\n",
    "    Temp['ID'] = Test['Rescue_ID'] + ' x ' + Column\n",
    "    Temp['error'] = 0\n",
    "    Scored_Data = Scored_Data.append(Temp)\n",
    "Scored_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows : 4292\n",
      "Test rows : 1362\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import read_csv,to_datetime, DataFrame, pivot, get_dummies\n",
    "\n",
    "# Train Data\n",
    "Variable_Description = read_csv(\"./variable_definitions.csv\",encoding='latin1')\n",
    "Dirty_Data = read_csv(\"./dirty_data.csv\",encoding='latin1')\n",
    "print('Train rows :' ,Dirty_Data.shape[0])\n",
    "# Test Data\n",
    "Test_Data = read_csv('./test_data.csv')\n",
    "print('Test rows :',Test_Data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag 2 subsequent with Tag 1 ? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test_Data['Tag_1_F'] = Test_Data['Tag_1'].map(lambda x : x[-4:])\n",
    "Test_Data['Tag_2_F'] = Test_Data['Tag_2'].map(lambda x : x[-4:])\n",
    "a = Test_Data.loc[Test_Data.Tag_2_F != 'None',['Tag_1_F','Tag_2_F']]\n",
    "display(Test_Data.loc[[137,509,666,1051],'Rescue_ID'])\n",
    "for x in Test_Data.loc[[137,509,666,1051],'Rescue_ID']:\n",
    "    Scored_Data.loc[Scored_Data['ID'] == x + ' x Tag_2','error'] = 1\n",
    "a['Tag_1_F'].map(int) - a['Tag_2_F'].map(int) != -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CaptureSite and ForagingGround\n",
    "#### Here we take the most frequent ForagingGround for each CaptureSite and consider the others as erros, this could be done with an machine algorithm but a if then rule works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ForagingGround_Errors = Test_Data[['CaptureSite','ForagingGround']].append(Dirty_Data[['CaptureSite','ForagingGround']])\n",
    "\n",
    "CaptureSite_to_ForagingGround = dict()\n",
    "for site in ForagingGround_Errors.CaptureSite.unique():\n",
    "    CaptureSite_to_ForagingGround[site] = ForagingGround_Errors.loc[ForagingGround_Errors.CaptureSite == site,'ForagingGround'].value_counts() \\\n",
    "                                          .reset_index()['index'][0]\n",
    "\n",
    "Scored_Data = Scored_Data.loc[Scored_Data.ID.map(lambda x : 'ForagingGround' not in x)]\n",
    "\n",
    "Temp = DataFrame()\n",
    "Temp['ID'] = Test_Data['Rescue_ID'] + ' x ' + 'ForagingGround'\n",
    "Temp['error'] = 0\n",
    "for idx, row in Test_Data.iterrows():\n",
    "    if (row['ForagingGround'] != CaptureSite_to_ForagingGround[row['CaptureSite']]):\n",
    "        Temp.loc[Temp['ID'] == row['Rescue_ID'] + ' x ' + 'ForagingGround', 'error'] = 1\n",
    "Scored_Data = Scored_Data.append(Temp)\n",
    "Scored_Data.error.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to last numerical value for each tag"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = ['2011_RE_0012','2011_RE_0013','2011_RE_0025','2011_RE_0048','2011_RE_0064',\n",
    "     '2011_RE_0095','2011_RE_0137','2011_RE_0152','2011_RE_1236']\n",
    "for y in x:\n",
    "    if y in  ['2011_RE_0008','2011_RE_0012','2011_RE_0013','2011_RE_0025','2011_RE_0032',\n",
    "              '2011_RE_0036','2011_RE_0064','2011_RE_0095','2011_RE_0112','2011_RE_0137',\n",
    "              '2011_RE_0152','2011_RE_0182','2011_RE_1236']:\n",
    "        print(y)\n",
    "        Scored_Data.loc[Scored_Data['ID'] == y + ' x CCL_cm','error'] = 1\n",
    "        Scored_Data.loc[Scored_Data['ID'] == y + ' x CCW_cm','error'] = 1\n",
    "              \n",
    "#x = ['2011_RE_0046','2011_RE_0051','2011_RE_0133','2011_RE_0139','2011_RE_0147','2011_RE_0148',\n",
    "#     '2011_RE_0160','2011_RE_0218','2011_RE_0257','2011_RE_0276','2011_RE_0319','2011_RE_0327',\n",
    "#     '2011_RE_0554','2011_RE_1037','2011_RE_1236']\n",
    "#for y in x:\n",
    "#    Scored_Data.loc[Scored_Data['ID'] == y + ' x Weight_Kg','error'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and make predictions (taking predictions instead of probability increase the score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>2011_RE_1361 x Tag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>2011_RE_1362 x Tag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>2011_RE_1363 x Tag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>2011_RE_1364 x Tag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>2011_RE_1365 x Tag_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  error\n",
       "1357  2011_RE_1361 x Tag_1      0\n",
       "1358  2011_RE_1362 x Tag_1      0\n",
       "1359  2011_RE_1363 x Tag_1      0\n",
       "1360  2011_RE_1364 x Tag_1      0\n",
       "1361  2011_RE_1365 x Tag_1      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cat_Errors = ['CaptureSite','LandingSite','ReleaseSite',\n",
    "              'CaptureMethod','Fisher','Tag_1']\n",
    "\n",
    "svc_classif = pickle.load(open('./Cat_model.p','rb'))\n",
    "vect_space = pickle.load(open('./vect_space.p','rb'))\n",
    "\n",
    "Temp = Test[['Rescue_ID'] + Cat_Errors].fillna(\"NA\").set_index('Rescue_ID')\n",
    "\n",
    "Test_set = get_dummies(Temp)\n",
    "New_features = [x for x in Test_set if x not in vect_space]\n",
    "Old_features = [x for x in vect_space if x not in Test_set]\n",
    "for o in Old_features:\n",
    "    Test_set[o] = 0\n",
    "\n",
    "\n",
    "Y_test_pred = DataFrame(svc_classif.predict(Test_set[vect_space]),\n",
    "                        columns=Cat_Errors,index=Temp.index)\n",
    "\n",
    "for Column in Cat_Errors:\n",
    "    Temp = Y_test_pred[Column].reset_index()\n",
    "    Temp['ID'] = Temp['Rescue_ID'] + ' x ' + Column\n",
    "    Temp['error'] = Temp[Column]\n",
    "    Scored_Data = Scored_Data.append(Temp[['ID','error']])\n",
    "Scored_Data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scored_Data.to_csv('./submission_v0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
