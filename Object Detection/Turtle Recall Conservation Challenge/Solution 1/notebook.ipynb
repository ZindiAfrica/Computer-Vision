{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101b04b7",
   "metadata": {},
   "source": [
    "### Download single fold weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4faef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   139    0   139    0     0    431      0 --:--:-- --:--:-- --:--:--   431\n",
      "100   340  100   340    0     0    537      0 --:--:-- --:--:-- --:--:--   537\n",
      "100   534    0   534    0     0    398      0 --:--:--  0:00:01 --:--:--     0\n",
      "100  267M  100  267M    0     0  22.8M      0  0:00:11  0:00:11 --:--:-- 27.8M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ef1b7-fold0.h5 https://www.dropbox.com/s/e9xi8cpjk152npb/ef1b7-fold0.h5?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77945546",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed06b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../lib')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print('tf:', tf.__version__)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import efficientnet.tfkeras as efn\n",
    "from vecxoz_utils import init_tpu\n",
    "from vecxoz_utils import create_cv_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7171e260",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f11729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    data_dir       = '../data'\n",
    "    data_preds_dir = 'preds'\n",
    "    tpu_ip_or_name = None\n",
    "    n_channels     = 3\n",
    "    dim            = 512\n",
    "    lr             = 5e-4\n",
    "    weights        = 'imagenet'\n",
    "    n_classes      = 2265"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fad3d1",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e4828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(file):\n",
    "    \"\"\"Read, decode image, and return 4D tensor\n",
    "    \"\"\"\n",
    "    image = tf.image.decode_jpeg(tf.io.read_file(file), channels=args.n_channels, dct_method='INTEGER_ACCURATE')\n",
    "    image = tf.image.resize(image, [args.dim, args.dim])\n",
    "    image = tf.reshape(image, [args.dim, args.dim, args.n_channels])\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def init_model(print_summary=True):\n",
    "    model = tf.keras.Sequential([\n",
    "        efn.EfficientNetB7(input_shape=(args.dim, args.dim, args.n_channels), \n",
    "                           weights=args.weights, \n",
    "                           include_top=False),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(args.n_classes, activation='softmax')\n",
    "    ], name='model')\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(args.lr), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def decode_prediction(probas):\n",
    "    \"\"\"Decode predictions for a single example\n",
    "    \"\"\"\n",
    "    # 0) Argsort probabilities\n",
    "    preds_int = np.argsort(probas, axis=1)[:, ::-1]\n",
    "\n",
    "    # 1) Transform integer labels into string labels\n",
    "    preds_str_1 = le.inverse_transform(np.squeeze(preds_int))\n",
    "\n",
    "    # 2) Replace labels outside 100 training ids with a \"new_turtle\"\n",
    "    preds_str_2 = []\n",
    "    for turtle_id in preds_str_1:\n",
    "        if turtle_id in turtle_ids_orig:\n",
    "            preds_str_2.append(turtle_id)\n",
    "        else:\n",
    "            preds_str_2.append('new_turtle')\n",
    "\n",
    "    # 4) If there are several \"new_turtle\" labels for a given example - \n",
    "    #    replace all except the 1st occurrence with the most probable training ids\n",
    "    preds_str_2 = np.array(preds_str_2)\n",
    "    cand = [x for x in preds_str_2[preds_str_2 != 'new_turtle'] if x not in preds_str_2[:5]][:4]\n",
    "    preds_str_3 = []\n",
    "    for t_id in preds_str_2[:5]:\n",
    "        if t_id not in preds_str_3:\n",
    "            preds_str_3.append(t_id)\n",
    "    for _ in range(5 - len(preds_str_3)):\n",
    "        preds_str_3.append(cand.pop(0))\n",
    "    #\n",
    "    return preds_str_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa81c6",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e778ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig_df = pd.read_csv(os.path.join(args.data_dir, 'train.csv'))\n",
    "turtle_ids_orig = sorted(train_orig_df['turtle_id'].unique()) # 100 unique\n",
    "train_df, test_df = create_cv_split(args.data_dir, 5)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(train_df['turtle_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a8d29",
   "metadata": {},
   "source": [
    "### Init accelerator and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ee001d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> TPU was not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:29:06.371020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:07.219113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:07.219857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:07.276061: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-25 10:29:07.287893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:07.288625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:07.289210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:14.260259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:14.261009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:14.261635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-25 10:29:14.283811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "--> Num replicas: 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnet-b7 (Functional  (None, 16, 16, 2560)     64097680  \n",
      " )                                                               \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2560)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2265)              5800665   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,898,345\n",
      "Trainable params: 69,587,625\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_, _, strategy = init_tpu(args.tpu_ip_or_name)\n",
    "with strategy.scope():\n",
    "    model = init_model()\n",
    "model.load_weights('ef1b7-fold0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ea0fe",
   "metadata": {},
   "source": [
    "### Predict test examples one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccdef32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 10:29:43.606809: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489\r"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "for counter, (_, row) in enumerate(test_df.iterrows()):\n",
    "    file = os.path.join(args.data_dir, 'images', row['image_id'] + '.JPG')\n",
    "    image = image_to_tensor(file)\n",
    "    probas = model(image)\n",
    "    preds = decode_prediction(probas)\n",
    "    preds_list.append(preds)\n",
    "    print(counter, end='\\r')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade904d",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08c4d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prediction1</th>\n",
       "      <th>prediction2</th>\n",
       "      <th>prediction3</th>\n",
       "      <th>prediction4</th>\n",
       "      <th>prediction5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_6NEDKOYZ</td>\n",
       "      <td>t_id_4ZfTUmwL</td>\n",
       "      <td>t_id_IlO9BOKc</td>\n",
       "      <td>t_id_uJXT7dGu</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_uIlC9Gfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_57QZ4S9N</td>\n",
       "      <td>t_id_Kf73l69A</td>\n",
       "      <td>t_id_fjHGjp1w</td>\n",
       "      <td>t_id_Ts5LyVQz</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_NW7wn8TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_OCGGJS5X</td>\n",
       "      <td>t_id_YjXYTCGC</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_AMnriNb5</td>\n",
       "      <td>t_id_pCO59rOk</td>\n",
       "      <td>t_id_ROFhVsy2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_R2993S3S</td>\n",
       "      <td>t_id_VP2NW7aV</td>\n",
       "      <td>t_id_pCO59rOk</td>\n",
       "      <td>t_id_uJXT7dGu</td>\n",
       "      <td>t_id_9GFmcOd5</td>\n",
       "      <td>new_turtle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_2E011NB0</td>\n",
       "      <td>t_id_dVQ4x3wz</td>\n",
       "      <td>new_turtle</td>\n",
       "      <td>t_id_QqeoI5F3</td>\n",
       "      <td>t_id_ksTLswDT</td>\n",
       "      <td>t_id_EEbWq5Pj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id    prediction1    prediction2    prediction3    prediction4  \\\n",
       "0  ID_6NEDKOYZ  t_id_4ZfTUmwL  t_id_IlO9BOKc  t_id_uJXT7dGu     new_turtle   \n",
       "1  ID_57QZ4S9N  t_id_Kf73l69A  t_id_fjHGjp1w  t_id_Ts5LyVQz     new_turtle   \n",
       "2  ID_OCGGJS5X  t_id_YjXYTCGC     new_turtle  t_id_AMnriNb5  t_id_pCO59rOk   \n",
       "3  ID_R2993S3S  t_id_VP2NW7aV  t_id_pCO59rOk  t_id_uJXT7dGu  t_id_9GFmcOd5   \n",
       "4  ID_2E011NB0  t_id_dVQ4x3wz     new_turtle  t_id_QqeoI5F3  t_id_ksTLswDT   \n",
       "\n",
       "     prediction5  \n",
       "0  t_id_uIlC9Gfo  \n",
       "1  t_id_NW7wn8TC  \n",
       "2  t_id_ROFhVsy2  \n",
       "3     new_turtle  \n",
       "4  t_id_EEbWq5Pj  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_list = np.array(preds_list)\n",
    "subm_df = pd.read_csv('/home/vecxoz/data/sample_submission.csv')\n",
    "subm_df['prediction1'] = preds_list[:, 0]\n",
    "subm_df['prediction2'] = preds_list[:, 1]\n",
    "subm_df['prediction3'] = preds_list[:, 2]\n",
    "subm_df['prediction4'] = preds_list[:, 3]\n",
    "subm_df['prediction5'] = preds_list[:, 4]\n",
    "subm_df.to_csv('submission-single-model-single-fold.csv', index=False)\n",
    "subm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ccb6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
