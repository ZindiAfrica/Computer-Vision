{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations import *\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import effdet\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, create_model_from_config\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap = {'fruit_healthy':1, 'fruit_woodiness':2, 'fruit_brownspot':3}\n",
    "labelmap_inv = {k:v for v,k in labelmap.items()}\n",
    "\n",
    "class PassionFruitDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, img_path, transforms):\n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "        self.root = img_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        row = self.csv.iloc[idx]\n",
    "        img_path = os.path.join(self.root, row.Image_ID) + '.jpg'\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\")).astype('uint8')\n",
    "        #img = cv2.rotate(img, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "        if self.transforms is not None:\n",
    "            annotations = {'image': img}\n",
    "            augmented = self.transforms(**annotations)\n",
    "            img = augmented['image']\n",
    "        \n",
    "        return img/255, row.Image_ID\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "def vis(img, target):\n",
    "    visualize.show_labeled_image(img.permute(1,2,0).numpy(), target['boxes'].numpy(), target[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = Compose([\n",
    "    #Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_ds = PassionFruitDataset(\n",
    "    'data/Test.csv',\n",
    "    'data/Test_Images/Test_Images', \n",
    "    transform_test\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(model_name):\n",
    "    if model_name == 'resnet':\n",
    "        backbone = torch.nn.Sequential(*(list(torchvision.models.resnet101(pretrained=True).children())[:-2]))\n",
    "        backbone.out_channels = 2048\n",
    "    elif model_name == 'densenet':\n",
    "        backbone = torchvision.models.densenet121(pretrained=True).features\n",
    "        backbone.out_channels = 1024\n",
    "    \n",
    "    elif model_name == 'inception':\n",
    "            backbone = torch.nn.Sequential(*(list(torchvision.models.inception_v3(pretrained=True).children())[:-3]))\n",
    "            backbone.out_channels = 1024\n",
    "    \n",
    "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                       aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0','1','2','3'],\n",
    "                                                    output_size=7,\n",
    "                                                    sampling_ratio=2)\n",
    "\n",
    "    # put the pieces together inside a FasterRCNN model\n",
    "    model = FasterRCNN(backbone,\n",
    "                       num_classes=4,\n",
    "                       rpn_anchor_generator=anchor_generator,\n",
    "                       box_roi_pool=roi_pooler)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_predictions(images, score_threshold=0.2):\n",
    "    images = images.cuda().float()\n",
    "    predictions = []\n",
    "    net.cuda()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        det = net(images)\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i]['boxes'].detach().cpu().numpy()   \n",
    "            scores = det[i]['scores'].detach().cpu().numpy()\n",
    "            classes = det[i]['labels'].detach().cpu().numpy()\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            \n",
    "           \n",
    "            predictions.append({ \n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "                'classes': classes[indexes]\n",
    "            })\n",
    "    return [predictions]\n",
    "\n",
    "def iou(box):\n",
    "    mat = []\n",
    "    ious = []\n",
    "    for a in range(len(box)):\n",
    "        for b in range(len(box)):\n",
    "            if a != b:\n",
    "                boxA = box[a]\n",
    "                boxB = box[b]\n",
    "                xA = max(boxA[0], boxB[0])\n",
    "                yA = max(boxA[1], boxB[1])\n",
    "                xB = min(boxA[2], boxB[2])\n",
    "                yB = min(boxA[3], boxB[3])\n",
    "                interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "                boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "                boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "                iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "                if iou not in ious:\n",
    "                    ious.append(iou)\n",
    "                    mat.append([a,b])\n",
    "    return np.array(ious), np.array(mat)\n",
    "\n",
    "def postprocessing(boxes, scores, labels):\n",
    "    boxes = (boxes).astype(np.int32).clip(min=0, max=512)\n",
    "    ious, mat = iou(boxes)\n",
    "    del_index = []\n",
    "    for i in mat[ious > 0.8]:\n",
    "        if scores[i[0]] > scores[i[1]]:\n",
    "            del_index.append(i[1])\n",
    "        else:\n",
    "            del_index.append(i[0])\n",
    "    boxes = np.delete(boxes,del_index,axis = 0)\n",
    "    scores = np.delete(scores,del_index)\n",
    "    labels = np.delete(labels,del_index)\n",
    "    \n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_net('resnet')\n",
    "checkpoint = torch.load('logs/fasterrcnn-resnet101-pseudo-heavyaug-5add32_64-5ep-final/best-checkpoint-001epoch.bin')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for images, image_id in data_loader:\n",
    "    predictions = make_predictions(images,0)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        boxes, scores, labels = predictions[0][i]['boxes'], predictions[0][i]['scores'], predictions[0][i]['classes']\n",
    "        \n",
    "        boxes, scores, labels = postprocessing(boxes, scores, labels)\n",
    "        result = {\n",
    "            'image_id': image_id[i],\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'scores': scores,\n",
    "        }\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/labels_train.csv')\n",
    "train_max = max(train.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(columns = ['Image_ID', 'class', 'confidence', 'ymin', 'xmin', 'ymax', 'xmax'])\n",
    "tr = 0.0\n",
    "img_name = ''\n",
    "counter2 = 0\n",
    "for i in results:\n",
    "    ID = i['image_id']\n",
    "    boxes = i['boxes']\n",
    "    scores = i['scores']\n",
    "    \n",
    "        \n",
    "    mask = scores > tr\n",
    "\n",
    "    if not mask.any():\n",
    "        mask[np.argmax(scores)] = True\n",
    "    labels = i['labels'][mask].tolist()\n",
    "    boxes = i['boxes'][mask]\n",
    "    labels = [labelmap_inv[j] for j in i['labels']]\n",
    "\n",
    "    for j, box in enumerate(boxes):\n",
    "\n",
    "        sub.loc[counter2] = [ID,\n",
    "                             labels[j],\n",
    "                             scores[j],\n",
    "                             box[1],\n",
    "                             box[0],\n",
    "                             box[3],\n",
    "                             box[2]]\n",
    "        counter2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('concat/resnet101.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
