{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations import *\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import effdet\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, create_model_from_config\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap = {'fruit_healthy':1, 'fruit_woodiness':2, 'fruit_brownspot':3}\n",
    "labelmap_inv = {k:v for v,k in labelmap.items()}\n",
    "\n",
    "class PassionFruitDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, img_path, transforms):\n",
    "        self.csv = pd.read_csv(csv_path)\n",
    "        self.root = img_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        row = self.csv.iloc[idx]\n",
    "        img_path = os.path.join(self.root, row.Image_ID) + '.jpg'\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\")).astype('uint8')\n",
    "        if self.transforms is not None:\n",
    "            annotations = {'image': img}\n",
    "            augmented = self.transforms(**annotations)\n",
    "            img = augmented['image']\n",
    "        \n",
    "        return img, row.Image_ID\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(model_name):\n",
    "    config = get_efficientdet_config(model_name)\n",
    "    config.num_classes = 3\n",
    "    config.pretrained = True\n",
    "    config.image_size = [512,512]\n",
    "    config.label_smoothing = 0.1\n",
    "    \n",
    "    net = create_model_from_config(config)\n",
    "    \n",
    "    return DetBenchPredict(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = Compose([\n",
    "    Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_ds = PassionFruitDatasetTest(\n",
    "    'data/Test.csv',\n",
    "    'data/Test_Images/Test_Images', \n",
    "    transform_test\n",
    ")\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_net('tf_efficientdet_d4')\n",
    "checkpoint = torch.load('logs/tf_effdet4-heavyaug-pseudo/last-checkpoint.bin')\n",
    "net.model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(images, score_threshold=0.2):\n",
    "    images = images.cuda().float()\n",
    "    predictions = []\n",
    "    net.cuda()\n",
    "    with torch.no_grad():\n",
    "        det = net(images, {'img_size':(torch.ones((images.shape[0], 2)) * 512).float().cuda(),'img_scale':torch.ones(images.shape[0]).float().cuda()})\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            classes = det[i].detach().cpu().numpy()[:,5]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            \n",
    "            \n",
    "            predictions.append({ \n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "                'classes': classes[indexes]\n",
    "            })\n",
    "    return [predictions]\n",
    "\n",
    "def iou(box):\n",
    "    mat = []\n",
    "    ious = []\n",
    "    for a in range(len(box)):\n",
    "        for b in range(len(box)):\n",
    "            if a != b:\n",
    "                boxA = box[a]\n",
    "                boxB = box[b]\n",
    "                xA = max(boxA[0], boxB[0])\n",
    "                yA = max(boxA[1], boxB[1])\n",
    "                xB = min(boxA[2], boxB[2])\n",
    "                yB = min(boxA[3], boxB[3])\n",
    "                interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "                boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "                boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "                iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "                if iou not in ious:\n",
    "                    ious.append(iou)\n",
    "                    mat.append([a,b])\n",
    "    return np.array(ious), np.array(mat)\n",
    "\n",
    "def postprocessing(boxes, scores, labels):\n",
    "    boxes = (boxes).astype(np.int32).clip(min=0, max=512)\n",
    "    ious, mat = iou(boxes)\n",
    "    del_index = []\n",
    "    for i in mat[ious > 0.8]:\n",
    "        if scores[i[0]] > scores[i[1]]:\n",
    "            del_index.append(i[1])\n",
    "        else:\n",
    "            del_index.append(i[0])\n",
    "    boxes = np.delete(boxes,del_index,axis = 0)\n",
    "    scores = np.delete(scores,del_index)\n",
    "    labels = np.delete(labels,del_index)\n",
    "    \n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenp\\anaconda3\\envs\\ml\\lib\\site-packages\\effdet\\bench.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  indices_all = cls_topk_indices_all // num_classes\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for images, image_id in data_loader:\n",
    "    predictions = make_predictions(images, 0.1)\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        boxes, scores, labels = predictions[0][i]['boxes'], predictions[0][i]['scores'], predictions[0][i]['classes']\n",
    "        \n",
    "        boxes, scores, labels = postprocessing(boxes, scores, labels)\n",
    "        result = {\n",
    "            'image_id': image_id[i],\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'scores': scores,\n",
    "        }\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/labels_train.csv')\n",
    "train_max = max(train.image_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.DataFrame(columns = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax', 'image_id','folder'])\n",
    "\n",
    "img_name = ''\n",
    "counter = train_max + 1\n",
    "counter2 = 0\n",
    "\n",
    "tr = 0.2\n",
    "for i in results:\n",
    "    ID = i['image_id']\n",
    "    boxes = i['boxes']\n",
    "    scores = i['scores']\n",
    "    \n",
    "    mask = scores > tr\n",
    "    if not mask.any():\n",
    "        mask[np.argmax(scores)] = True\n",
    "    labels = i['labels'][mask].tolist()\n",
    "    boxes = i['boxes'][mask]\n",
    "    labels = [labelmap_inv[j] for j in i['labels']]\n",
    "    \n",
    "    for j, box in enumerate(boxes):\n",
    "       \n",
    "        train_.loc[counter2] = [f'{ID}.jpg',\n",
    "                         512,\n",
    "                         512,\n",
    "                         labels[j],\n",
    "                         box[0],\n",
    "                         box[1],\n",
    "                         box[2],\n",
    "                         box[3],\n",
    "                         counter,\n",
    "                        'Test']\n",
    "        \n",
    "        counter2 += 1\n",
    "    counter += 1\n",
    "    \n",
    "train_ = pd.concat((train,train_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_.to_csv('data/labels_pseudo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5206"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
