{"cells":[{"metadata":{},"cell_type":"markdown","source":"***hello Zindi \nin this compitition i tried to use a new Pretrained Model named \"ProtBert-BFD model\" so thanx to the bioinformatics deep learning\n and specially to Rostlab, because they did the real and the hard part of this solution , ProtBert-BFD is based on Bert model which pretrained on a large corpus of protein sequences in a self-supervised fashion, ***"},{"metadata":{"trusted":true,"id":"og0mVjIc4tnP"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"ZUVvdTWo4tnU","outputId":"e7b58e14-b32a-4c5b-bda1-2dfe6641ff2c"},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Dense,Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom sklearn.model_selection import train_test_split\nimport transformers\nfrom sklearn import preprocessing\nfrom transformers import TFAutoModel, AutoTokenizer, BertTokenizer, TFBertModel\nfrom tqdm.notebook import tqdm\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n\nprint('Using Tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"id":"yzJsGHsi8FJu","trusted":true},"cell_type":"code","source":"# the tokenizer of prot_bert_bfd\ntokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert_bfd\")","execution_count":null,"outputs":[]},{"metadata":{"id":"YI8Q9brY82Ru","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/instadeep-enzyme-classification-challenge/Train (4).csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= pd.read_csv(\"../input/instadeep-enzyme-classification-challenge/Test (3).csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode the sequences","execution_count":null,"outputs":[]},{"metadata":{"id":"RhQnZVyu64T_","trusted":true},"cell_type":"code","source":"def bert_encoder(review):\n  txt =\" \".join(review)\n  encoded = tokenizer.encode_plus(txt, add_special_tokens=True, \n                                    max_length=380, \n                                    pad_to_max_length=True, \n                                    return_attention_mask=True, \n                                    return_token_type_ids=True)\n  return encoded['input_ids']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build The Model \""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"uQ21rVJo4tnY"},"cell_type":"code","source":"def build_model(transformer, max_len=380):\n    \n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    linear= Dense(1024, activation= 'relu')(cls_token)\n    drop= Dropout(0.5)(linear)\n    out = Dense(20, activation='softmax')(drop) \n    model = Model(inputs=input_word_ids, outputs=out)\n    model.compile(Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"encode the 20 labels \n"},{"metadata":{"trusted":true,"id":"Fd_8u4vb4tnb"},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(train_df[\"LABEL\"].unique())\ntrain_df[\"LABEL\"]= le.transform(train_df[\"LABEL\"])","execution_count":null,"outputs":[]},{"metadata":{"id":"mdBXtqiKCc7i","outputId":"20594632-09d7-4871-baf4-12c8ab2c700c","trusted":false},"cell_type":"code","source":"#encode Train data\nbert_train = [bert_encoder(r) for r in tqdm(train_df[\"SEQUENCE\"])]\nbert_train = np.array(bert_train)\n\nbert_lbl = [l for l in tqdm(train_df[\"LABEL\"])]\nbert_lbl = tf.keras.utils.to_categorical(bert_lbl, num_classes=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode Test \nbert_test= [bert_encoder(r) for r in tqdm(test[\"SEQUENCE\"])]\nbert_test = np.array(bert_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split our data into Train and validation"},{"metadata":{"id":"JD2j2gw3BPUk","outputId":"42196075-729d-4dd4-d750-4db39db66cd4","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(bert_train, \n                                         bert_lbl,\n                                         test_size=0.15, \n                                         random_state=42,\n                                        )\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will use the Kaggle TPU "},{"metadata":{"trusted":true,"id":"jueOgILH4tne","outputId":"8acaa6b3-2962-498d-ea9f-5cd294db8062"},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"VoT-31RZ4tnf"},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nEPOCHS = 1\nBATCH_SIZE = 22 * strategy.num_replicas_in_sync\nMODEL = \"Rostlab/prot_bert_bfd\" # bert-base-multilingual-uncased","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MNCfhsKO4tnq"},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_val, y_val))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"s5X9_IyC4tnr"},"cell_type":"code","source":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(bert_test)\n    .batch(BATCH_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"NXEvpLzA4tnr"},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    transformer_layer = TFBertModel.from_pretrained(MODEL)\n    model = build_model(transformer_layer, max_len=380)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_steps = x_train.shape[0] // BATCH_SIZE\ntrain_history = model.fit(\n    train_dataset,\n    steps_per_epoch=n_steps,\n    validation_data=valid_dataset,\n    epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"TVB1upnT4tnt"},"cell_type":"code","source":"pred = model.predict(test_dataset, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"FV-_3rja4tnu"},"cell_type":"code","source":"test[\"LABEL\"]= 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"jGI683QC4tnu"},"cell_type":"code","source":"np.save('kk', pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"UgpbhHSk4tnv"},"cell_type":"code","source":"pred_sentiment = np.argmax(pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"XA5RAJwQ4tnv"},"cell_type":"code","source":"test[\"LABEL\"]= pred_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DvVDuIJP4tnv"},"cell_type":"code","source":"test[\"LABEL\"]= le.inverse_transform(test[\"LABEL\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"RO_jaAZi4tnw"},"cell_type":"code","source":"cc= [\"SEQUENCE_ID\", \"LABEL\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LcWC8T6d4tnw"},"cell_type":"code","source":"test= test[cc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"RH-_zhOy4tnx"},"cell_type":"code","source":"test.to_csv(\"submission49.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}