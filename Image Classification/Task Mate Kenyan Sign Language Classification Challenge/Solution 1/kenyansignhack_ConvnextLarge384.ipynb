{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Author : ASSAZZIN [ KSOURI Azer ]"
      ],
      "metadata": {
        "id": "OvvyjiVNyQlR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c74062"
      },
      "source": [
        "## SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c4b4c3a",
        "outputId": "d1e9bf48-5b4e-4a6b-dbb0-11890ad5a91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 28 09:29:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # TESLA V100 : 16Gb ram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9abe8c10"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown -q\n",
        "!pip install efficientnet_pytorch -q\n",
        "!pip uninstall albumentations --y\n",
        "!pip install albumentations==1.0.3 -q \n",
        "!pip install timm==0.4.12 -q\n",
        "!pip install yacs==0.1.8 pyyaml==5.4.1 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vua1jUvNHSgm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall opencv-python --y\n",
        "!pip install --upgrade opencv-python\n",
        "!pip install --upgrade opencv-contrib-python\n",
        "!pip install tensorboardX -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMLzInu2YkFF"
      },
      "outputs": [],
      "source": [
        "# Download Data \n",
        "\n",
        "! pip install kaggle -q\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkix6xNKM6No",
        "outputId": "fc69e3b1-9b7b-4de3-ced9-f2e600115aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading task-mate-kenyan-sign-language-classification.zip to /content\n",
            "100% 1.10G/1.10G [00:05<00:00, 256MB/s]\n",
            "100% 1.10G/1.10G [00:05<00:00, 233MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d ahmedmesslmani01/task-mate-kenyan-sign-language-classification\n",
        "!unzip -q  /content/task-mate-kenyan-sign-language-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuzpeqgHYkCd",
        "outputId": "73720b75-558f-4256-94a3-58032f42855a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Oh5jcmOKezToTvljcZ32vnHFwzyX9fLA\n",
            "To: /content/convnext.zip\n",
            "\r  0% 0.00/73.1k [00:00<?, ?B/s]\r100% 73.1k/73.1k [00:00<00:00, 74.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1Oh5jcmOKezToTvljcZ32vnHFwzyX9fLA\n",
        "!unzip -q convnext.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc1DtUWdkBDJ"
      },
      "outputs": [],
      "source": [
        "exit(0) # if you run on colab exit(0) will restart the session so packages versions will be updated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fbba65"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zupc9mWQYkAD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brCSKr3IZZ01"
      },
      "outputs": [],
      "source": [
        "import models.convnext\n",
        "import models.convnext_isotropic\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "250e77ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import io\n",
        "from tqdm import tqdm_notebook as tqdm \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score ,roc_curve, auc , f1_score , precision_score , log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from   torchvision import datasets, transforms, models\n",
        "from   torchvision import transforms\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from   torch.utils.data import DataLoader, Dataset\n",
        "from   torch.optim.lr_scheduler import MultiStepLR\n",
        "from   torch.optim.lr_scheduler import OneCycleLR\n",
        "from   torch.nn import functional as F\n",
        "from   torch.autograd import Variable\n",
        "\n",
        "import albumentations\n",
        "import albumentations as A\n",
        "import albumentations.augmentations.transforms as AT\n",
        "from   albumentations.pytorch.transforms import ToTensorV2\n",
        "import albumentations.augmentations.transforms as AT\n",
        "import albumentations.augmentations.geometric.transforms as AG\n",
        "import albumentations.augmentations.geometric.rotate as AGR\n",
        "from albumentations import (\n",
        "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
        "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose, RandomGamma, ElasticTransform, ChannelShuffle,RGBShift, Rotate\n",
        ")\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import yaml\n",
        "from yacs.config import CfgNode as CN\n",
        "from functools import reduce , wraps\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bde7a213"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "415ed853",
        "outputId": "ae17abd8-a2f5-4d7b-ff10-3c9cc52ce9da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9da31e05-f9a4-4fff-a081-74dd8d8f6108\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_IDS</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ImageID_33HMDMJ3</td>\n",
              "      <td>Temple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ImageID_V5POEX4O</td>\n",
              "      <td>Church</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ImageID_89CCCCW6</td>\n",
              "      <td>Enough/Satisfied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ImageID_GNJXOWX5</td>\n",
              "      <td>Me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ImageID_7Q9LOP7R</td>\n",
              "      <td>Love</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9da31e05-f9a4-4fff-a081-74dd8d8f6108')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9da31e05-f9a4-4fff-a081-74dd8d8f6108 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9da31e05-f9a4-4fff-a081-74dd8d8f6108');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            img_IDS             Label\n",
              "0  ImageID_33HMDMJ3            Temple\n",
              "1  ImageID_V5POEX4O            Church\n",
              "2  ImageID_89CCCCW6  Enough/Satisfied\n",
              "3  ImageID_GNJXOWX5                Me\n",
              "4  ImageID_7Q9LOP7R              Love"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "Train = pd.read_csv('Train.csv')\n",
        "Train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08b1ecd0"
      },
      "outputs": [],
      "source": [
        "targets = Train.Label.unique().tolist()\n",
        "\n",
        "Target_Mapper = dict(zip(targets,[i for i in range(len(targets))]))\n",
        "InverseTarget_Mapper = dict(zip([i for i in range(len(targets))],targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03719547"
      },
      "outputs": [],
      "source": [
        "Train.Label = Train.Label.map(Target_Mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a703d3f5"
      },
      "outputs": [],
      "source": [
        "Test = pd.read_csv('Test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f966572"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "904613d4"
      },
      "outputs": [],
      "source": [
        "_C = CN()\n",
        "\n",
        "_C.data = CN()\n",
        "_C.data.data_path = 'Images' # path of the folder that contains train and test images\n",
        "_C.data.Image_ID_col = 'img_IDS'\n",
        "_C.data.LABELS = 'Label'\n",
        "\n",
        "_C.preprocess=CN()\n",
        "_C.preprocess.input_shape = [384,384]\n",
        "\n",
        "_C.model = CN()\n",
        "_C.model.name_model = \"convnext_large\"\n",
        "\n",
        "_C.model.train_bs = 8\n",
        "_C.model.test_bs = 32\n",
        "\n",
        "_C.model.base_lr = 5e-5\n",
        "_C.model.weight_decay = 1e-6\n",
        "_C.model.epochs = 7\n",
        "\n",
        "_C.n_folds = 10\n",
        "_C.num_classes = 9\n",
        "_C.seed = 42\n",
        "_C.metric = 'LogLoss'\n",
        "_C.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def get_cfg_defaults():\n",
        "    \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
        "    # Return a clone so that the defaults will not be altered\n",
        "    # This is for the \"local variable\" use pattern\n",
        "    #return _C.clone()\n",
        "    return _C\n",
        "\n",
        "def dump_cfg(config = get_cfg_defaults() , path = \"experiment.yaml\"):\n",
        "    \"\"\"Save a yacs CfgNode object in a yaml file in path.\"\"\"\n",
        "    stream = open(path, 'w')\n",
        "    stream.write(config.dump())\n",
        "    stream.close()\n",
        "\n",
        "def inject_config(funct):\n",
        "    \"\"\"Inject a yacs CfgNode object in a function as first arg.\"\"\"\n",
        "    @wraps(funct)\n",
        "    def function_wrapper(*args,**kwargs):\n",
        "        return funct(*args,**kwargs,config=_C)  \n",
        "    return function_wrapper\n",
        "\n",
        "def dump_dict(config,path=\"config.yaml\"):\n",
        "        stream = open(path, 'w')\n",
        "        yaml.dump(config,stream)\n",
        "        stream.close()\n",
        "\n",
        "c=get_cfg_defaults()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0Wcbvw1UAXN"
      },
      "outputs": [],
      "source": [
        "if c.model.name_model =='convnext_base': \n",
        "  os.system(\"wget https://dl.fbaipublicfiles.com/convnext/convnext_base_22k_1k_384.pth\")\n",
        "elif c.model.name_model =='convnext_large':  \n",
        "  os.system(\"wget https://dl.fbaipublicfiles.com/convnext/convnext_large_22k_1k_384.pth\")\n",
        "else: \n",
        "  os.system(\"wget https://dl.fbaipublicfiles.com/convnext/convnext_xlarge_22k_1k_384_ema.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6692e2d1"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "824ef984"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    @inject_config\n",
        "    def __init__(self,df, transform=None,mode='train',config =CN):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.dir = config.data.data_path\n",
        "        self.Image_ID_col = config.data.Image_ID_col\n",
        "        self.LABELS = config.data.LABELS\n",
        "\n",
        "    def cv_reader(self,path):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = os.path.join(self.dir,f\"{self.df[self.Image_ID_col][index]}.jpg\")\n",
        "        image = self.cv_reader(image_name)\n",
        "        if self.transform is not None:\n",
        "          image = self.transform(image=image)\n",
        "          image=image[\"image\"]\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            label = self.df[self.LABELS][index]\n",
        "            return {'image' : torch.tensor(image,dtype=torch.float), \n",
        "                    'label' : torch.tensor(label,dtype = torch.float) }\n",
        "        return {'image' : torch.tensor(image,dtype=torch.float)}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2848d0a1"
      },
      "outputs": [],
      "source": [
        "class TimmModel(nn.Module):\n",
        "    @inject_config\n",
        "    def __init__(self,model_name,config:CN):\n",
        "        super().__init__()\n",
        "        if 'resne' in model_name : \n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.fc.in_features\n",
        "          self.model.global_pool = nn.Identity()\n",
        "          self.model.fc  = nn.Identity()\n",
        "          self.pooling = nn.AdaptiveAvgPool2d(1)  \n",
        "          self.fc  = nn.Linear(n_features,config.num_classes)  \n",
        "        elif 'efficient' in model_name :\n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.classifier.in_features\n",
        "          self.model.global_pool = nn.Identity()\n",
        "          self.model.classifier = nn.Identity()\n",
        "          self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "          self.fc  = nn.Linear(n_features,config.num_classes)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        bs = x.size(0)\n",
        "        features = self.model(x)\n",
        "        pooled_features = self.pooling(features).view(bs, -1)\n",
        "        output = self.fc(pooled_features)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce74e3b8"
      },
      "outputs": [],
      "source": [
        "class SwinModel(nn.Module):\n",
        "    @inject_config\n",
        "    def __init__(self,model_name,config:CN):\n",
        "        super().__init__()\n",
        "        if 'swin' in model_name or 'visformer_small' in model_name: \n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.in_features\n",
        "          self.model.head  = nn.Linear(n_features,config.num_classes)\n",
        "\n",
        "        elif 'cait' in model_name : \n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.in_features\n",
        "          self.model.head  = nn.Linear(n_features,config.num_classes)\n",
        "        else :\n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.fc.in_features\n",
        "          self.model.head.fc  = nn.Linear(n_features,config.num_classes)\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c0d9c4f"
      },
      "outputs": [],
      "source": [
        "class TrochvisionModel(nn.Module):\n",
        "    @inject_config\n",
        "    def __init__(self,model_name,config:CN):\n",
        "        super().__init__()\n",
        "        self.model = getattr(models, model_name)(True)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features,config.num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        pooled_features = self.model(x)\n",
        "        return  pooled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2isdjKhalXU"
      },
      "outputs": [],
      "source": [
        "class ImgClassifier(nn.Module):\n",
        "    @inject_config\n",
        "    def __init__(self, model_arch, in_channels=3,pretrained_path='',config=CN):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch,in_chans=in_channels, pretrained=False)\n",
        "        self.model=self.load_pretrain(self.model,pretrained_path)\n",
        "        num_ftrs = self.model.head.in_features\n",
        "        self.model.head = nn.Linear(num_ftrs, config.num_classes)\n",
        "    def load_pretrain(self,model,pretrained_path):\n",
        "        checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
        "        print(\"Load ckpt from %s\" % pretrained_path)\n",
        "        checkpoint_model = checkpoint['model']\n",
        "        state_dict = model.state_dict()\n",
        "        for k in ['head.weight', 'head.bias']:\n",
        "            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "                print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "                del checkpoint_model[k]\n",
        "        utils.load_state_dict(model, checkpoint_model, prefix='')\n",
        "        return model\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f89a300"
      },
      "outputs": [],
      "source": [
        "class AverageMeter():\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a148c75"
      },
      "outputs": [],
      "source": [
        "class Trainer :\n",
        "  @inject_config\n",
        "  def __init__(self,config : CN) :\n",
        "    self.device = config.device\n",
        "\n",
        "  def get_score(self,y_true, y_pred):\n",
        "    return f1_score(y_true, np.argmax(y_pred,axis=1),average='weighted')\n",
        "\n",
        "  def loss_fn(self,outputs,targets):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(outputs,targets)\n",
        "    return loss\n",
        "  \n",
        "  def train_fn(self,train_data_loader,model,optimizer,scheduler = None):\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    roc_auc = AverageMeter()\n",
        "    tk0 = tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    tot_loss = 0\n",
        "    for bi,d in enumerate(tk0):\n",
        "      images =  d['image']\n",
        "      labels =  d['label']\n",
        "      #send them to device \n",
        "      images  = images.to(self.device,dtype=torch.float)\n",
        "      labels  = labels.to(self.device,dtype=torch.long)\n",
        "\n",
        "      optimizer.zero_grad()    \n",
        "      outputs  = model(images)\n",
        "      loss = self.loss_fn(outputs,labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      tot_loss = tot_loss + loss.item()\n",
        "      losses.update(loss.item(), labels.size(0))\n",
        "      tk0.set_postfix(loss=losses.avg)\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    loss_score = tot_loss/len(train_data_loader)\n",
        "    f1_scoree = self.get_score(labels.cpu().numpy(), torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "    \n",
        "    print(\"Training loss for this epoch: \", loss_score)\n",
        "    print(\"Training F1 Score for this epoch: \", f1_scoree)\n",
        "    return f1_scoree\n",
        "\n",
        "  def eval_fn(self,valid_data_loader,model):\n",
        "    model.eval()\n",
        "    tot_loss = 0\n",
        "    final_outputs = []\n",
        "    final_targets = []\n",
        "    with torch.no_grad():\n",
        "      for bi,d in enumerate(valid_data_loader):\n",
        "        images = d['image']\n",
        "        labels = d['label']\n",
        "        #send them to device \n",
        "        images = images.to(self.device,dtype=torch.float)\n",
        "        labels = labels.to(self.device,dtype=torch.long)\n",
        "        \n",
        "        outputs  = model(images)\n",
        "        loss = self.loss_fn(outputs,labels)\n",
        "        tot_loss = tot_loss + loss.item()\n",
        "\n",
        "        final_outputs.append(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "        final_targets.append(labels.cpu().numpy())\n",
        "\n",
        "      final_targets = np.concatenate(final_targets)\n",
        "      final_outputs = np.concatenate(final_outputs)\n",
        "      \n",
        "      loss_score  = tot_loss/len(valid_data_loader)\n",
        "      f1_scoree = self.get_score(final_targets,final_outputs)\n",
        "      print(\"Validation loss for this epoch: \",loss_score)\n",
        "      print('Validation F1 Score for this epoch',f1_scoree)\n",
        "    return loss_score,f1_scoree , final_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUy18KqiEAR"
      },
      "outputs": [],
      "source": [
        "class RandomCenterCrop:\n",
        "    def __init__(self,height_limit , width_limit):\n",
        "        if isinstance(height_limit, (int, float)):\n",
        "          self.height_limit = [height_limit , 1]\n",
        "        else :\n",
        "          self.height_limit = height_limit\n",
        "\n",
        "        if isinstance(width_limit, (int, float)):\n",
        "          self.width_limit = [width_limit , 1]\n",
        "        else :\n",
        "          self.width_limit = width_limit\n",
        "\n",
        "    def __call__(self,image,**kwargs):\n",
        "        #print(\"image hey : \",image.shape)\n",
        "        height = int(random.uniform(self.height_limit[0] , self.height_limit[1]) * image.shape[0])\n",
        "        width = int(random.uniform(self.width_limit[0] , self.width_limit[1]) * image.shape[1])\n",
        "        return A.CenterCrop(height , width,p=1)(image=image)[\"image\"]\n",
        "\n",
        "class RandomCenterBlur:\n",
        "    def __init__(self,height_limit , width_limit, blur_limit):\n",
        "        if isinstance(height_limit, (int, float)):\n",
        "          self.height_limit = [height_limit , 1]\n",
        "        else :\n",
        "          self.height_limit = height_limit\n",
        "\n",
        "        if isinstance(width_limit, (int, float)):\n",
        "          self.width_limit = [width_limit , 1]\n",
        "        else :\n",
        "          self.width_limit = width_limit\n",
        "        \n",
        "        if isinstance(blur_limit, (int, float)):\n",
        "          self.blur_limit = [blur_limit , 199]\n",
        "        else :\n",
        "          self.blur_limit = blur_limit\n",
        "\n",
        "    def __call__(self,img,**kwargs):\n",
        "      y,x,_ = img.shape\n",
        "      height = int(random.uniform(self.height_limit[0] , self.height_limit[1]) * img.shape[0])\n",
        "      width = int(random.uniform(self.width_limit[0] , self.width_limit[1]) * img.shape[1])\n",
        "      startx = (x//2)-(width//2)\n",
        "      starty = (y//2)-(height//2)\n",
        "      center_img = img[starty:starty+height,startx:startx+width]\n",
        "      blured = A.Compose([A.GaussianBlur(blur_limit=self.blur_limit,always_apply=True ,p=1)])(image=center_img)['image']\n",
        "\n",
        "      # Insert ROI back into image\n",
        "      img[starty:starty+height,startx:startx+width] = blured\n",
        "      return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68f0bf7e"
      },
      "outputs": [],
      "source": [
        "class Augmentation :\n",
        "  @inject_config\n",
        "  def __init__(self,config :CN) :\n",
        "    self.input_shape = config.preprocess.input_shape\n",
        "    self.SEED_VAL  = config.seed\n",
        "    \n",
        "  def seed_all(self):\n",
        "        random.seed(self.SEED_VAL)\n",
        "        np.random.seed(self.SEED_VAL)\n",
        "        torch.manual_seed(self.SEED_VAL)\n",
        "        torch.cuda.manual_seed_all(self.SEED_VAL)\n",
        "        os.environ['PYTHONHASHSEED'] = str(self.SEED_VAL)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        \n",
        "  def train_transform(self,) :\n",
        "    self.seed_all()\n",
        "    train_transform = A.Compose([\n",
        "                              A.OneOf([\n",
        "                                    A.RandomResizedCrop (self.input_shape[0], self.input_shape[0], scale=(0.8, 1.0), ratio=(0.8, 1.0), p=0.5),       \n",
        "                                    A.Resize(height=self.input_shape[0], width=self.input_shape[1], p=0.5),\n",
        "                                  ]\n",
        "                                  , p=1),\n",
        "                              OneOf([\n",
        "                                     A.Lambda(name = \"RandomCenterBlur\" , \n",
        "                                    image= RandomCenterBlur(height_limit=[0.5 , 0.7] , width_limit=[0.7 , 0.9],blur_limit=(101,199)) ,\n",
        "                                    p=0.5)  , \n",
        "                                    #  MotionBlur(p=.2),\n",
        "                                    #  MedianBlur(blur_limit=3, p=.1),\n",
        "                                     Blur(blur_limit=15, p=.1),\n",
        "                              ], p=0.3),\n",
        "                              OneOf([CLAHE(clip_limit=4,p=0.5),\n",
        "                                     A.Equalize(p=0.3),\n",
        "                                     A.HueSaturationValue(p=0.3),\n",
        "                                     A.ColorJitter(p=0.3),\n",
        "                                    ], p=0.3),\n",
        "                              OneOf([\n",
        "                                     IAASharpen(p=0.1),\n",
        "                                    #  IAAEmboss(p=0.5),\n",
        "                                     RandomContrast(p=0.5),\n",
        "                                     RandomBrightness(p=0.5),\n",
        "                              ], p=0.3),\n",
        "                              OneOf([ \n",
        "                                  A.Transpose(p=0.05),\n",
        "                                  A.VerticalFlip(0.01),\n",
        "                                  # RandomRotate90(p=0.2),\n",
        "                              ], p=0.05),\n",
        "                              A.HorizontalFlip(p=0.3),\n",
        "                              A.Rotate (limit=45, interpolation=1, border_mode=4, value=None, mask_value=None, p=0.3),\n",
        "                              A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                              ToTensorV2(),\n",
        "                              ])\n",
        "    return train_transform\n",
        "  \n",
        "  def test_trasnform(self,Augstype='Resize') :\n",
        "    if   Augstype =='RandomCrop' : \n",
        "        test_transform = A.Compose([ \n",
        "                                  A.RandomResizedCrop (self.input_shape[0], self.input_shape[0], scale=(0.8, 1.0), ratio=(0.8, 1.0), p=1.0),\n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "    elif Augstype == 'Center_Crop_Resize' :\n",
        "        test_transform = A.Compose([ \n",
        "                                  A.Lambda(name = \"RandomCenterCrop\" , image = RandomCenterCrop( height_limit=[0.7 , 0.9] , width_limit=[0.95 , 1] ) , p = 1.0),\n",
        "                                  A.Resize(height=self.input_shape[0], width=self.input_shape[1],p=1),\n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "    elif Augstype == 'Resize' :\n",
        "        test_transform = A.Compose([ \n",
        "                                  A.Resize(height=self.input_shape[0], width=self.input_shape[1],p=1),\n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "    elif Augstype == 'HueFilpResize' :\n",
        "        test_transform = A.Compose([ A.HueSaturationValue(p=1.0),\n",
        "                                  A.Resize(height=self.input_shape[0], width=self.input_shape[1],p=1),\n",
        "                                  A.HorizontalFlip(p=1.0),  \n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "    elif Augstype == 'RRR_PROCESS' :\n",
        "        test_transform = A.Compose([ \n",
        "                                  A.OneOf([\n",
        "                                    A.RandomResizedCrop (self.input_shape[0], self.input_shape[0], scale=(0.8, 1.0), ratio=(0.8, 1.0), p=0.8),       \n",
        "                                    A.Resize(height=self.input_shape[0], width=self.input_shape[1], p=0.2),\n",
        "                                  ]\n",
        "                                  , p=1),\n",
        "                                  OneOf([CLAHE(clip_limit=2),\n",
        "                                     IAASharpen(),\n",
        "                                     IAAEmboss(),\n",
        "                                     RandomContrast(),\n",
        "                                     RandomBrightness(),\n",
        "                                  ], p=0.3),\n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "        \n",
        "    return test_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47df5cd0"
      },
      "outputs": [],
      "source": [
        "class PytorchTrainer :\n",
        "  @inject_config\n",
        "  def __init__(self, config:CN) :\n",
        "    \n",
        "    self.model_name  = config.model.name_model\n",
        "    self.EPOCHS  = config.model.epochs\n",
        "    self.lr  = config.model.base_lr\n",
        "    self.weight_decay = config.model.weight_decay\n",
        "    self.train_bs = config.model.train_bs\n",
        "    self.test_bs = config.model.test_bs\n",
        "    self.LABELS = config.data.LABELS\n",
        "    self.NTargets = config.num_classes\n",
        "    self.device   = config.device\n",
        "    self.SEED_VAL  = config.seed\n",
        "    self.n_splits  = config.n_folds\n",
        "    self.metric = config.metric\n",
        "  \n",
        "  def get_score(self,y_true, y_pred):\n",
        "    return accuracy_score(y_true, np.argmax(y_pred,axis=1))\n",
        "\n",
        "  def seed_all(self):\n",
        "        random.seed(self.SEED_VAL)\n",
        "        np.random.seed(self.SEED_VAL)\n",
        "        torch.manual_seed(self.SEED_VAL)\n",
        "        torch.cuda.manual_seed_all(self.SEED_VAL)\n",
        "        os.environ['PYTHONHASHSEED'] = str(self.SEED_VAL)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False \n",
        "\n",
        "  def kfold_split(self,Train,y):\n",
        "        Train[\"folds\"]=-1\n",
        "        kf = StratifiedKFold(n_splits= self.n_splits,random_state=self.SEED_VAL,shuffle=True)\n",
        "        for fold, (_, val_index) in enumerate(kf.split(Train,y)):\n",
        "                Train.loc[val_index, \"folds\"] = fold\n",
        "        return Train\n",
        "  \n",
        "  def Train_One_Fold(self,train_df , valid_df,fold):\n",
        "    self.seed_all()\n",
        "    trainer = Trainer()\n",
        "    augs = Augmentation()\n",
        "\n",
        "    train_transform = augs.train_transform()\n",
        "    val_transform   = augs.test_trasnform()\n",
        "\n",
        "    train_dataset = ImageDataset(train_df.reset_index(),train_transform)\n",
        "    valid_dataset = ImageDataset(valid_df.reset_index(),val_transform)\n",
        "    \n",
        "    train_data_loader = DataLoader(dataset=train_dataset,shuffle=True,batch_size=self.train_bs)\n",
        "    valid_data_loader = DataLoader(dataset=valid_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "    \n",
        "    if 'eff' in self.model_name or 'resnest' in self.model_name or 'resnet200d' in self.model_name : \n",
        "        model = TimmModel(model_name=self.model_name) \n",
        "        model.to(self.device)\n",
        "    elif 'swin' in self.model_name or 'vit' in self.model_name or 'cait' in self.model_name: \n",
        "        model = SwinModel(model_name=self.model_name) \n",
        "        model.to(self.device)\n",
        "    elif 'convnext' in self.model_name :\n",
        "        # model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_base_1k_384.pth')\n",
        "        model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_large_22k_1k_384.pth')\n",
        "        # model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_xlarge_22k_1k_384_ema.pth')\n",
        "        model.to(self.device)\n",
        "    else :\n",
        "        model = TrochvisionModel(model_name=self.model_name) \n",
        "        model.to(self.device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "    best_score = np.inf\n",
        "    for epoch in range(self.EPOCHS):\n",
        "      print(\"----------------EPOCH \"+str(epoch+1)+\"---------------------\")\n",
        "      Acc_train = trainer.train_fn(train_data_loader, model, optimizer,scheduler=None)\n",
        "      loss_val,Score_val,oof_ = trainer.eval_fn(valid_data_loader ,model)\n",
        "      if loss_val<best_score:\n",
        "        best_score = loss_val \n",
        "        oof_1f = np.copy(oof_) \n",
        "        torch.save(model.state_dict(),f\"best_model_{fold}\") \n",
        "    return oof_1f , best_score \n",
        "\n",
        "  def Train_K_folds(self,train):\n",
        "    self.seed_all()\n",
        "    oof = np.zeros((train.shape[0],self.NTargets))\n",
        "    train = self.kfold_split(train,train[self.LABELS])\n",
        "    \n",
        "    for fold in  [9] : #range(self.n_splits):\n",
        "      print(f\"#########################  Fold {fold+1}/{self.n_splits}  #########################\")\n",
        "      train_df = train[train['folds']!=fold]\n",
        "      valid_df = train[train['folds']==fold]\n",
        "      oof_1f , best_score = self.Train_One_Fold(train_df , valid_df,fold)\n",
        "      oof[valid_df.index.tolist()] = oof_1f \n",
        "      free_memory(sleep_time=0.1)\n",
        "    print(f'{self.metric} OOF Score :',self.get_score(train[self.LABELS],oof))\n",
        "    return oof\n",
        "\n",
        "  def InferenceValid(self,valid_df,Augstype='Resize') :\n",
        "    self.seed_all()\n",
        "    print(f'Inference On {Augstype} Augs ...')\n",
        "    augs = Augmentation()\n",
        "    test_transform   = augs.test_trasnform(Augstype=Augstype)\n",
        "    valid_dataset = ImageDataset(valid_df.reset_index(drop=True),test_transform,mode='test')\n",
        "    test_data_loader = DataLoader(dataset=valid_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "    if 'eff' in self.model_name or 'resnest' in self.model_name or 'resnet200d' in self.model_name :  \n",
        "        best_model = TimmModel(model_name=self.model_name) \n",
        "    elif 'swin' in self.model_name or 'vit' in self.model_name or 'cait' in self.model_name: \n",
        "        best_model = SwinModel(model_name=self.model_name) \n",
        "    elif 'convnext' in self.model_name :\n",
        "        # best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_base_1k_384.pth')\n",
        "        best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_large_22k_1k_384.pth')\n",
        "        # best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_xlarge_22k_1k_384_ema.pth')\n",
        "        best_model.to(self.device)\n",
        "    else :\n",
        "        best_model = TrochvisionModel(model_name=self.model_name) \n",
        "    best_model.load_state_dict(torch.load(f'best_model_{fold}'))\n",
        "    best_model.to(self.device)\n",
        "    best_model.eval()\n",
        "    \n",
        "    final_outputs = []\n",
        "    with torch.no_grad() :\n",
        "        tk0 = tqdm(test_data_loader, total=len(test_data_loader))\n",
        "        for bi,d in enumerate(tk0):\n",
        "          images = d['image']\n",
        "          #send them to device \n",
        "          images = images.to(self.device,dtype=torch.float)\n",
        "          outputs  = best_model(images)\n",
        "          final_outputs.append(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "\n",
        "    final_outputs = np.concatenate(final_outputs)\n",
        "    Final_Prediction   = np.argmax(final_outputs,axis=1)\n",
        "    return  final_outputs , Final_Prediction \n",
        "\n",
        "  def Inference(self,test,Augstype='Resize') :\n",
        "    augs = Augmentation()\n",
        "    test_transform   = augs.test_trasnform(Augstype=Augstype)\n",
        "\n",
        "    test_dataset = ImageDataset(test.reset_index(drop=True),test_transform,mode='test')\n",
        "    test_data_loader = DataLoader(dataset=test_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "\n",
        "    all_folds = []\n",
        "    for fold in range(self.n_splits):\n",
        "      print(f\"#########################  Fold {fold+1}/{self.n_splits}  #########################\")\n",
        "      if 'eff' in self.model_name or 'resnest' in self.model_name  or 'resnet200d' in self.model_name : \n",
        "        best_model = TimmModel(model_name=self.model_name) \n",
        "      elif 'swin' in self.model_name or 'vit' in self.model_name or 'rexnet_200' in self.model_name:\n",
        "          best_model = SwinModel(model_name=self.model_name) \n",
        "      elif 'convnext' in self.model_name :\n",
        "        # best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_base_1k_384.pth')\n",
        "        best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_large_22k_1k_384.pth')\n",
        "        # best_model = ImgClassifier(model_arch=self.model_name,pretrained_path='convnext_xlarge_22k_1k_384_ema.pth')\n",
        "        best_model.to(self.device)\n",
        "      else :\n",
        "          best_model = TrochvisionModel(model_name=self.model_name) \n",
        "        \n",
        "      best_model.load_state_dict(torch.load(f'best_model_{fold}'))\n",
        "      best_model.to(self.device)\n",
        "      best_model.eval()\n",
        "      final_outputs = []\n",
        "      with torch.no_grad() :\n",
        "        tk0 = tqdm(test_data_loader, total=len(test_data_loader))\n",
        "        for bi,d in enumerate(tk0):\n",
        "          images = d['image']\n",
        "          #send them to device \n",
        "          images = images.to(self.device,dtype=torch.float)\n",
        "          outputs  = best_model(images)\n",
        "          final_outputs.append(F.softmax(outputs, dim=1).data.squeeze().cpu().detach().numpy())\n",
        "\n",
        "      final_outputs = np.concatenate(final_outputs)\n",
        "      all_folds.append(final_outputs)\n",
        "    Final_Prediction_f = np.mean(all_folds,axis=0)\n",
        "    Final_Prediction   = np.argmax(Final_Prediction_f,axis=1)\n",
        "    return  Final_Prediction_f , Final_Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "709c3e38"
      },
      "outputs": [],
      "source": [
        "AssazzinTrainer = PytorchTrainer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac9726cc"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ce0a0c",
        "outputId": "047d8d25-284b-44e2-cd3a-a8556664b000"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "449"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import gc ; gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6kvjYfXJ72A"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import time\n",
        "def free_memory(sleep_time=0.1) :\n",
        "    \"\"\" Black magic function to free torch memory and some jupyter whims \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    time.sleep(sleep_time)\n",
        "\n",
        "free_memory(sleep_time=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfdfc0fb"
      },
      "outputs": [],
      "source": [
        "OOF = AssazzinTrainer.Train_K_folds(train=Train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a78b68f9"
      },
      "source": [
        "# Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sEqWCXkxg7sm"
      },
      "outputs": [],
      "source": [
        "free_memory(sleep_time=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d756123"
      },
      "outputs": [],
      "source": [
        "Final_Prediction_f1 , _ = AssazzinTrainer.Inference(test=Test,Augstype ='Resize')\n",
        "print('-----------')\n",
        "Final_Prediction_f2 , _ = AssazzinTrainer.Inference(test=Test,Augstype ='Center_Crop_Resize')\n",
        "print('-----------')\n",
        "Final_Prediction_f3 , _ = AssazzinTrainer.Inference(test=Test,Augstype ='RandomCrop')\n",
        "print('-----------')\n",
        "Final_Prediction_f4 , _ = AssazzinTrainer.Inference(test=Test,Augstype ='RRR_PROCESS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25300981"
      },
      "outputs": [],
      "source": [
        "Final_Prediction = Final_Prediction_f1*0.25+Final_Prediction_f2*0.25+Final_Prediction_f3*0.25+Final_Prediction_f4*0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "945dd767"
      },
      "outputs": [],
      "source": [
        "np.save(f'AssazzinBaseline_{c.model.name_model}_Preds_TTAx4.npy',Final_Prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHrW4FFFQoHf"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import gmean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq9DLSGuQoHf"
      },
      "outputs": [],
      "source": [
        "def weighted_gmean(weights,predictions) :\n",
        "  weighted_gmean = 0\n",
        "  sum_1 =0\n",
        "  sum_2 =0\n",
        "  for i in range(len(weights)) :\n",
        "    sum_1 += weights[i]* np.log(predictions[i])\n",
        "    sum_2 += weights[i]\n",
        "  weighted_gmean += np.exp(sum_1/sum_2)\n",
        "  return weighted_gmean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGUT6MgTQoHg"
      },
      "outputs": [],
      "source": [
        "test_dict = {'Original': Final_Prediction_f1, \n",
        "            'CenterCrop': Final_Prediction_f2, \n",
        "            'RandomCrop': Final_Prediction_f3, \n",
        "            'Koktel': Final_Prediction_f4, \n",
        "           }\n",
        "BlendTest = np.zeros((len(test_dict), Test.shape[0],y_true.shape[1]))\n",
        "for i in range(BlendTest.shape[0]):\n",
        "    BlendTest[i] = np.array(list(test_dict.values())[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYyXhLNNQoHg"
      },
      "outputs": [],
      "source": [
        "GmeanPreds = weighted_gmean([0.47597992, 0.22984611, 0.164385  , 0.12978896],BlendTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb631mJwRMxK"
      },
      "outputs": [],
      "source": [
        "np.save(f'AssazzinBaseline_{c.model.name_model}_GmeanPreds_TTAx4.npy',GmeanPreds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "kenyansignhack_ConvnextLarge384.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}