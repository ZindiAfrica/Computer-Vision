{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from helper.utils import *\n",
    "from helper.cross_validation import *\n",
    "from config import *\n",
    "random_seed_cpu(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(join(raw_data_path, \"balanced_train.pkl\"))\n",
    "test = pd.read_pickle(join(raw_data_path, \"test.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=train.drop([\"target\",\"image_id\",\"event_id\"],1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"count_>_zero\"]=train[features].apply(lambda x :( x>0).sum(),axis=1)\n",
    "test[\"count_>_zero\"]=test[features].apply(lambda x :( x>0).sum(),axis=1)\n",
    "\n",
    "train[\"count_=_zero\"]=train[features].apply(lambda x :( x==0).sum(),axis=1)\n",
    "test[\"count_=_zero\"]=test[features].apply(lambda x :( x==0).sum(),axis=1)\n",
    "\n",
    "train[\"mean_>_zero\"]=train[features].apply(lambda x :x[x>0].mean(),axis=1)\n",
    "test[\"mean_>_zero\"]=test[features].apply(lambda x :x[x>0].mean(),axis=1)\n",
    "\n",
    "train[\"arg_max\"]=train[features].apply(lambda x:int( np.argmax(x).split(\"_\")[-1]),1)\n",
    "test[\"arg_max\"]=test[features].apply(lambda x:int( np.argmax(x).split(\"_\")[-1]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_per_row={ i : [ \"feat_\"+str(j) for j in range(i*10,(i+1)*10)] \n",
    "                 for i in range( 10 )}\n",
    "features_per_columns ={ i : [ \"feat_\"+str(j*10+i) for j in range(10)] \n",
    "                 for i in range( 10 )}\n",
    "for key,value in zip(features_per_row.keys(),features_per_row.values()):\n",
    "    train[\"count_>_zero_row_\"+str(key)]=train[features].apply(lambda x :( x[value]>0).sum(),axis=1)\n",
    "    test[\"count_>_zero_row_\"+str(key)]=test[features].apply(lambda x :( x[value]>0).sum(),axis=1)\n",
    "    train[\"count_=_zero_row_\"+str(key)]=train[features].apply(lambda x :( x[value]==0).sum(),axis=1)\n",
    "    test[\"count_=_zero_row_\"+str(key)]=test[features].apply(lambda x :( x[value]==0).sum(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in zip(features_per_columns.keys(),features_per_columns.values()):\n",
    "    train[\"count_>_zero_column_\"+str(key)]=train[features].apply(lambda x :( x[value]>0).sum(),axis=1)\n",
    "    test[\"count_>_zero_column_\"+str(key)]=test[features].apply(lambda x :( x[value]>0).sum(),axis=1)\n",
    "    train[\"count_=_zero_column_\"+str(key)]=train[features].apply(lambda x :( x[value]==0).sum(),axis=1)\n",
    "    test[\"count_=_zero_column_\"+str(key)]=test[features].apply(lambda x :( x[value]==0).sum(),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = cross_validation(\n",
    "    train_df=train,\n",
    "    _id_=\"image_id\",\n",
    "    target_name=\"target\",\n",
    "    kfold_type=\"skfold\",\n",
    "    output_dir=proc_data_path,\n",
    "    split_ratio=0.1,\n",
    "    nfolds=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    shuffle=True,\n",
    "    stratify=False,\n",
    ")\n",
    "train = CV.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "train.to_csv(join(proc_data_path, \"train_{}.csv\".format(version)), index=False)\n",
    "test.to_csv(join(proc_data_path, \"test_{}.csv\".format(version)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
