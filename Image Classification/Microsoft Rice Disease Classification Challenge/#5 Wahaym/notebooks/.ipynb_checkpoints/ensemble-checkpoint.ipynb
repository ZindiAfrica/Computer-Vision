{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27726c3-3362-435d-ab4b-f8b99637d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "from sklearn.metrics import roc_auc_score,log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829890e-2654-418c-9361-9777b2f1d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(\"../ensemble/\"):\n",
    "    os.makedirs(\"../ensemble/\")\n",
    "if not os.path.exists(\"../sub/\"):\n",
    "    os.makedirs(\"../sub/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e90d35-977e-4d83-93b8-96de9a5d705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oof(exp_names,n_splits=5):\n",
    "    \n",
    "    for exp_name in exp_names:\n",
    "        if os.path.exists(f\"../ensemble/{exp_name}.csv\"):\n",
    "            continue\n",
    "        logits=[]\n",
    "        labels=[]\n",
    "        indexes=[]\n",
    "        for f in range(n_splits):\n",
    "            results_path=f\"../result/{exp_name}/{f}/val_rgb_results.npz\"\n",
    "            results = np.load(results_path)\n",
    "            logits.append(results[\"pred_logit\"])\n",
    "            labels.append(results[\"label\"])\n",
    "            indexes.append(results[\"original_index\"])\n",
    "        logits=np.concatenate(logits,axis=0)\n",
    "        logits=torch.tensor(logits,dtype=torch.float64)\n",
    "        preds=F.softmax(logits).numpy()\n",
    "        labels=np.expand_dims(np.concatenate(labels,axis=0), axis=1)\n",
    "        indexes=np.expand_dims(np.concatenate(indexes,axis=0), axis=1)\n",
    "        df=pd.DataFrame(np.concatenate([indexes,labels,preds],axis=1),\n",
    "                        columns=[\"Image_id\",\"target\",\"blast\",\"brown\",\"healthy\"])\n",
    "        df.to_csv(f\"../ensemble/{exp_name}.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54f0d5-ab84-4c0f-a606-09ba557d31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_names=[\"beit_224aug\",\"deit_384\",\"swin_base_384v2\",\"swin_large_192v2\",\"swin_base_256v2cv\",\"vit_r50\",\"cnvxt_384\",\"vit_384_cv\",\"vit_224_cv\"]\n",
    "make_oof(exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101ea19-88a8-4af3-8ca1-90fce5238af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../ensemble/'\n",
    "FILES = os.listdir(PATH)\n",
    "\n",
    "OOF = np.sort( [f for f in FILES if 'oof' in f] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0937b9f-ac56-4e1f-ae66-c7b00cce3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF=exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a08794-ca04-46c6-a6f0-cae1531f6e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_CSV = [pd.read_csv(PATH+k+\".csv\") for k in OOF]\n",
    "\n",
    "print('We have %i oof files...'%len(OOF))\n",
    "print(); print(OOF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1821805-836c-4cf1-95a5-cc1517181739",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(( len(OOF_CSV[0]),len(OOF),OOF_CSV[0].shape[1]-2 ))\n",
    "for k in range(len(OOF)):\n",
    "    x[:,k,:] = OOF_CSV[k].iloc[:,2:].values\n",
    "    \n",
    "TRUE = OOF_CSV[0].target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89e253-3e9a-409f-b3eb-5b0186667f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc5c59-d270-4b16-bbe9-f1dbf0121887",
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "for k in range(x.shape[1]):\n",
    "    loss = log_loss(TRUE,x[:,k])\n",
    "    all.append(loss)\n",
    "    print('%s = %.4f'%(OOF[k],loss))\n",
    "m=[np.argmin(all)]    \n",
    "#m = [1]; \n",
    "w = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f8146-c4d3-4582-a85b-64348b6a86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = np.min(all); \n",
    "RES = 400; \n",
    "PATIENCE = 10; \n",
    "TOL = 0.000\n",
    "DUPLICATES = False\n",
    "\n",
    "print('Ensemble LogLoss= %.4f by beginning with model %i'%(old,m[0]))\n",
    "print()\n",
    "\n",
    "for kk in range(len(OOF)):\n",
    "    \n",
    "    # BUILD CURRENT ENSEMBLE\n",
    "    md = x[:,m[0]]\n",
    "    for i,k in enumerate(m[1:]):\n",
    "        md = w[i]*x[:,k] + (1-w[i])*md\n",
    "        \n",
    "    # FIND MODEL TO ADD\n",
    "    mx = 10; mx_k = 0; mx_w = 0\n",
    "    print('Searching for best model to add... ')\n",
    "    \n",
    "    # TRY ADDING EACH MODEL\n",
    "    for k in range(x.shape[1]):\n",
    "        #import pdb;pdb.set_trace()\n",
    "        print(k,', ',end='')\n",
    "        if not DUPLICATES and (k in m): continue\n",
    "            \n",
    "        # EVALUATE ADDING MODEL K WITH WEIGHTS W\n",
    "        bst_j = 0; bst = 10; ct = 0\n",
    "        for j in range(RES):\n",
    "            tmp = j/RES*x[:,k] + (1-j/RES)*md\n",
    "            loss = log_loss(TRUE,tmp)\n",
    "            if loss<bst:\n",
    "                bst = loss\n",
    "                bst_j = j/RES\n",
    "            else: ct += 1\n",
    "            if ct>PATIENCE: break\n",
    "        if bst<mx:\n",
    "            mx = bst\n",
    "            mx_k = k\n",
    "            mx_w = bst_j\n",
    "            \n",
    "    # STOP IF decrease IS LESS THAN TOL\n",
    "    dec = old-mx\n",
    "    if dec<=TOL: \n",
    "        print(); print('No decreasing. Stopping.')\n",
    "        break\n",
    "        \n",
    "    # DISPLAY RESULTS\n",
    "    print(); #print(kk,mx,mx_k,mx_w,'%.5f'%inc)\n",
    "    print('Ensemble LogLoss = %.4f after adding model %i with weight %.3f. decrease of %.4f'%(mx,mx_k,mx_w,dec))\n",
    "    print()\n",
    "    \n",
    "    old = mx; m.append(mx_k); w.append(mx_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d4901-7d1e-45e6-97d0-e2cd6f23caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are using models',m)\n",
    "print('with weights',w)\n",
    "print('and achieve ensemble AUC = %.4f'%old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b52638-e257-448b-a617-3facf46b432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = OOF_CSV[0].copy()\n",
    "df.pred = md\n",
    "df.to_csv('../ensemble/ensemble_oof.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5e43f-c208-4438-a544-26aa7e8f2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sub(exp_names,n_splits=5):\n",
    "    \n",
    "    for exp_name in exp_names:\n",
    "        if os.path.exists(f\"../sub/{exp_name}.csv\"):\n",
    "            continue\n",
    "        predictions=[]\n",
    "        for f in range(n_splits):\n",
    "            results_path=f\"../result/{exp_name}/{f}/test_rgb_results.npz\"\n",
    "            results = np.load(results_path)\n",
    "            logits=torch.tensor(results[\"pred_logit\"],dtype=torch.float64)\n",
    "            preds=F.softmax(logits).numpy()\n",
    "            predictions.append(np.expand_dims(preds,axis=-1))\n",
    "        predictions=np.concatenate(predictions,axis=-1).mean(-1)\n",
    "        \n",
    "        df_sub=pd.read_csv(\"../input/SampleSubmission.csv\")\n",
    "        df_sub.iloc[:,1:]=predictions\n",
    "        df_sub.to_csv(f\"../sub/{exp_name}.csv\",index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c76f86-bb33-4a78-acf4-0be2e59b8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sub(exp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d3ebc-1347-41a6-84d7-2eaf2700402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = np.sort( [f for f in FILES if 'sub' in f] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617030dc-027a-4c12-8c70-2303f50d0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB = exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86198315-a35a-4d3a-a3da-2aeb58eae5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SUB_CSV = [pd.read_csv(\"../sub/\"+k+\".csv\") for k in SUB]\n",
    "\n",
    "print('We have %i submission files...'%len(SUB))\n",
    "print(); print(SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b9c48-cf22-4b81-a62e-8205fc77f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(( len(SUB_CSV[0]),len(SUB),SUB_CSV[0].shape[1]-1  ))\n",
    "for k in range(len(SUB)):\n",
    "    y[:,k] = SUB_CSV[k].iloc[:,1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c1bb9-4207-4cf2-81db-00aa4bd3e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b89c5-e3af-446c-b5cc-5748b5b1d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = y[:,m[0]]\n",
    "for i,k in enumerate(m[1:]):\n",
    "    md2 = w[i]*y[:,k] + (1-w[i])*md2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90c06b-f942-4b74-97ca-9cb2f53af8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "md2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83eb3e-4b4f-4472-8e6c-088f8b28cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = SUB_CSV[0].copy()\n",
    "df.target = md2\n",
    "df.to_csv('../ensemble_last.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f29f7-d23f-4d4d-a560-7e5c0361303f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
