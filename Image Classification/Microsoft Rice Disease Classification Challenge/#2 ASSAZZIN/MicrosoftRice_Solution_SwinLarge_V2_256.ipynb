{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43c74062"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c4b4c3a",
        "outputId": "da6816fa-f235-4af5-b7f0-7b8922d64065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 11 08:06:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # I want TESLA A100 please "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r83-xkeqKTIA",
        "outputId": "f0ad9dcf-3332-4e20-dc99-bec3ada11af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9abe8c10"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gdown -q\n",
        "!pip install efficientnet_pytorch -q\n",
        "!pip uninstall albumentations --y\n",
        "!pip install albumentations==1.0.3 -q \n",
        "!pip install timm -q\n",
        "!pip install yacs==0.1.8 pyyaml==5.4.1 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vua1jUvNHSgm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall opencv-python --y\n",
        "!pip install --upgrade opencv-python\n",
        "!pip install --upgrade opencv-contrib-python\n",
        "!pip install tensorboardX -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hn_6IcZKnRW"
      },
      "outputs": [],
      "source": [
        "!pip install timm -q\n",
        "!pip install yacs==0.1.8 pyyaml==5.4.1 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb6WwLjusbNj"
      },
      "outputs": [],
      "source": [
        "!cp '/content/drive/MyDrive/Microsoft_Rice_Disease/Images.zip' .\n",
        "!cp '/content/drive/MyDrive/Microsoft_Rice_Disease/Train.csv' .\n",
        "!cp '/content/drive/MyDrive/Microsoft_Rice_Disease/Test.csv' .\n",
        "!cp '/content/drive/MyDrive/Microsoft_Rice_Disease/SampleSubmission.csv' ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2BPvCKDH_j_"
      },
      "outputs": [],
      "source": [
        "# Unzipping the provided images\n",
        "!mkdir -p images\n",
        "!unzip -q Images.zip -d images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc1DtUWdkBDJ"
      },
      "outputs": [],
      "source": [
        "exit(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50fbba65"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "250e77ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy  as np\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "import io\n",
        "from tqdm import tqdm_notebook as tqdm \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score ,roc_curve, auc , f1_score , precision_score , log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from   torchvision import datasets, transforms, models\n",
        "from   torchvision import transforms\n",
        "\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from   torch.utils.data import DataLoader, Dataset\n",
        "from   torch.optim.lr_scheduler import MultiStepLR\n",
        "from   torch.optim.lr_scheduler import OneCycleLR\n",
        "from   torch.nn import functional as F\n",
        "from   torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import albumentations\n",
        "import albumentations as A\n",
        "import albumentations.augmentations.transforms as AT\n",
        "from   albumentations.pytorch.transforms import ToTensorV2\n",
        "import albumentations.augmentations.transforms as AT\n",
        "import albumentations.augmentations.geometric.transforms as AG\n",
        "import albumentations.augmentations.geometric.rotate as AGR\n",
        "from albumentations import (\n",
        "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,RandomCrop,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
        "    IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, Flip, OneOf, Compose, RandomGamma, ElasticTransform, ChannelShuffle,RGBShift, Rotate\n",
        ")\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from scipy.stats import gmean\n",
        "\n",
        "import yaml\n",
        "from yacs.config import CfgNode as CN\n",
        "from functools import reduce , wraps\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bde7a213"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "415ed853",
        "outputId": "853e2614-a273-42c5-de7a-d63edf94640c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Image_id  Label\n",
              "0      id_004wknd7qd.jpg  blast\n",
              "1  id_004wknd7qd_rgn.jpg  blast\n",
              "2      id_005sitfgr2.jpg  brown\n",
              "3  id_005sitfgr2_rgn.jpg  brown\n",
              "4      id_00stp9t6m6.jpg  blast"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ab889de-67c6-4df5-99fe-464a139eb856\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_id</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id_004wknd7qd.jpg</td>\n",
              "      <td>blast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id_004wknd7qd_rgn.jpg</td>\n",
              "      <td>blast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id_005sitfgr2.jpg</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id_005sitfgr2_rgn.jpg</td>\n",
              "      <td>brown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id_00stp9t6m6.jpg</td>\n",
              "      <td>blast</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ab889de-67c6-4df5-99fe-464a139eb856')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ab889de-67c6-4df5-99fe-464a139eb856 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ab889de-67c6-4df5-99fe-464a139eb856');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "Train = pd.read_csv('Train.csv')\n",
        "Train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08b1ecd0"
      },
      "outputs": [],
      "source": [
        "targets = Train.Label.unique().tolist()\n",
        "\n",
        "Target_Mapper = dict(zip(targets,[i for i in range(len(targets))]))\n",
        "InverseTarget_Mapper = dict(zip([i for i in range(len(targets))],targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03719547"
      },
      "outputs": [],
      "source": [
        "Train.Label = Train.Label.map(Target_Mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a703d3f5"
      },
      "outputs": [],
      "source": [
        "Test = pd.read_csv('Test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llItBvXqO-HI"
      },
      "outputs": [],
      "source": [
        "Train = Train[~Train.Image_id.str.contains('_rgn')].reset_index(drop=True) # Just the RGB images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f966572"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "904613d4"
      },
      "outputs": [],
      "source": [
        "_C = CN()\n",
        "\n",
        "_C.data = CN()\n",
        "_C.data.data_path = 'images' # path of the folder that contains train and test images\n",
        "_C.data.Image_ID_col = 'Image_id'\n",
        "_C.data.LABELS = 'Label'\n",
        "\n",
        "_C.preprocess=CN()\n",
        "_C.preprocess.input_shape = [256,256]\n",
        "_C.preprocess.crop_shape  = [256,256]\n",
        "\n",
        "_C.model = CN()\n",
        "_C.model.name_model = \"swinv2_large_window12to16_192to256_22kft1k\"\n",
        "\n",
        "_C.model.train_bs = 64\n",
        "_C.model.n_accumulate = 8\n",
        "_C.model.test_bs = 64\n",
        "\n",
        "_C.model.base_lr = 5e-5\n",
        "_C.model.weight_decay = 1e-6\n",
        "_C.model.epochs = 50\n",
        "_C.model.scheduler = \"ReduceLROnPlateau\"\n",
        "_C.model.min_lr = 1e-6\n",
        "_C.model.factor = 0.9\n",
        "_C.model.patience = 3\n",
        "\n",
        "_C.n_folds = 10\n",
        "_C.num_classes = len(targets)\n",
        "_C.seed = 42\n",
        "_C.metric = 'LogLoss'\n",
        "_C.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def get_cfg_defaults():\n",
        "    \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
        "    # Return a clone so that the defaults will not be altered\n",
        "    # This is for the \"local variable\" use pattern\n",
        "    #return _C.clone()\n",
        "    return _C\n",
        "\n",
        "def dump_cfg(config = get_cfg_defaults() , path = \"experiment.yaml\"):\n",
        "    \"\"\"Save a yacs CfgNode object in a yaml file in path.\"\"\"\n",
        "    stream = open(path, 'w')\n",
        "    stream.write(config.dump())\n",
        "    stream.close()\n",
        "\n",
        "def inject_config(funct):\n",
        "    \"\"\"Inject a yacs CfgNode object in a function as first arg.\"\"\"\n",
        "    @wraps(funct)\n",
        "    def function_wrapper(*args,**kwargs):\n",
        "        return funct(*args,**kwargs,config=_C)  \n",
        "    return function_wrapper\n",
        "\n",
        "def dump_dict(config,path=\"config.yaml\"):\n",
        "        stream = open(path, 'w')\n",
        "        yaml.dump(config,stream)\n",
        "        stream.close()\n",
        "\n",
        "c=get_cfg_defaults()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6692e2d1"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "824ef984"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    @inject_config\n",
        "    def __init__(self,df, transform=None,mode='train',config =CN):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "        self.dir = config.data.data_path\n",
        "        self.Image_ID_col = config.data.Image_ID_col\n",
        "        self.LABELS = config.data.LABELS\n",
        "\n",
        "    def cv_reader(self,path):\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return img\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = os.path.join(self.dir,f\"{self.df[self.Image_ID_col][index].split('.')[0]}.jpg\")\n",
        "        image = self.cv_reader(image_name)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "          image = self.transform(image=image)\n",
        "          image=image[\"image\"]\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            label = self.df[self.LABELS][index]\n",
        "            return {'image' : torch.tensor(image,dtype=torch.float), \n",
        "                    'label' : torch.tensor(label,dtype = torch.float) }\n",
        "        return {'image' : torch.tensor(image,dtype=torch.float)}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce74e3b8"
      },
      "outputs": [],
      "source": [
        "class SwinModel(nn.Module):\n",
        "    @inject_config\n",
        "    def __init__(self,model_name,config:CN):\n",
        "        super().__init__()\n",
        "        if 'swin' in model_name or 'visformer_small' in model_name: \n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.in_features\n",
        "          self.model.head  = nn.Linear(n_features,config.num_classes)\n",
        "\n",
        "        elif 'cait' in model_name : \n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.in_features\n",
        "          self.model.head  = nn.Linear(n_features,config.num_classes)\n",
        "        else :\n",
        "          self.model = timm.create_model(model_name, pretrained=True)\n",
        "          n_features = self.model.head.fc.in_features\n",
        "          self.model.head.fc  = nn.Linear(n_features,config.num_classes)\n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f89a300"
      },
      "outputs": [],
      "source": [
        "class AverageMeter():\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a148c75"
      },
      "outputs": [],
      "source": [
        "class Trainer :\n",
        "  @inject_config\n",
        "  def __init__(self,config : CN) :\n",
        "    self.device = config.device\n",
        "    self.n_accumulate = config.model.n_accumulate\n",
        "    \n",
        "  def get_score(self,y_true, y_pred):\n",
        "    return f1_score(y_true, np.argmax(y_pred,axis=1),average='weighted')\n",
        "\n",
        "  def loss_fn(self,outputs,targets):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss = criterion(outputs,targets)\n",
        "    return loss\n",
        "  \n",
        "  def train_fn(self,train_data_loader,model,optimizer,scheduler = None):\n",
        "    from  torch.cuda import amp\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    model.train()\n",
        "    losses = AverageMeter()\n",
        "    roc_auc = AverageMeter()\n",
        "    tk0 = tqdm(train_data_loader, total=len(train_data_loader))\n",
        "    tot_loss = 0\n",
        "    for step,d in enumerate(tk0):\n",
        "      images =  d['image']\n",
        "      labels =  d['label']\n",
        "      #send them to device \n",
        "      images  = images.to(self.device,dtype=torch.float)\n",
        "      labels  = labels.to(self.device,dtype=torch.long)\n",
        "\n",
        "      with amp.autocast(enabled=True):\n",
        "        outputs  = model(images)\n",
        "        loss = self.loss_fn(outputs,labels)\n",
        "      \n",
        "      # Accumulates gradients after scale.\n",
        "      scaler.scale(loss).backward()\n",
        "\n",
        "      if (step+ 1) % self.n_accumulate == 0:\n",
        "          scaler.step(optimizer)\n",
        "          scaler.update()\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "      tot_loss = tot_loss + loss.item()\n",
        "      losses.update(loss.item(), labels.size(0))\n",
        "      tk0.set_postfix(loss=losses.avg)\n",
        "      \n",
        "\n",
        "    loss_score = tot_loss/len(train_data_loader)\n",
        "    f1_scoree = self.get_score(labels.cpu().numpy(), torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "    \n",
        "    print(f'LR for this Epoch :: {optimizer.param_groups[0][\"lr\"]}')\n",
        "    print(\"Training loss for this epoch: \", loss_score)\n",
        "    print(\"Training F1 Score for this epoch: \", f1_scoree)\n",
        "    return f1_scoree\n",
        "\n",
        "  def eval_fn(self,valid_data_loader,model):\n",
        "    model.eval()\n",
        "    tot_loss = 0\n",
        "    final_outputs = []\n",
        "    final_targets = []\n",
        "    with torch.no_grad():\n",
        "      for bi,d in enumerate(valid_data_loader):\n",
        "        images = d['image']\n",
        "        labels = d['label']\n",
        "        #send them to device \n",
        "        images = images.to(self.device,dtype=torch.float)\n",
        "        labels = labels.to(self.device,dtype=torch.long)\n",
        "        \n",
        "        outputs  = model(images)\n",
        "        loss = self.loss_fn(outputs,labels)\n",
        "        tot_loss = tot_loss + loss.item()\n",
        "\n",
        "        final_outputs.append(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "        final_targets.append(labels.cpu().numpy())\n",
        "\n",
        "      final_targets = np.concatenate(final_targets)\n",
        "      final_outputs = np.concatenate(final_outputs)\n",
        "      \n",
        "      loss_score  = tot_loss/len(valid_data_loader)\n",
        "      f1_scoree = self.get_score(final_targets,final_outputs)\n",
        "      print(\"Validation loss for this epoch: \",loss_score)\n",
        "      print('Validation F1 Score for this epoch',f1_scoree)\n",
        "    return loss_score,f1_scoree , final_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68f0bf7e"
      },
      "outputs": [],
      "source": [
        "class Augmentation :\n",
        "  @inject_config\n",
        "  def __init__(self,config :CN) :\n",
        "    self.input_shape = config.preprocess.input_shape\n",
        "    self.SEED_VAL  = config.seed\n",
        "    self.crop_shape  = config.preprocess.crop_shape\n",
        "    \n",
        "  def seed_all(self):\n",
        "        random.seed(self.SEED_VAL)\n",
        "        np.random.seed(self.SEED_VAL)\n",
        "        torch.manual_seed(self.SEED_VAL)\n",
        "        torch.cuda.manual_seed_all(self.SEED_VAL)\n",
        "        os.environ['PYTHONHASHSEED'] = str(self.SEED_VAL)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        \n",
        "  def train_transform(self,) :\n",
        "    self.seed_all()\n",
        "    train_transform = A.Compose([\n",
        "                              A.OneOf([\n",
        "                                    A.RandomResizedCrop (self.input_shape[0], self.input_shape[1], scale=(0.8, 1.0), ratio=(0.8, 1.0), p=0.2),\n",
        "                                    A.Compose([ \n",
        "                                        A.RandomCrop(self.crop_shape[0], self.crop_shape[1],p=1.0),\n",
        "                                        A.Resize(height=self.input_shape[0], width=self.input_shape[1], p=1.0)\n",
        "                                        ],p=0.3),      \n",
        "                                    A.Resize(height=self.input_shape[0], width=self.input_shape[1], p=0.5),\n",
        "                                  ]\n",
        "                                  , p=1),\n",
        "                              OneOf([\n",
        "                                    A.RandomFog(p=0.5),\n",
        "                                    A.Blur(blur_limit=10, p=.1), \n",
        "                                     A.MotionBlur(p=0.2)\n",
        "                              ], p=0.1),\n",
        "                              OneOf([CLAHE(clip_limit=[2,4],p=0.5),\n",
        "                                     A.Equalize(p=0.3),\n",
        "                                     A.HueSaturationValue(p=0.3),\n",
        "                                    ], p=0.3),\n",
        "                              OneOf([\n",
        "                                     IAASharpen(p=0.1),\n",
        "                                     A.RandomBrightnessContrast(p=0.5),\n",
        "                                     RandomContrast(p=0.5),\n",
        "                                     RandomBrightness(p=0.5),\n",
        "                              ], p=0.3),\n",
        "                              OneOf([ \n",
        "                                  A.Transpose(p=0.5),\n",
        "                                  A.VerticalFlip(0.5),\n",
        "                              ], p=0.3),\n",
        "                              A.HorizontalFlip(p=0.3),\n",
        "                              OneOf([A.Rotate (limit=45, interpolation=1, border_mode=4,p=0.7), # change p\n",
        "                                     AG.Affine(translate_percent=0.1,rotate=10,interpolation=1,mode=cv2.BORDER_REPLICATE, p=0.3) , \n",
        "                                ], p=0.3),\n",
        "                              A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                              ToTensorV2(),\n",
        "                              ])\n",
        "    return train_transform\n",
        "  \n",
        "  def test_trasnform(self,Augstype='Resize') :\n",
        "    if Augstype == 'Resize' :\n",
        "        test_transform = A.Compose([ \n",
        "                                  A.Resize(height=self.input_shape[0], width=self.input_shape[1],p=1),\n",
        "                                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), p=1.0),\n",
        "                                  ToTensorV2(),\n",
        "                                  ])\n",
        "        \n",
        "    return test_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47df5cd0"
      },
      "outputs": [],
      "source": [
        "class PytorchTrainer :\n",
        "  @inject_config\n",
        "  def __init__(self, config:CN) :\n",
        "    \n",
        "    self.model_name  = config.model.name_model\n",
        "    self.EPOCHS  = config.model.epochs\n",
        "    self.lr  = config.model.base_lr\n",
        "    self.weight_decay = config.model.weight_decay\n",
        "    self.train_bs = config.model.train_bs\n",
        "    self.test_bs = config.model.test_bs\n",
        "    self.LABELS = config.data.LABELS\n",
        "    self.NTargets = config.num_classes\n",
        "    self.device   = config.device\n",
        "    self.SEED_VAL  = config.seed\n",
        "    self.n_splits  = config.n_folds\n",
        "    self.metric = config.metric\n",
        "    self.n_accumulate = config.model.n_accumulate\n",
        "\n",
        "  def fetch_scheduler(self,optimizer):\n",
        "    if _C.model.scheduler == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n",
        "                                                   eta_min=_C.model.min_lr)\n",
        "    elif _C.model.scheduler == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
        "                                                             eta_min=_C.model.min_lr)\n",
        "    elif _C.model.scheduler == 'ReduceLROnPlateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                   mode='min',\n",
        "                                                   factor=_C.model.factor,\n",
        "                                                   patience=_C.model.patience,\n",
        "                                                   threshold=0.00001,\n",
        "                                                   min_lr=_C.model.min_lr,)\n",
        "    elif _C.model.scheduler == 'ExponentialLR':\n",
        "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
        "    elif _C.model.scheduler == None:\n",
        "        return None\n",
        "        \n",
        "    return scheduler\n",
        "\n",
        "  def get_score(self,y_true, y_pred):\n",
        "    return accuracy_score(y_true, np.argmax(y_pred,axis=1))\n",
        "\n",
        "  def seed_all(self):\n",
        "        random.seed(self.SEED_VAL)\n",
        "        np.random.seed(self.SEED_VAL)\n",
        "        torch.manual_seed(self.SEED_VAL)\n",
        "        torch.cuda.manual_seed_all(self.SEED_VAL)\n",
        "        os.environ['PYTHONHASHSEED'] = str(self.SEED_VAL)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False \n",
        "\n",
        "  def kfold_split(self,Train,y):\n",
        "        Train[\"folds\"]=-1\n",
        "        kf = StratifiedKFold(n_splits= self.n_splits,random_state=self.SEED_VAL,shuffle=True)\n",
        "        for fold, (_, val_index) in enumerate(kf.split(Train,y)):\n",
        "                Train.loc[val_index, \"folds\"] = fold\n",
        "        return Train\n",
        "  \n",
        "  def Train_One_Fold(self,train_df , valid_df,fold):\n",
        "    self.seed_all()\n",
        "    trainer = Trainer()\n",
        "    augs = Augmentation()\n",
        "\n",
        "    train_transform = augs.train_transform()\n",
        "    val_transform   = augs.test_trasnform()\n",
        "\n",
        "    train_dataset = ImageDataset(train_df.reset_index(),train_transform)\n",
        "    valid_dataset = ImageDataset(valid_df.reset_index(),val_transform)\n",
        "    \n",
        "    train_data_loader = DataLoader(dataset=train_dataset,shuffle=True,batch_size=self.train_bs//self.n_accumulate)\n",
        "    valid_data_loader = DataLoader(dataset=valid_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "    \n",
        "    if 'swin' in self.model_name or 'cait' in self.model_name or 'cait' in self.model_name: \n",
        "        model = SwinModel(model_name=self.model_name) \n",
        "        model.to(self.device)\n",
        "    \n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "    scheduler = self.fetch_scheduler(optimizer)\n",
        "    \n",
        "    best_score = np.inf\n",
        "    for epoch in range(self.EPOCHS):\n",
        "      print(\"----------------EPOCH \"+str(epoch+1)+\"---------------------\")\n",
        "      Acc_train = trainer.train_fn(train_data_loader, model, optimizer,scheduler=None)\n",
        "      loss_val,Score_val,oof_ = trainer.eval_fn(valid_data_loader ,model)\n",
        "      scheduler.step(loss_val)\n",
        "      if loss_val<best_score:\n",
        "        best_score = loss_val \n",
        "        oof_1f = np.copy(oof_) \n",
        "        torch.save(model.state_dict(),f\"best_model_{fold}\") \n",
        "    return oof_1f , best_score \n",
        "\n",
        "  def Train_K_folds(self,train):\n",
        "    self.seed_all()\n",
        "    oof = np.zeros((train.shape[0],self.NTargets))\n",
        "    train = self.kfold_split(train,train[self.LABELS])\n",
        "    \n",
        "    for fold in range(self.n_splits):\n",
        "      print(f\"#########################  Fold {fold+1}/{self.n_splits}  #########################\")\n",
        "      train_df = train[train['folds']!=fold]\n",
        "      valid_df = train[train['folds']==fold]\n",
        "      oof_1f , best_score = self.Train_One_Fold(train_df , valid_df,fold)\n",
        "      oof[valid_df.index.tolist()] = oof_1f \n",
        "      free_memory(sleep_time=0.1)\n",
        "    print(f'{self.metric} OOF Score :',self.get_score(train[self.LABELS],oof))\n",
        "    return oof\n",
        "\n",
        "  def InferenceValid(self,valid_df,Augstype='Resize') :\n",
        "    self.seed_all()\n",
        "    print(f'Inference On {Augstype} Augs ...')\n",
        "    augs = Augmentation()\n",
        "    test_transform   = augs.test_trasnform(Augstype=Augstype)\n",
        "    valid_dataset = ImageDataset(valid_df.reset_index(drop=True),test_transform,mode='test')\n",
        "    test_data_loader = DataLoader(dataset=valid_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "    if 'swin' in self.model_name or 'cait' in self.model_name or 'cait' in self.model_name: \n",
        "        best_model = SwinModel(model_name=self.model_name) \n",
        "        best_model.to(self.device)\n",
        "    best_model.load_state_dict(torch.load(f'best_model_{fold}'))\n",
        "    best_model.to(self.device)\n",
        "    best_model.eval()\n",
        "    \n",
        "    final_outputs = []\n",
        "    with torch.no_grad() :\n",
        "        tk0 = tqdm(test_data_loader, total=len(test_data_loader))\n",
        "        for bi,d in enumerate(tk0):\n",
        "          images = d['image']\n",
        "          #send them to device \n",
        "          images = images.to(self.device,dtype=torch.float)\n",
        "          outputs  = best_model(images)\n",
        "          final_outputs.append(torch.nn.functional.softmax(outputs).cpu().detach().numpy())\n",
        "\n",
        "    final_outputs = np.concatenate(final_outputs)\n",
        "    Final_Prediction   = np.argmax(final_outputs,axis=1)\n",
        "    return  final_outputs , Final_Prediction \n",
        "\n",
        "  def Inference(self,test,Augstype='Resize') :\n",
        "    augs = Augmentation()\n",
        "    test_transform   = augs.test_trasnform(Augstype=Augstype)\n",
        "\n",
        "    test_dataset = ImageDataset(test.reset_index(drop=True),test_transform,mode='test')\n",
        "    test_data_loader = DataLoader(dataset=test_dataset,shuffle=False,batch_size=self.test_bs)\n",
        "\n",
        "    all_folds = []\n",
        "    for fold in range(self.n_splits):\n",
        "      print(f\"#########################  Fold {fold+1}/{self.n_splits}  #########################\")\n",
        "      if 'swin' in self.model_name or 'cait' in self.model_name or 'cait' in self.model_name: \n",
        "        best_model = SwinModel(model_name=self.model_name) \n",
        "        best_model.to(self.device)\n",
        "        \n",
        "      best_model.load_state_dict(torch.load(f'best_model_{fold}'))\n",
        "      best_model.to(self.device)\n",
        "      best_model.eval()\n",
        "      final_outputs = []\n",
        "      with torch.no_grad() :\n",
        "        tk0 = tqdm(test_data_loader, total=len(test_data_loader))\n",
        "        for bi,d in enumerate(tk0):\n",
        "          images = d['image']\n",
        "          #send them to device \n",
        "          images = images.to(self.device,dtype=torch.float)\n",
        "          outputs  = best_model(images)\n",
        "          final_outputs.append(F.softmax(outputs, dim=1).data.squeeze().cpu().detach().numpy())\n",
        "\n",
        "      final_outputs = np.concatenate(final_outputs)\n",
        "      all_folds.append(final_outputs)\n",
        "    Final_Prediction_f = np.mean(all_folds,axis=0)\n",
        "    Final_Prediction_gmean = gmean(all_folds)\n",
        "    Final_Prediction   = np.argmax(Final_Prediction_f,axis=1)\n",
        "    return  Final_Prediction_f, Final_Prediction_gmean, Final_Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "709c3e38"
      },
      "outputs": [],
      "source": [
        "AssazzinTrainer = PytorchTrainer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac9726cc"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4ce0a0c",
        "outputId": "40642bda-80c4-4aac-c45f-27a151c608b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import gc ; gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6kvjYfXJ72A"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import time\n",
        "def free_memory(sleep_time=0.1) :\n",
        "    \"\"\" Black magic function to free torch memory and some jupyter whims \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    time.sleep(sleep_time)\n",
        "\n",
        "free_memory(sleep_time=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfdfc0fb"
      },
      "outputs": [],
      "source": [
        "OOF = AssazzinTrainer.Train_K_folds(train=Train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a78b68f9"
      },
      "source": [
        "# Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEqWCXkxg7sm"
      },
      "outputs": [],
      "source": [
        "free_memory(sleep_time=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQXiUg923eiL"
      },
      "outputs": [],
      "source": [
        "Test = Test[~Test.Image_id.str.contains('_rgn')].reset_index(drop=True) # Just the RGB images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d756123"
      },
      "outputs": [],
      "source": [
        "Final_Prediction_f1, Final_Prediction_gmean_f1, _ = AssazzinTrainer.Inference(test=Test,Augstype ='Resize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25300981"
      },
      "outputs": [],
      "source": [
        "Final_Prediction = Final_Prediction_gmean_f1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "945dd767"
      },
      "outputs": [],
      "source": [
        "np.save(f'AssazzinBaseline_{c.model.name_model}_Preds_gmean_10Folds.npy',Final_Prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q000gHdu4fkm",
        "outputId": "1215e482-1dff-43b7-b27b-80fc4d85a9a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "455"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import gc ; gc.collect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "MicrosoftRice - Solution - SwinLarge_V2_256",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}