---
title: "ICLR Crop detection"
author: "Dr Fad"
date: "Feb 17, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Load libraries

```{r cars}
rm(list = ls())
# library(keras)
# library(tensorflow)
#library(EBImage)
# use_condaenv("r-tensorflow")
# install_keras()
# library(sf)
# library(spdep)
library(rgdal)

## Import packages
library(ggplot2)
library(gridExtra)
library(repr)
library(dplyr)
library(caret)
library(e1071)
library(MLmetrics)
library(klaR)
library(gdalUtils)
library(raster) #Manipulating geospatil images
library(sqldf) #Running sql type of query
library(Matrix) # For matrix conversion used for xgboost
library(beepr) #For output sound
library(stringi) #For text manipulation
library(stringr) #For text manipulation
library(lubridate) #For manipulating dates
library(geosphere) #For getting distance from geospatial data i.e long and lat
library(factoextra) #To visualise clusters
library(fpc) # for computing density based clustering
library(dbscan) # for computing density based clustering
library(tictoc) #To calculate running time
library(mapproj) #To map projections
library(catboost) #For modelling
library(Boruta)#For feature selection
library(xgboost)
library(Matrix)
# library(lightgbm)
#library(ROCR) #Visualising performance of classifiers

options(repr.plot.width=4, repr.plot.height=4)
options(scipen=99999999) # Used to revoke display of scientific numbers
```

#Load rda's
```{r}
#load("ICLR_NDVI.rda")
```


##Read load and test
```{r}
tic()
setwd("C:/Users/A199702/Documents/Zindi/Crop Recognition")
ICLR <- read.csv("completed data.csv")
# ICLR <- read.csv("C:/Users/A221572/Documents/ICLR Crop detection Winning solution by Threshold Alchemi and DrFad/completed data.csv")
Sample_sub <- read.csv("SampleSubmission.csv")
# Sample_sub <- read.csv("C:/Users/A221572/Documents/ICLR Crop detection Winning solution by Threshold Alchemi and DrFad/SampleSubmission.csv")
Sample_sub <- Sample_sub[,c(1,2)]
#Change column name
colnames(ICLR)[1] <- "Field_ID"
ICLR_test <- merge(Sample_sub, ICLR, by = "Field_ID", all.y=T)
ICLR_train <- ICLR_test[is.na(ICLR_test$Crop_ID_1),]
ICLR_test <- ICLR_test[!is.na(ICLR_test$Crop_ID_1),]
#Drop dummy column
ICLR_train$Crop_ID_1 <- NULL
ICLR_test$Crop_ID_1 <- NULL

ICLR_train[,c("row_loc","col_loc","tile")] <- NULL
ICLR_test[,c("row_loc","col_loc","tile")] <- NULL


head(ICLR_train)
toc()
```

#Feature Engineering
Get standard deviations
Didn't work

```{r}
# ICLR_train_sd <- ICLR_train
# ICLR_test_sd <- ICLR_test
# 
# ICLR_train_sd <- ICLR_train_sd %>% group_by(Field_ID,label) %>% summarise_all(funs(sd))
# ICLR_test_sd <- ICLR_test_sd %>% group_by(Field_ID,label) %>% summarise_all(funs(sd))
# table(ICLR_train$label)
# ICLR_train_sd <- as.data.frame(ICLR_train_sd)
# ICLR_test_sd <- as.data.frame(ICLR_test_sd)
# colnames(ICLR_train_sd) <- c(colnames(ICLR_train_sd)[1:2],paste0(colnames(ICLR_train_sd)[3:171],"_sd"))
# colnames(ICLR_test_sd) <- c(colnames(ICLR_test_sd)[1:2],paste0(colnames(ICLR_test_sd)[3:171],"_sd"))
# 
# #Replace NaN's with 0
# is.nan.data.frame <- function(x)
# do.call(cbind, lapply(x, is.nan))
# 
# ICLR_train_sd[is.nan(ICLR_train_sd)] <- 0
# ICLR_test_sd[is.nan(ICLR_test_sd)] <- 0

```

Get Area of each field
```{r}
# ICLR_Area <- rbind(ICLR_train,ICLR_test)
# ICLR_Area <- ICLR_Area[,c('Field_ID',"row_loc","col_loc")]
# ICLR_Area <- ICLR_Area %>% group_by(Field_ID) %>% summarise(rowmin = min(row_loc),
#                                                             rowmax = max(row_loc),
#                                                             colmin = min(col_loc),
#                                                           colmax = max(col_loc))
# ICLR_Area$Area <- ((ICLR_Area$rowmax - ICLR_Area$rowmin)+1)*((ICLR_Area$colmax - ICLR_Area$colmin)+1)
# ICLR_Area <- ICLR_Area[,c("Field_ID","Area")]
```



```{r}
bands <- c("B01","B02","B03","B04","B05","B06","B07","B08","B8A","B09","B11","B12","CLD")
dt <- c("0606","0701","0706","0711","0721","0805","0815","0825","0909","0919","0924","1004","1103")

##########################################################################
#NDVI train
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDVI","_",dt[i])] <- (ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])]) 
}

#NDVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDVI","_",dt[i])] <- (ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])]) 
}


##########################################################################
#NDRE5 train
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDRE5","_",dt[i])] <- (ICLR_train[,paste0("B05","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B05","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#NDRE5 test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDRE5","_",dt[i])] <- (ICLR_test[,paste0("B05","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B05","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#Multiply row and col
##########################################################################
# ICLR_train$col_of_row <- ICLR_train$row_loc * ICLR_train$col_loc
# ICLR_test$col_of_row <- ICLR_test$row_loc * ICLR_test$col_loc


##########################################################################
#WDRVI train 
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("WDRVI","_",dt[i])] <- (8*ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(8*ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#WDRVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("WDRVI","_",dt[i])] <- (8*ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(8*ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#NDRE6 train - dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("NDRE6","_",dt[i])] <- (ICLR_train[,paste0("B06","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B06","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
# }
# 
# #NDRE6 test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("NDRE6","_",dt[i])] <- (ICLR_test[,paste0("B06","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B06","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
# }

##########################################################################
#NDRE7 train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("NDRE7","_",dt[i])] <- (ICLR_train[,paste0("B07","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B07","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
}

#NDRE7 test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("NDRE7","_",dt[i])] <- (ICLR_test[,paste0("B07","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B07","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
}

##########################################################################
#NDSI train- dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("NDSI","_",dt[i])] <- (ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B06","_2019",dt[i])])/(ICLR_train[,paste0("B04","_2019",dt[i])] + ICLR_train[,paste0("B06","_2019",dt[i])])
# }
# 
# #NDSI test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("NDSI","_",dt[i])] <- (ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B06","_2019",dt[i])])/(ICLR_test[,paste0("B04","_2019",dt[i])] + ICLR_test[,paste0("B06","_2019",dt[i])])
# }



##########################################################################
#VARI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("VARI","_",dt[i])] <- (ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(ICLR_train[,paste0("B03","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B02","_2019",dt[i])])
}

#VARI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("VARI","_",dt[i])] <- (ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(ICLR_test[,paste0("B03","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B02","_2019",dt[i])])
}

##########################################################################
#MTCI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("MTCI","_",dt[i])] <- (ICLR_train[,paste0("B8A","_2019",dt[i])] - ICLR_train[,paste0("B06","_2019",dt[i])])/(ICLR_train[,paste0("B06","_2019",dt[i])] + ICLR_train[,paste0("B07","_2019",dt[i])])
}

#MTCI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("MTCI","_",dt[i])] <- (ICLR_test[,paste0("B8A","_2019",dt[i])] - ICLR_test[,paste0("B06","_2019",dt[i])])/(ICLR_test[,paste0("B06","_2019",dt[i])] + ICLR_test[,paste0("B07","_2019",dt[i])])
}

##########################################################################
#GRVI train- dropped
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("GRVI","_",dt[i])] <- (ICLR_train[,paste0("B08","_2019",dt[i])] )/(ICLR_train[,paste0("B03","_2019",dt[i])] )
# }
# 
# #GRVI test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("GRVI","_",dt[i])] <- (ICLR_test[,paste0("B08","_2019",dt[i])] )/(ICLR_test[,paste0("B03","_2019",dt[i])] )
# }

##########################################################################
#Exblue train- (2B2- B3 - B4)Fairly good
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("exblue","_",dt[i])] <- 2*ICLR_train[,paste0("B02","_2019",dt[i])] - ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])]
}

#exblue test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("exblue","_",dt[i])] <- 2*ICLR_test[,paste0("B02","_2019",dt[i])] - ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])]
}

##########################################################################
#Exgreen train- (2B2- B3 - B4)Fairly good
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("exgreen","_",dt[i])] <- 2*ICLR_train[,paste0("B03","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])] - ICLR_train[,paste0("B02","_2019",dt[i])]
}

#Exgreen test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("exgreen","_",dt[i])] <- 2*ICLR_test[,paste0("B03","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])] - ICLR_test[,paste0("B02","_2019",dt[i])]
}
dim(ICLR_train)

##########################################################################
#Area- (lenght * breadth)
##########################################################################
# ICLR_train <- merge(ICLR_Area, ICLR_train, by = "Field_ID", all.y = T )
# ICLR_test <- merge(ICLR_Area, ICLR_test, by = "Field_ID", all.y = T )

##########################################################################
#SAVI train- dropped
##########################################################################
for (i in seq(1,13,1)){
 ICLR_train[,paste0("SAVI","_",dt[i])] <- ((ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])] )/(ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])] + 0.428))*1.428
}

#SAVI test
for (i in seq(1,13,1)){
 ICLR_test[,paste0("SAVI","_",dt[i])] <- ((ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])] )/(ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])] + 0.428))*1.428
}

##########################################################################
#WDRVI08 train at 0.8
##########################################################################
# for (i in seq(1,13,1)){
#  ICLR_train[,paste0("WDRVI08","_",dt[i])] <- (0.8*ICLR_train[,paste0("B08","_2019",dt[i])] - ICLR_train[,paste0("B04","_2019",dt[i])])/(0.8*ICLR_train[,paste0("B08","_2019",dt[i])] + ICLR_train[,paste0("B04","_2019",dt[i])])
# }
# 
# #WDRVI08 test
# for (i in seq(1,13,1)){
#  ICLR_test[,paste0("WDRVI08","_",dt[i])] <- (0.8*ICLR_test[,paste0("B08","_2019",dt[i])] - ICLR_test[,paste0("B04","_2019",dt[i])])/(0.8*ICLR_test[,paste0("B08","_2019",dt[i])] + ICLR_test[,paste0("B04","_2019",dt[i])])
# }
dim(ICLR_train)

```
#Save as rda to engineer other features that gets quantiles and min max in days

```{r}
save(ICLR_train,ICLR_test, file= "ICLR.rda")
```





#Explore cloud cover effect
```{r}
# Cloud <- ICLR_train[,c("CLD_20190606","CLD_20190701","CLD_20190706","CLD_20190711"
#                                     ,"CLD_20190721","CLD_20190805","CLD_20190815","CLD_20190825",
#                                     "CLD_20190909","CLD_20190919","CLD_20190924","CLD_20191004",
#                                     "CLD_20191103")]
# Cloud$dummy <- 1
# Cloud <- Cloud %>% group_by(dummy) %>% summarise_all(funs(mean))
# Cloud
```
#Aggregate data
```{r}
ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
table(ICLR_train$label)
ICLR_train <- as.data.frame(ICLR_train)
ICLR_test <- as.data.frame(ICLR_test)

#Cbind sd data
# ICLR_train <- cbind(ICLR_train, ICLR_train_sd[,c(3:171)])
# ICLR_test <- cbind(ICLR_test, ICLR_test_sd[,c(3:171)])

#Try remove 0805 data due to large cloud presence
# ICLR_train[,c(68:80)]

```
Dropped VDVI
#Data Exploration
```{r}
visual <- ICLR_train
visual$label <- factor(visual$label)
plot_box <- function(df, cols, col_x = 'label'){
  options(repr.plot.width = 4, repr.plot.height = 3.5)
  for(col in cols){
    p = ggplot(df, aes_string(col_x,col)) +
      geom_boxplot() +
      ggtitle(paste('Box plot of ', col, '\n vs. ', col_x))
    print(p)
  }
}

num_cols = colnames(visual[,c(1:5,172:184)])
plot_box(visual, num_cols)
```

#Add min and max values plus their difference
```{r}
#Min max for NDVI
ICLR_train$NDVI_min <- apply(ICLR_train[,c(172:184)], 1, FUN=min)
ICLR_train$NDVI_max <- apply(ICLR_train[,c(172:184)], 1, FUN=max)
ICLR_train$NDVI_diff <- ICLR_train$NDVI_max - ICLR_train$NDVI_min

ICLR_test$NDVI_min <- apply(ICLR_test[,c(172:184)], 1, FUN=min)
ICLR_test$NDVI_max <- apply(ICLR_test[,c(172:184)], 1, FUN=max)
ICLR_test$NDVI_diff <- ICLR_test$NDVI_max - ICLR_test$NDVI_min


#Min max for NDRE5
ICLR_train$NDRE5_min <- apply(ICLR_train[,c(185:197)], 1, FUN=min)
ICLR_train$NDRE5_max <- apply(ICLR_train[,c(185:197)], 1, FUN=max)
ICLR_train$NDRE5_diff <- ICLR_train$NDRE5_max - ICLR_train$NDRE5_min

ICLR_test$NDRE5_min <- apply(ICLR_test[,c(185:197)], 1, FUN=min)
ICLR_test$NDRE5_max <- apply(ICLR_test[,c(185:197)], 1, FUN=max)
ICLR_test$NDRE5_diff <- ICLR_test$NDRE5_max - ICLR_test$NDRE5_min

#Min max for WDRVI
ICLR_train$WDRVI_min <- apply(ICLR_train[,c(198:210)], 1, FUN=min)
ICLR_train$WDRVI_max <- apply(ICLR_train[,c(198:210)], 1, FUN=max)
ICLR_train$WDRVI_diff <- ICLR_train$WDRVI_max - ICLR_train$WDRVI_min

ICLR_test$WDRVI_min <- apply(ICLR_test[,c(198:210)], 1, FUN=min)
ICLR_test$WDRVI_max <- apply(ICLR_test[,c(198:210)], 1, FUN=max)
ICLR_test$WDRVI_diff <- ICLR_test$WDRVI_max - ICLR_test$WDRVI_min

#Min max for NDRE7
ICLR_train$NDRE7_min <- apply(ICLR_train[,c(211:223)], 1, FUN=min)
ICLR_train$NDRE7_max <- apply(ICLR_train[,c(211:223)], 1, FUN=max)
ICLR_train$NDRE7_diff <- ICLR_train$NDRE7_max - ICLR_train$NDRE7_min

ICLR_test$NDRE7_min <- apply(ICLR_test[,c(211:223)], 1, FUN=min)
ICLR_test$NDRE7_max <- apply(ICLR_test[,c(211:223)], 1, FUN=max)
ICLR_test$NDRE7_diff <- ICLR_test$NDRE7_max - ICLR_test$NDRE7_min

#Min max for SAVI
ICLR_train$SAVI_min <- apply(ICLR_train[,c(276:288)], 1, FUN=min)
ICLR_train$SAVI_max <- apply(ICLR_train[,c(276:288)], 1, FUN=max)
ICLR_train$SAVI_diff <- ICLR_train$SAVI_max - ICLR_train$SAVI_min

ICLR_test$SAVI_min <- apply(ICLR_test[,c(276:288)], 1, FUN=min)
ICLR_test$SAVI_max <- apply(ICLR_test[,c(276:288)], 1, FUN=max)
ICLR_test$SAVI_diff <- ICLR_test$SAVI_max - ICLR_test$SAVI_min
```

#Add quantile data
Top 8
```{r}
# load("ICLR_qt.rda") #For top8
load("ICLR_qt8.rda") #For top12

ICLR_train <- merge(ICLR_qt_train,ICLR_train, by = "Field_ID", all.y= T)
ICLR_test <- merge(ICLR_qt_test,ICLR_test, by = "Field_ID", all.y= T)

#To ensure field_ID and label are cols 1 n 2
ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
table(ICLR_train$label)
ICLR_train <- as.data.frame(ICLR_train)
ICLR_test <- as.data.frame(ICLR_test)
```

```{r}
# # #NDVI Drop
# # ICLR_train <- merge(ICLR_NDVI_train,ICLR_train, by = "Field_ID", all.y= T)
# # ICLR_test <- merge(ICLR_NDVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #NDRE5
# load("ICLR_NDRE5.rda")
# ICLR_train <- merge(ICLR_NDRE5_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_NDRE5_test,ICLR_test, by = "Field_ID", all.y= T)
# # 
# #WDRVI
# load("ICLR_WDRVI.rda")
# ICLR_train <- merge(ICLR_WDRVI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_WDRVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #NDRE7
# load("ICLR_NDRE7.rda")
# ICLR_train <- merge(ICLR_NDRE7_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_NDRE7_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #MTCI
# load("ICLR_MTCI.rda")
# ICLR_train <- merge(ICLR_MTCI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_MTCI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# #SAVI
# load("ICLR_SAVI.rda")
# ICLR_train <- merge(ICLR_SAVI_train,ICLR_train, by = "Field_ID", all.y= T)
# ICLR_test <- merge(ICLR_SAVI_test,ICLR_test, by = "Field_ID", all.y= T)
# 
# ########
# #To ensure field_ID and label are cols 1 n 2
# ICLR_train <- ICLR_train %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# ICLR_test <- ICLR_test %>% group_by(Field_ID,label) %>% summarise_all(funs(mean))
# table(ICLR_train$label)
# ICLR_train <- as.data.frame(ICLR_train)
# ICLR_test <- as.data.frame(ICLR_test)

```


#Feature selection using Boruta
```{r}
# library(Boruta)
# # Traffic_Boruta <- Traffic #For the Boruta package
# # summary(Churn_Boruta)
# # library(doParallel)
# # registerDoParallel(cores = 4)
# set.seed(777)
# system.time(
# ICLR_Boruta_Out <- Boruta(Field_ID ~ . - label, data=ICLR_train, doTrace=2)
# )
# ICLR_boruta_signif <- names(ICLR_Boruta_Out$finalDecision[ICLR_Boruta_Out$finalDecision %in% c("Confirmed","Tentative")])  # collect Confirmed and Tentative variables
# # print(Traffic_boruta_signif)  # significant variables
# 
# plot(ICLR_Boruta_Out, cex.axis=0.6, las=2, xlab="", main="Variable Importance")   # plot variable importance
# grid(ny = 100, lty = "dotted",lwd = 2)
# save(ICLR_boruta_signif,ICLR_Boruta_Out, file = "ICLR_Boruta_F3b26.rda")
```
#Load Boruta object and subset data

```{r}
# load("ICLR_Boruta_F3b26.rda")
# ICLR_train <- ICLR_train[,c("Field_ID","label",ICLR_boruta_signif)]
# ICLR_test <- ICLR_test[,c("Field_ID","label",ICLR_boruta_signif)]

```


##Balance Data using SMOTE
```{r}
library(UBL) #For SMOOTE
ICLR_train$label <- factor(ICLR_train$label)
table(ICLR_train$label)
set.seed(200)

# ICLR_train<-  SmoteClassif(label ~ ., ICLR_train, list(`1` = 1, `2` = 1.76,`3` = 14.92, `4` = 3, `5`= 8.5,`6` = 9.14,`7`=18.74))
ICLR_train<-  SmoteClassif(label ~ ., ICLR_train, list(`1` = 1, `2` = 1.76,`3` = 14.92, `4` = 4.5, `5`= 12.75,`6` = 13.71,`7`=28.11))

table(ICLR_train$label)
```
#Parameter Tuning

```{r}
# tic()
# input_x <- as.matrix(ICLR_train[,-c(1,2)])
# input_y <- factor(ICLR_train$label) #must be factors
# levels(input_y) <- c("X1", "X2","X3","X4","X5","X6","X7")
# 
# 
# ##########################################################
# # XGboost with default parameters
# ##########################################################
# # note to start nrounds from 200, as smaller learning rates result in errors so
# # big with lower starting points that they'll mess the scales
# tune_grid <- expand.grid(
#   nrounds = seq(from = 200, to = 450, by = 50),
#   eta = c(0.032),
#   max_depth = c(3),
#   gamma = c(0),
#   colsample_bytree = c(1),
#   min_child_weight = c(16),
#   subsample = c(0.8)
# )
# 
# tune_control <- caret::trainControl(
#   method = "cv", # cross-validation
#   number = 5, # with n folds
#   #index = createFolds(tr_treated$Id_clean), # fix the folds
#   verboseIter = FALSE, # no training log
#   allowParallel = TRUE, # FALSE for reproducible results
#   classProbs=TRUE,
#   summaryFunction = multiClassSummary
# )
# 
# xgb_tune <- caret::train(
#   x = input_x,
#   y = input_y,
#   trControl = tune_control,
#   tuneGrid = tune_grid,
#   method = "xgbTree",
#   verbose = TRUE,
#   metric="logLoss"
# )
# 
# # helper function for the plots
# tuneplot <- function(x, probs = .90) {
#   ggplot(x) +
#     coord_cartesian(ylim = c(quantile(x$results$logLoss, probs = probs), min(x$results$logLoss))) +
#     theme_bw()
# }
# 
# tuneplot(xgb_tune)
# xgb_tune$bestTune
# min(xgb_tune$results$logLoss)
# library(beepr)
# beep(6)
# toc()
```



#Cross validation or xgboost

```{r}
library(ggplot2) # Data visualization
library(data.table)
library(xgboost)
library(caret)
library(Matrix)


#Remove Field ID from train features
Train_XG <- ICLR_train[,-c(1)]
# Train_XG <- ICLR_train

table(Train_XG$label)
Test_XG <- ICLR_test[,-c(1,2)]

train = Train_XG #training partition

#Create Matrix
dtrain <- sparse.model.matrix(label ~ . -1, data = train)
feature_names <- names(dtrain)
target <- as.numeric(train[,"label"])-1
dtrain <- xgb.DMatrix( data = as.matrix(dtrain), label = target, missing= NA)

###################
#XG Boost setup 
###################

dtest_F <- xgb.DMatrix(data=as.matrix( Test_XG))

###################
#Cross Validation
###################
# Set up cross-validation scheme (3-fold)
foldsCV <- createFolds(target, k=5, list=TRUE, returnTrain=FALSE)


  param <- list(booster = "gbtree"
              , objective = "multi:softprob"
              , subsample = 0.85 #0.8
              , max_depth = 3
              , colsample_bytree = 0.95 #0.95,1
              , eta = 0.032
              #, lambda = 0.08
              , eval_metric = 'mlogloss'
              , num_class = 7
              , gamma = 0
              #, base_score = 0.012 #average
              , min_child_weight = 2#2,16
                )
# xgb_cv <- xgb.cv(data=dtrain,
#                    params=param,
#                   nrounds=500,
#                   prediction=TRUE,
#                   maximize=FALSE,
#                   folds=foldsCV,
#                   early_stopping_rounds = 20,
#                   print_every_n = 5
#   )


  # Check best results and get best nrounds
  # print(xgb_cv$evaluation_log[which.min(xgb_cv$evaluation_log$test_mae_mean)])
# nrounds <- xgb_cv$best_iteration
```

#Try 1600,1700. Bad at 2000
```{r}

  ################
  # Final model
  ################
  set.seed(987654321)
  xgb <- xgboost::xgboost(params = param
                   , data = dtrain
                  # , watchlist = list(train = dtrain)
                   , nrounds = 1700#500,751
                   , verbose = 1
                   , print_every_n = 2
                   #, feval = amm_mae
                  )
  ###############
  # Results
  ###############
  #Feature imprtance
  imp <- xgb.importance(feature_names, model =xgb)
  imp
  xgb.plot.importance(imp)
  # imp$Feature
  
  
  #Submission
  test_new <- as.matrix(Test_XG)

  
  #Prep for submit
  Check_XG <- predict(xgb, newdata = test_new)
  Check_XG <- as.data.frame(matrix(Check_XG,ncol =7, byrow=T))
  ICLR_Submit <- cbind(ICLR_test,Check_XG)
  c1<- ncol(ICLR_Submit)-6
  c2<- ncol(ICLR_Submit)
  ICLR_Submit <- ICLR_Submit[,c(1,c1:c2)]

  #Group 
  ICLR_Submit <- ICLR_Submit %>% group_by(Field_ID) %>% summarise_all(funs(mean))
  table(ICLR_train$class)
  colnames(ICLR_Submit)[2:8] <-c('Crop_ID_1','Crop_ID_2','Crop_ID_3','Crop_ID_4','Crop_ID_5','Crop_ID_6','Crop_ID_7')
  


# write.csv(ICLR_Submit, file = "C:/Users/A221572/Documents/ICLR Crop detection Winning solution by Threshold Alchemi and DrFad/ICLR_Submit_SMOTE_QhCpzd44_1700.csv", row.names = F)
write.csv(ICLR_Submit, file = "ICLR_Submit_SMOTE_QhCpzd44_1700.csv", row.names = F)
beep(6)

```

```{r}

```

