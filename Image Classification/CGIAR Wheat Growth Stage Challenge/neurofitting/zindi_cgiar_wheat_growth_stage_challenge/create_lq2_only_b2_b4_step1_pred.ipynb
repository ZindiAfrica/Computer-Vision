{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create_lq2_only_b2_b4_step1_pred.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd2b793e6954440589d6ea2098e38582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5b8a373feb3451d98cc71af51ac4ece",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c6ba33d828e49408b6d95ad7cd4e4f7",
              "IPY_MODEL_32b209433c9e4c479bcf2a0664c2626d"
            ]
          }
        },
        "c5b8a373feb3451d98cc71af51ac4ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c6ba33d828e49408b6d95ad7cd4e4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffc9a25568c84823988af1906e21059b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 31519111,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31519111,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df131f42b02e4f71a79f2fe60d11e12a"
          }
        },
        "32b209433c9e4c479bcf2a0664c2626d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2c60fe6d0b154953aaa0e79d6dffe806",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.1M/30.1M [00:11&lt;00:00, 2.66MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae1c8ce13924475c960f65e13d034430"
          }
        },
        "ffc9a25568c84823988af1906e21059b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df131f42b02e4f71a79f2fe60d11e12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c60fe6d0b154953aaa0e79d6dffe806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae1c8ce13924475c960f65e13d034430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVMFW3kikJck"
      },
      "source": [
        "# This colab notebook must be run on a **P100** GPU or **T4** GPU instance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WBz60yDkSuz"
      },
      "source": [
        "Cell-1: Ensure the required gpu instance (P100 or T4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y7614glj9Re",
        "outputId": "40b09d0b-d0c9-4452-a021-3cc68494f78f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'\n",
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'\n",
        "#no.of threads each core is having\n",
        "!lscpu | grep 'Thread(s) per core'\n",
        "#GPU count and name\n",
        "!nvidia-smi -L\n",
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Socket(s):           1\n",
            "Core(s) per socket:  1\n",
            "Thread(s) per core:  2\n",
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-076b5f5f-c889-3069-967f-b2c54c5de3cd)\n",
            "Wed Oct  7 10:21:01 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5JcN_WHkaC6"
      },
      "source": [
        "Cell-2: Add Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9aPGh67kVtX",
        "outputId": "756f1807-718f-4bc9-a0e7-7863fc8ac3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoKz10O0khcH"
      },
      "source": [
        "Cell-3: Install Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAiKdbdUkcIE",
        "outputId": "6b0a95de-7d15-45e1-e3af-e4ba84f944b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install efficientnet_pytorch==0.7.0 \n",
        "!pip install albumentations==0.4.5\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch\\_stable.html -q\\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch==0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch==0.7.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch==0.7.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch==0.7.0) (0.16.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=1b91a0113310e84891d4c7b9e039a5328474099da4030d4fb1179f8e1e044407\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n",
            "Collecting albumentations==0.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/40/a343ecacc7e22fe52ab9a16b84dc6165ba05ee17e3729adeb3e2ffa2b37b/albumentations-0.4.5.tar.gz (116kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (1.4.1)\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 634kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.5) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.15.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.5)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.5) (2.8.1)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.5-cp36-none-any.whl size=64378 sha256=2b5c44c98073bc2b77c14395df09a518b8d128bbea69fcc8fc797e6792fc56b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/a0/61/e50f93165a5ec7e7f5d65064e513239505bc4c06d2289557d3\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654021 sha256=e4845c32e947bbf0cd73402f95e7e109367ee0f9ed2118bf6652874e4deeb347\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.5 imgaug-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOEhMcTPlHr6"
      },
      "source": [
        "Cell-4: Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGFNX2A1kjZV"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/src_ensemble\")\n",
        "\n",
        "from dataset import *\n",
        "from model import *\n",
        "from utils import *\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "set_random_state(4690)\n",
        "imgs = np.load('/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/zindi_npy_data/train_imgs.npy')\n",
        "labels_quality = np.load('/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/zindi_npy_data/train_labels_quality.npy')\n",
        "imgs = imgs[labels_quality == 1]\n",
        "test_dataset = ZCTESTDataset(imgs)                                           \n",
        "test_loader = DataLoader( \n",
        "                  test_dataset, \n",
        "                  batch_size=86, \n",
        "                  shuffle=False, \n",
        "                  num_workers=2,\n",
        "                  drop_last=False,\n",
        "                  pin_memory=True,                  \n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ITr-96cmFDl"
      },
      "source": [
        "Cell-5: Run this cell to generate lq2 only b2 step1 pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klQ3su38lztm",
        "outputId": "a65fd54b-1e34-4d87-e5ed-2963815409de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728,
          "referenced_widgets": [
            "bd2b793e6954440589d6ea2098e38582",
            "c5b8a373feb3451d98cc71af51ac4ece",
            "1c6ba33d828e49408b6d95ad7cd4e4f7",
            "32b209433c9e4c479bcf2a0664c2626d",
            "ffc9a25568c84823988af1906e21059b",
            "df131f42b02e4f71a79f2fe60d11e12a",
            "2c60fe6d0b154953aaa0e79d6dffe806",
            "ae1c8ce13924475c960f65e13d034430"
          ]
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model_infos = {\n",
        "      # b2 lq2 only step 1 \n",
        "      'b2_lq2_only_step1_fold0': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b2_step1/weights/fold0/checkpoint_best_f1_score_fold0.pth',\n",
        "            'model_name': 'efficientnet-b2',\n",
        "            'global_dim': 1408,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b2_lq2_only_step1_fold1': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b2_step1/weights/fold1/checkpoint_best_f1_score_fold1.pth',\n",
        "            'model_name': 'efficientnet-b2',\n",
        "            'global_dim': 1408,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b2_lq2_only_step1_fold2': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b2_step1/weights/fold2/checkpoint_best_f1_score_fold2.pth',\n",
        "            'model_name': 'efficientnet-b2',\n",
        "            'global_dim': 1408,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b2_lq2_only_step1_fold3': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b2_step1/weights/fold3/checkpoint_best_f1_score_fold3.pth',\n",
        "            'model_name': 'efficientnet-b2',\n",
        "            'global_dim': 1408,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b2_lq2_only_step1_fold4': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b2_step1/weights/fold4/checkpoint_best_f1_score_fold4.pth',\n",
        "            'model_name': 'efficientnet-b2',\n",
        "            'global_dim': 1408,\n",
        "            'version': 1,\n",
        "      },\n",
        "}\n",
        "\n",
        "models = []\n",
        "for model_type in model_infos:\n",
        "    try:\n",
        "        models.append(get_model(model_infos[model_type]))\n",
        "    except:\n",
        "        print('Error has occured...skipping!')\n",
        "\n",
        "all_growth_stage = []\n",
        "torch.set_grad_enabled(False)                                \n",
        "with torch.no_grad():\n",
        "    for itera_no, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "        images, images_fliplr = data\n",
        "        images = images.cuda()\n",
        "        images_fliplr = images_fliplr.cuda()\n",
        "\n",
        "        y_pred = 0                                                      \n",
        "        for i in range(len(models)):\n",
        "            with torch.cuda.amp.autocast():\n",
        "               out_1 = models[i](images)\n",
        "               out_2 = models[i](images_fliplr)\n",
        "            y_pred += out_1['LOGITS'][:,0].cpu().data.numpy()\n",
        "            y_pred += out_2['LOGITS'][:,0].cpu().data.numpy()\n",
        "\n",
        "        y_pred = y_pred/(len(models)*2)\n",
        "        all_growth_stage += y_pred.clip(min=0, max=6).tolist()      \n",
        "            \n",
        "all_growth_stage = np.array(all_growth_stage)\n",
        "np.save('/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/b2_lq2_only_step1_5fold_pred_wd.npy', all_growth_stage)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b1-f1951068.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b1-f1951068.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd2b793e6954440589d6ea2098e38582",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=31519111.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "(Val) loss is 3.9425562501162448\n",
            "(Val) f1 score is 0.0\n",
            "(Val) rmse is 3.19597281310445\n",
            "(Train) loss is 3.140910883744558\n",
            "(Train) f1 score is 0\n",
            "(Train) rmse is 0\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "(Val) loss is 3.178070466697947\n",
            "(Val) f1 score is 0.0022675736961451248\n",
            "(Val) rmse is 3.03745487033048\n",
            "(Train) loss is 3.0040662388006845\n",
            "(Train) f1 score is 0\n",
            "(Train) rmse is 0\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "(Val) loss is 3.5846992015003534\n",
            "(Val) f1 score is 0.0\n",
            "(Val) rmse is 3.186018693259899\n",
            "(Train) loss is 3.1435382465521493\n",
            "(Train) f1 score is 0\n",
            "(Train) rmse is 0\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "(Val) loss is 3.062673478953266\n",
            "(Val) f1 score is 0.005952380952380952\n",
            "(Val) rmse is 3.0329025835688332\n",
            "(Train) loss is 3.1356143852074942\n",
            "(Train) f1 score is 0\n",
            "(Train) rmse is 0\n",
            "Loaded pretrained weights for efficientnet-b1\n",
            "(Val) loss is 2.9511563928240028\n",
            "(Val) f1 score is 0.004608294930875576\n",
            "(Val) rmse is 2.90316511744526\n",
            "(Train) loss is 3.0087155401706696\n",
            "(Train) f1 score is 0\n",
            "(Train) rmse is 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92/92 [04:10<00:00,  2.72s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DGhn2Byo56-"
      },
      "source": [
        "Cell-5: Run this cell to generate lq2 only b4 step1 pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1O8Je-pnUim"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model_infos = {\n",
        "      # b4 lq2 only step 1 \n",
        "      'b4_lq2_only_step1_fold0': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b4_step1/weights/fold0/checkpoint_best_f1_score_fold0.pth',\n",
        "            'model_name': 'efficientnet-b4',\n",
        "            'global_dim': 1792,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b4_lq2_only_step1_fold1': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b4_step1/weights/fold1/checkpoint_best_f1_score_fold1.pth',\n",
        "            'model_name': 'efficientnet-b4',\n",
        "            'global_dim': 1792,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b4_lq2_only_step1_fold2': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b4_step1/weights/fold2/checkpoint_best_f1_score_fold2.pth',\n",
        "            'model_name': 'efficientnet-b4',\n",
        "            'global_dim': 1792,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b4_lq2_only_step1_fold3': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b4_step1/weights/fold3/checkpoint_best_f1_score_fold3.pth',\n",
        "            'model_name': 'efficientnet-b4',\n",
        "            'global_dim': 1792,\n",
        "            'version': 1,\n",
        "      },\n",
        "      'b4_lq2_only_step1_fold4': {\n",
        "            'path': '/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/train_lq2_only_effnet_b4_step1/weights/fold4/checkpoint_best_f1_score_fold4.pth',\n",
        "            'model_name': 'efficientnet-b4',\n",
        "            'global_dim': 1792,\n",
        "            'version': 1,\n",
        "      },\n",
        "}\n",
        "\n",
        "models = []\n",
        "for model_type in model_infos:\n",
        "    try:\n",
        "        models.append(get_model(model_infos[model_type]))\n",
        "    except:\n",
        "        print('Error has occured...skipping!')\n",
        "\n",
        "all_growth_stage = []\n",
        "torch.set_grad_enabled(False)                                \n",
        "with torch.no_grad():\n",
        "    for itera_no, data in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "        images, images_fliplr = data\n",
        "        images = images.cuda()\n",
        "        images_fliplr = images_fliplr.cuda()\n",
        "\n",
        "        y_pred = 0                                                      \n",
        "        for i in range(len(models)):\n",
        "            with torch.cuda.amp.autocast():\n",
        "               out_1 = models[i](images)\n",
        "               out_2 = models[i](images_fliplr)\n",
        "            y_pred += out_1['LOGITS'][:,0].cpu().data.numpy()\n",
        "            y_pred += out_2['LOGITS'][:,0].cpu().data.numpy()\n",
        "\n",
        "        y_pred = y_pred/(len(models)*2)\n",
        "        all_growth_stage += y_pred.clip(min=0, max=6).tolist()      \n",
        "            \n",
        "all_growth_stage = np.array(all_growth_stage)\n",
        "np.save('/content/gdrive/My Drive/zindi_cgiar_wheat_growth_stage_challenge/b4_lq2_only_step1_5fold_pred_wd.npy', all_growth_stage)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}